{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X4cRE8IbIrIV"
   },
   "source": [
    "If you're opening this Notebook on colab, you will probably need to install ü§ó Transformers and ü§ó Datasets. Uncomment the following cell and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T04:41:27.091781Z",
     "start_time": "2024-04-11T04:41:23.714762Z"
    },
    "id": "48_bU0zVYoUk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.30.2\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HFASsisvIrIb"
   },
   "source": [
    "You can find a script version of this notebook to fine-tune your model in a distributed fashion using multiple GPUs or TPUs [here](https://github.com/huggingface/transformers/tree/master/examples/token-classification)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z0IkEJXkYoUk"
   },
   "source": [
    "We also quickly upload some telemetry - this tells us which examples and software versions are getting used so we know where to prioritize our maintenance efforts. We don't collect (or care about) any personally identifiable information, but if you'd prefer not to be counted, feel free to skip this step or delete this cell entirely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rEJBSTyZIrIb"
   },
   "source": [
    "# Fine-tuning a model on a token classification task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mcib0_rLYoUl"
   },
   "source": [
    "In this notebook, we will see how to fine-tune one of the [ü§ó Transformers](https://github.com/huggingface/transformers) model to a token classification task, which is the task of predicting a label for each token.\n",
    "\n",
    "![Widget inference representing the NER task](https://github.com/huggingface/notebooks/blob/main/examples/images/token_classification.png?raw=1)\n",
    "\n",
    "The most common token classification tasks are:\n",
    "\n",
    "- NER (Named-entity recognition) Classify the entities in the text (person, organization, location...).\n",
    "- POS (Part-of-speech tagging) Grammatically classify the tokens (noun, verb, adjective...)\n",
    "- Chunk (Chunking) Grammatically classify the tokens and group them into \"chunks\" that go together\n",
    "\n",
    "We will see how to easily load a dataset for these kinds of tasks and use the `Trainer` API to fine-tune a model on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4RRkXuteIrIh"
   },
   "source": [
    "This notebook is built to run on any token classification task, with any model checkpoint from the [Model Hub](https://huggingface.co/models) as long as that model has a version with a token classification head and a fast tokenizer (check on [this table](https://huggingface.co/transformers/index.html#bigtable) if this is the case). It might just need some small adjustments if you decide to use a different dataset than the one used here. Depending on you model and the GPU you are using, you might need to adjust the batch size to avoid out-of-memory errors. Set those three parameters, then the rest of the notebook should run smoothly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T04:41:50.263736Z",
     "start_time": "2024-04-11T04:41:50.238142Z"
    },
    "id": "zVvslsfMIrIh"
   },
   "outputs": [],
   "source": [
    "task = \"ner\" # Should be one of \"ner\", \"pos\" or \"chunk\"\n",
    "model_checkpoint = \"ai-forever/ruBert-base\"\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whPRbBNbIrIl"
   },
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W7QYTpxXIrIl"
   },
   "source": [
    "We will use the [ü§ó Datasets](https://github.com/huggingface/datasets) library to download the data and get the metric we need to use for evaluation (to compare our model to the benchmark). This can be easily done with the functions `load_dataset` and `load_metric`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T04:45:44.763538Z",
     "start_time": "2024-04-11T04:45:44.753171Z"
    },
    "id": "IreSlFmlIrIm"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric, load_from_disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CKx2zKs5IrIq"
   },
   "source": [
    "For our example here, we'll use the [CONLL 2003 dataset](https://www.aclweb.org/anthology/W03-0419.pdf). The notebook should work with any token classification dataset provided by the ü§ó Datasets library. If you're using your own dataset defined from a JSON or csv file (see the [Datasets documentation](https://huggingface.co/docs/datasets/loading_datasets.html#from-local-files) on how to load them), it might need some adjustments in the names of the columns used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T04:45:49.519079Z",
     "start_time": "2024-04-11T04:45:49.494395Z"
    }
   },
   "outputs": [],
   "source": [
    "datasets = load_from_disk('test.hf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T04:45:52.632497Z",
     "start_time": "2024-04-11T04:45:52.627911Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'text', 'entities', 'relations', 'links'],\n",
       "        num_rows: 746\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'text', 'entities', 'relations', 'links'],\n",
       "        num_rows: 93\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['id', 'text', 'entities', 'relations', 'links'],\n",
       "        num_rows: 94\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RzfPtOMoIrIu"
   },
   "source": [
    "The `datasets` object itself is [`DatasetDict`](https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasetdict), which contains one key for the training, validation and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T16:12:45.603Z",
     "start_time": "2024-04-10T16:12:45.593148Z"
    },
    "id": "GWiVUF0jIrIv",
    "outputId": "35e3ea43-f397-4a54-c90c-f2cf8d36873e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'text', 'entities', 'relations', 'links'],\n",
       "        num_rows: 746\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'text', 'entities', 'relations', 'links'],\n",
       "        num_rows: 93\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['id', 'text', 'entities', 'relations', 'links'],\n",
       "        num_rows: 94\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9lzzOQLDYoUm"
   },
   "source": [
    "We can see the training, validation and test sets all have a column for the tokens (the input texts split into words) and one column of labels for each kind of task we introduced before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u3EtYfeHIrIz"
   },
   "source": [
    "To access an actual element, you need to select a split first, then give an index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T16:12:45.627086Z",
     "start_time": "2024-04-10T16:12:45.610163Z"
    },
    "id": "X6HrpprwIrIz",
    "outputId": "d7670bc0-42e4-4c09-8a6a-5c018ded7d95"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'text': '–ü—É–ª–µ–º–µ—Ç—ã, –∞–≤—Ç–æ–º–∞—Ç—ã –∏ —Å–Ω–∞–π–ø–µ—Ä—Å–∫–∏–µ –≤–∏–Ω—Ç–æ–≤–∫–∏ –∏–∑—ä—è—Ç—ã –≤ –∞—Ä–µ–Ω–¥—É–µ–º–æ–º –∞–º–µ—Ä–∏–∫–∞–Ω—Ü–∞–º–∏ –¥–æ–º–µ –≤ –ë–∏—à–∫–µ–∫–µ\\n\\n05/08/2008 10:35\\n\\n–ë–ò–®–ö–ï–ö, 5 –∞–≤–≥—É—Å—Ç–∞ /–ù–æ–≤–æ—Å—Ç–∏-–ì—Ä—É–∑–∏—è/. –ü—Ä–∞–≤–æ–æ—Ö—Ä–∞–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –æ—Ä–≥–∞–Ω—ã –ö–∏—Ä–≥–∏–∑–∏–∏ –æ–±–Ω–∞—Ä—É–∂–∏–ª–∏ –≤ –¥–æ–º–µ, –∞—Ä–µ–Ω–¥—É–µ–º–æ–º –≥—Ä–∞–∂–¥–∞–Ω–∞–º–∏ –°–®–ê –≤ –ë–∏—à–∫–µ–∫–µ, –ø—É–ª–µ–º–µ—Ç—ã, –∞–≤—Ç–æ–º–∞—Ç—ã –∏ —Å–Ω–∞–π–ø–µ—Ä—Å–∫–∏–µ –≤–∏–Ω—Ç–æ–≤–∫–∏, —Å–æ–æ–±—â–∞–µ—Ç –≤–æ –≤—Ç–æ—Ä–Ω–∏–∫ –ø—Ä–µ—Å—Å-—Å–ª—É–∂–±–∞ –ú–í–î –ö–∏—Ä–≥–∏–∑–∏–∏.\\n\\n\"–í —Ö–æ–¥–µ –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è –æ–ø–µ—Ä–∞—Ç–∏–≤–Ω–æ-–ø—Ä–æ—Ñ–∏–ª–∞–∫—Ç–∏—á–µ—Å–∫–æ–≥–æ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è –ø–æ–¥ –∫–æ–¥–æ–≤—ã–º –Ω–∞–∑–≤–∞–Ω–∏–µ–º \"–ê—Ä—Å–µ–Ω–∞–ª\" –≤ –Ω–æ–≤–æ—Å—Ç—Ä–æ–π–∫–µ –´–Ω—Ç—ã–º–∞–∫, –≤ –¥–æ–º–µ, –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∞—â–µ–º 66-–ª–µ—Ç–Ω–µ–º—É –≥—Ä–∞–∂–¥–∞–Ω–∏–Ω—É –ö–∏—Ä–≥–∏–∑–∏–∏ –∏ –∞—Ä–µ–Ω–¥—É–µ–º–æ–º –≥—Ä–∞–∂–¥–∞–Ω–∞–º–∏ –°–®–ê, –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã –∏ –∏–∑—ä—è—Ç—ã: —à–µ—Å—Ç—å –∫—Ä—É–ø–Ω–æ–∫–∞–ª–∏–±–µ—Ä–Ω—ã—Ö –ø—É–ª–µ–º–µ—Ç–æ–≤ —Å –æ–ø—Ç–∏—á–µ—Å–∫–∏–º –ø—Ä–∏—Ü–µ–ª–æ–º –∏ —Å –ø—Ä–∏–±–æ—Ä–∞–º–∏ –Ω–æ—á–Ω–æ–≥–æ –≤–∏–¥–µ–Ω–∏—è, 26 –∞–≤—Ç–æ–º–∞—Ç–æ–≤ –∫–∞–ª–∏–±—Ä–∞ 5,56 –º–∏–ª–ª–∏–º–µ—Ç—Ä–∞, –¥–≤–∞ –≤–∏–Ω—á–µ—Å—Ç–µ—Ä–∞ –º–∞—Ä–∫–∏ –ú–û–°–í–ï–ì–ê 12-–≥–æ –∫–∞–ª–∏–±—Ä–∞, —á–µ—Ç—ã—Ä–µ —Å—Ç–≤–æ–ª–∞ –æ—Ç –∫—Ä—É–ø–Ω–æ–∫–∞–ª–∏–±–µ—Ä–Ω–æ–≥–æ –ø—É–ª–µ–º–µ—Ç–∞, –¥–≤–∞ –ø–æ–¥—Å—Ç–≤–æ–ª—å–Ω—ã—Ö –≥—Ä–∞–Ω–∞—Ç–æ–º–µ—Ç–∞, —á–µ—Ç—ã—Ä–µ —Å–Ω–∞–π–ø–µ—Ä—Å–∫–∏–µ –≤–∏–Ω—Ç–æ–≤–∫–∏ —Å –æ–ø—Ç–∏—á–µ—Å–∫–∏–º –ø—Ä–∏—Ü–µ–ª–æ–º –∑–∞—â–∏—Ç–Ω–æ–≥–æ —Ü–≤–µ—Ç–∞, —à–µ—Å—Ç—å –ø–∏—Å—Ç–æ–ª–µ—Ç–æ–≤ –∫–∞–ª–∏–±—Ä–∞ 9 –º–∏–ª–ª–∏–º–µ—Ç—Ä–æ–≤ –º–∞—Ä–∫–∏ –ë–µ—Ä–µ—Ç—Ç–∞, –æ–¥–Ω–∞ –≤–∏–Ω—Ç–æ–≤–∫–∞\", - –≥–æ–≤–æ—Ä–∏—Ç—Å—è –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏ –ú–í–î.\\n\\n–ü—Ä–µ—Å—Å-—Å–ª—É–∂–±–∞ –æ—Ç–º–µ—á–∞–µ—Ç, —á—Ç–æ –Ω–∞ –º–æ–º–µ–Ω—Ç –æ–±—ã—Å–∫–∞ \"–≤ –¥–æ–º–µ –Ω–∞—Ö–æ–¥–∏–ª–∏—Å—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –ø–æ—Å–æ–ª—å—Å—Ç–≤–∞ –°–®–ê, –æ–±–ª–∞–¥–∞—é—â–∏—Ö –¥–∏–ø–ª–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –∏–º–º—É–Ω–∏—Ç–µ—Ç–æ–º, –∏ 10 –≤–æ–µ–Ω–Ω–æ—Å–ª—É–∂–∞—â–∏—Ö, —è–∫–æ–±—ã –ø—Ä–∏–±—ã–≤—à–∏—Ö –∏–∑ –°–®–ê –¥–ª—è –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è —Ç—Ä–µ–Ω–∏–Ω–≥–∞ —Å —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞–º–∏ —Å–ø–µ—Ü–ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –æ–¥–Ω–æ–π –∏–∑ —Å–∏–ª–æ–≤—ã—Ö —Å—Ç—Ä—É–∫—Ç—É—Ä —Ä–µ—Å–ø—É–±–ª–∏–∫–∏, –ª–∏—á–Ω–æ—Å—Ç–∏ –∫–æ—Ç–æ—Ä—ã—Ö –≤ –Ω–∞—Å—Ç–æ—è—â–µ–µ –≤—Ä–µ–º—è —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é—Ç—Å—è\".\\n\\n–°–æ–≥–ª–∞—Å–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏—é, –≤ –¥–æ–º–µ –±—ã–ª–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ –∏ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–æ–µ–ø—Ä–∏–ø–∞—Å–æ–≤. \"–î–≤–∞ –Ω–æ–∂–∞, 2920 —à—Ç—É–∫ –ø–∞—Ç—Ä–æ–Ω–æ–≤ –∫–∞–ª–∏–±—Ä–∞ 5,56 –º–∏–ª–ª–∏–º–µ—Ç—Ä–∞, 10556 —à—Ç—É–∫ –ø–∞—Ç—Ä–æ–Ω–æ–≤ –∫–∞–ª–∏–±—Ä–∞ 9 –º–∏–ª–ª–∏–º–µ—Ç—Ä–æ–≤, –¥–≤–∞ —è—â–∏–∫–∞ –ø–∞—Ç—Ä–æ–Ω–æ–≤ –∫–∞–ª–∏–±—Ä–∞ 50 –º–∏–ª–ª–∏–º–µ—Ç—Ä–æ–≤, –≤ –∫–∞–∂–¥–æ–º 350 —à—Ç—É–∫, –ø–∞—Ç—Ä–æ–Ω—ã –∫–∞–ª–∏–±—Ä–∞ 12 –º–∏–ª–ª–∏–º–µ—Ç—Ä–æ–≤ –≤ –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ 478 —à—Ç—É–∫, –º–∞—Ä–∫–∏—Ä–æ–≤–æ—á–Ω—ã–µ (—Ç—Ä–∞—Å—Å–∏—Ä—É—é—â–∏–µ) –ø–∞—Ç—Ä–æ–Ω—ã (–∫—Ä–∞—Å–Ω–æ–≥–æ —Ü–≤–µ—Ç–∞) 1000 —à—Ç—É–∫, 66 —à—Ç—É–∫ –ø—É—Å—Ç—ã—Ö –º–∞–≥–∞–∑–∏–Ω–æ–≤ –æ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ—Ä—É–∂–∏—è, 57 —à—Ç—É–∫ –ø—É—Å—Ç—ã—Ö –º–∞–≥–∞–∑–∏–Ω–æ–≤ –æ—Ç –ø–∏—Å—Ç–æ–ª–µ—Ç–∞ –ë–µ—Ä–µ—Ç—Ç–∞\", - –≥–æ–≤–æ—Ä–∏—Ç—Å—è –≤ –ø—Ä–µ—Å—Å-—Ä–µ–ª–∏–∑–µ.\\n\\n–ü—Ä–µ—Å—Å-—Å–ª—É–∂–±–∞ –ú–í–î —Å–æ–æ–±—â–∏–ª–∞, —á—Ç–æ —Ä–∞—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ –¥–∞–Ω–Ω–æ–º—É —Ñ–∞–∫—Ç—É –ø—Ä–æ–≤–æ–¥–∏—Ç –ø—Ä–æ–∫—É—Ä–∞—Ç—É—Ä–∞ –ë–∏—à–∫–µ–∫–∞. –°–µ–π—á–∞—Å –≤—ã—è—Å–Ω—è–µ—Ç—Å—è, –∫–æ–º—É –∏–º–µ–Ω–Ω–æ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∏—Ç –∏–∑—ä—è—Ç–æ–µ –æ—Ä—É–∂–∏–µ, –ø–µ—Ä–µ–¥–∞–µ—Ç –†–ò–ê –ù–æ–≤–æ—Å—Ç–∏.\\n\\n–û—Ä—É–∂–∏–µ, –∏–∑—ä—è—Ç–æ–µ —É –≥—Ä–∞–∂–¥–∞–Ω –°–®–ê –ø—Ä–∞–≤–æ–æ—Ö—Ä–∞–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ –æ—Ä–≥–∞–Ω–∞–º–∏ –ö–∏—Ä–≥–∏–∑–∏–∏, –Ω–∞—Ö–æ–¥–∏–ª–æ—Å—å –≤ —Ä–µ—Å–ø—É–±–ª–∏–∫–µ —Å –≤–µ–¥–æ–º–∞ –ø—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–∞ –ö–∏—Ä–≥–∏–∑–∏–∏, —Å–æ–æ–±—â–∏–ª –≤–æ –≤—Ç–æ—Ä–Ω–∏–∫ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ–ª—å –ø—Ä–µ—Å—Å-—Å–ª—É–∂–±—ã –ø–æ—Å–æ–ª—å—Å—Ç–≤–∞ –°–®–ê.\\n\\n\"–í—Å–µ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ –Ω–∞—Ö–æ–¥–∏–ª–æ—Å—å –Ω–∞ —Ç–µ—Ä—Ä–∏—Ç–æ—Ä–∏–∏ –ö–∏—Ä–≥–∏–∑–∏–∏ —Å –≤–µ–¥–æ–º–∞ –∏ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –∫–∏—Ä–≥–∏–∑—Å–∫–∏—Ö –≤–ª–∞—Å—Ç–µ–π\", - —Å–∫–∞–∑–∞–ª —Å–æ–±–µ—Å–µ–¥–Ω–∏–∫ –∞–≥–µ–Ω—Ç—Å—Ç–≤–∞. –í–æ–µ–Ω–Ω–æ—Å–ª—É–∂–∞—â–∏–µ –∏ –æ—Ä—É–∂–∏–µ \"–ø—Ä–∏–±—ã–ª–∏ –≤ —Ä–µ—Å–ø—É–±–ª–∏–∫—É –ø–æ –ø—Ä–∏–≥–ª–∞—à–µ–Ω–∏—é –ø—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–∞ —Å —Ü–µ–ª—å—é –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è –∞–Ω—Ç–∏—Ç–µ—Ä—Ä–æ—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö —É—á–µ–Ω–∏–π –¥–ª—è –º–∏–Ω–∏—Å—Ç–µ—Ä—Å—Ç–≤\", –∑–∞—è–≤–∏–ª–æ –∞–º–µ—Ä–∏–∫–∞–Ω—Å–∫–æ–µ –¥–∏–ø–ª–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –≤–µ–¥–æ–º—Å—Ç–≤–æ.\\n\\n\"–î–æ–º –∏ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ –Ω–∞—Ö–æ–¥–∏–ª–∏—Å—å –ø–æ–¥ –∑–∞—â–∏—Ç–æ–π –∫–∏—Ä–≥–∏–∑—Å–∫–∏—Ö –≤–ª–∞—Å—Ç–µ–π\", - –æ—Ç–º–µ—á–∞–µ—Ç –ø—Ä–µ—Å—Å-—Å–ª—É–∂–±–∞.\\n\\n–ü–æ—Å–æ–ª—å—Å—Ç–≤–æ –°–®–ê —Å—á–∏—Ç–∞–µ—Ç —Å–ª—É—á–∏–≤—à–µ–µ—Å—è \"–Ω–µ–ø—Ä–∏—è—Ç–Ω—ã–º –∏–Ω—Ü–∏–¥–µ–Ω—Ç–æ–º\" –∏ –≤—ã—Ä–∞–∂–∞–µ—Ç –Ω–∞–¥–µ–∂–¥—É —á—Ç–æ \"–°–®–ê –∏ –ö–∏—Ä–≥–∏–∑–∏—è –º–æ–≥–ª–∏ –±—ã –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å —É—Å–∏–ª–∏—è –ø–æ —É–ª—É—á—à–µ–Ω–∏—é –∞–Ω—Ç–∏—Ç–µ—Ä—Ä–æ—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π –ö–∏—Ä–≥–∏–∑–∏–∏\".\\n\\n–ü—Ä–µ—Å—Å-—Å–ª—É–∂–±–∞ –∞–º–µ—Ä–∏–∫–∞–Ω—Å–∫–æ–π –≤–æ–µ–Ω–Ω–æ–π –±–∞–∑—ã —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–Ω–æ–π –≤ –º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω–æ–º –∞—ç—Ä–æ–ø–æ—Ä—Ç—É \"–ú–∞–Ω–∞—Å\" —Å—Ç–æ–ª–∏—Ü—ã –ö–∏—Ä–≥–∏–∑–∏–∏ –æ—Ç–∫–∞–∑–∞–ª–∞—Å—å –∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–π –∏–Ω—Ü–∏–¥–µ–Ω—Ç —Å —É—á–∞—Å—Ç–∏–µ–º –∞–º–µ—Ä–∏–∫–∞–Ω—Å–∫–∏—Ö –≤–æ–µ–Ω–Ω—ã—Ö.\\n\\n\"–í—Å–µ–º–∏ –≤–æ–ø—Ä–æ—Å–∞–º–∏, —Å–≤—è–∑–∞–Ω–Ω—ã–º–∏ —Å –¥–∞–Ω–Ω—ã–º —Å–ª—É—á–∞–µ–º, –∑–∞–Ω–∏–º–∞–µ—Ç—Å—è –ø–æ—Å–æ–ª—å—Å—Ç–≤–æ –°–®–ê\", - —Å–æ–æ–±—â–∏–ª–∏ –†–ò–ê –ù–æ–≤–æ—Å—Ç–∏ –≤ –ø—Ä–µ—Å—Å-—Å–ª—É–∂–±–µ –±–∞–∑—ã.',\n",
       " 'entities': ['T1\\tNATIONALITY 62 74\\t–∞–º–µ—Ä–∏–∫–∞–Ω—Ü–∞–º–∏',\n",
       "  'T2\\tCITY 82 89\\t–ë–∏—à–∫–µ–∫–µ',\n",
       "  'T3\\tDATE 117 126\\t5 –∞–≤–≥—É—Å—Ç–∞',\n",
       "  'T4\\tCOUNTRY 136 142\\t–ì—Ä—É–∑–∏—è',\n",
       "  'T5\\tORGANIZATION 145 179\\t–ü—Ä–∞–≤–æ–æ—Ö—Ä–∞–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –æ—Ä–≥–∞–Ω—ã –ö–∏—Ä–≥–∏–∑–∏–∏',\n",
       "  'T6\\tCOUNTRY 171 179\\t–ö–∏—Ä–≥–∏–∑–∏–∏',\n",
       "  'T7\\tCOUNTRY 221 224\\t–°–®–ê',\n",
       "  'T8\\tCITY 227 234\\t–ë–∏—à–∫–µ–∫–µ',\n",
       "  'T9\\tDATE 288 298\\t–≤–æ –≤—Ç–æ—Ä–Ω–∏–∫',\n",
       "  'T10\\tORGANIZATION 312 315\\t–ú–í–î',\n",
       "  'T11\\tDATE 91 101\\t05/08/2008',\n",
       "  'T12\\tCITY 433 440\\t–´–Ω—Ç—ã–º–∞–∫',\n",
       "  'T13\\tAGE 464 474\\t66-–ª–µ—Ç–Ω–µ–º—É',\n",
       "  'T14\\tCOUNTRY 486 494\\t–ö–∏—Ä–≥–∏–∑–∏–∏',\n",
       "  'T15\\tCOUNTRY 519 522\\t–°–®–ê',\n",
       "  'T16\\tNUMBER 545 550\\t—à–µ—Å—Ç—å',\n",
       "  'T17\\tNUMBER 631 633\\t26',\n",
       "  'T18\\tNUMBER 652 667\\t5,56 –º–∏–ª–ª–∏–º–µ—Ç—Ä–∞',\n",
       "  'T19\\tNUMBER 669 672\\t–¥–≤–∞',\n",
       "  'T20\\tPRODUCT 690 697\\t–ú–û–°–í–ï–ì–ê',\n",
       "  'T21\\tNUMBER 713 719\\t—á–µ—Ç—ã—Ä–µ',\n",
       "  'T22\\tNUMBER 758 761\\t–¥–≤–∞',\n",
       "  'T23\\tNUMBER 788 794\\t—á–µ—Ç—ã—Ä–µ',\n",
       "  'T24\\tNUMBER 855 860\\t—à–µ—Å—Ç—å',\n",
       "  'T25\\tNUMBER 880 893\\t9 –º–∏–ª–ª–∏–º–µ—Ç—Ä–æ–≤',\n",
       "  'T26\\tPRODUCT 900 907\\t–ë–µ—Ä–µ—Ç—Ç–∞',\n",
       "  'T27\\tNUMBER 909 913\\t–æ–¥–Ω–∞',\n",
       "  'T28\\tORGANIZATION 949 952\\t–ú–í–î',\n",
       "  'T29\\tNUMBER 1098 1100\\t10',\n",
       "  'T30\\tCOUNTRY 1136 1139\\t–°–®–ê',\n",
       "  'T31\\tNUMBER 1372 1375\\t–î–≤–∞',\n",
       "  'T32\\tNUMBER 1382 1386\\t2920',\n",
       "  'T33\\tNUMBER 1409 1424\\t5,56 –º–∏–ª–ª–∏–º–µ—Ç—Ä–∞',\n",
       "  'T34\\tNUMBER 1426 1431\\t10556',\n",
       "  'T35\\tNUMBER 1454 1467\\t9 –º–∏–ª–ª–∏–º–µ—Ç—Ä–æ–≤',\n",
       "  'T36\\tNUMBER 1469 1472\\t–¥–≤–∞',\n",
       "  'T37\\tNUMBER 1496 1510\\t50 –º–∏–ª–ª–∏–º–µ—Ç—Ä–æ–≤',\n",
       "  'T38\\tNUMBER 1521 1524\\t350',\n",
       "  'T39\\tNUMBER 1547 1561\\t12 –º–∏–ª–ª–∏–º–µ—Ç—Ä–æ–≤',\n",
       "  'T40\\tNUMBER 1575 1578\\t478',\n",
       "  'T41\\tNUMBER 1639 1643\\t1000',\n",
       "  'T42\\tORGANIZATION 312 324\\t–ú–í–î –ö–∏—Ä–≥–∏–∑–∏–∏',\n",
       "  'T43\\tNUMBER 1650 1652\\t66',\n",
       "  'T44\\tORGANIZATION 1792 1795\\t–ú–í–î',\n",
       "  'T45\\tNUMBER 1702 1704\\t57',\n",
       "  'T46\\tPRODUCT 1740 1747\\t–ë–µ—Ä–µ—Ç—Ç–∞',\n",
       "  'T47\\tORGANIZATION 1779 1795\\t–ü—Ä–µ—Å—Å-—Å–ª—É–∂–±–∞ –ú–í–î',\n",
       "  'T48\\tORGANIZATION 1850 1861\\t–ø—Ä–æ–∫—É—Ä–∞—Ç—É—Ä–∞',\n",
       "  'T49\\tORGANIZATION 1939 1950\\t–†–ò–ê –ù–æ–≤–æ—Å—Ç–∏',\n",
       "  'T50\\tCOUNTRY 1979 1982\\t–°–®–ê',\n",
       "  'T51\\tCOUNTRY 2012 2020\\t–ö–∏—Ä–≥–∏–∑–∏–∏',\n",
       "  'T52\\tORGANIZATION 2055 2077\\t–ø—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–∞ –ö–∏—Ä–≥–∏–∑–∏–∏',\n",
       "  'T53\\tDATE 2087 2097\\t–≤–æ –≤—Ç–æ—Ä–Ω–∏–∫',\n",
       "  'T54\\tORGANIZATION 2216 2234\\t–∫–∏—Ä–≥–∏–∑—Å–∫–∏—Ö –≤–ª–∞—Å—Ç–µ–π',\n",
       "  'T55\\tCOUNTRY 2185 2193\\t–ö–∏—Ä–≥–∏–∑–∏–∏',\n",
       "  'T56\\tCOUNTRY 2216 2226\\t–∫–∏—Ä–≥–∏–∑—Å–∫–∏—Ö',\n",
       "  'T57\\tCOUNTRY 2417 2429\\t–∞–º–µ—Ä–∏–∫–∞–Ω—Å–∫–æ–µ',\n",
       "  'T58\\tCOUNTRY 2501 2511\\t–∫–∏—Ä–≥–∏–∑—Å–∫–∏—Ö',\n",
       "  'T59\\tCITY 2819 2835\\t—Å—Ç–æ–ª–∏—Ü—ã –ö–∏—Ä–≥–∏–∑–∏–∏',\n",
       "  'T60\\tCOUNTRY 2631 2634\\t–°–®–ê',\n",
       "  'T61\\tCOUNTRY 2637 2645\\t–ö–∏—Ä–≥–∏–∑–∏—è',\n",
       "  'T62\\tCOUNTRY 2720 2728\\t–ö–∏—Ä–≥–∏–∑–∏–∏',\n",
       "  'T63\\tNUMBER 698 711\\t12-–≥–æ –∫–∞–ª–∏–±—Ä–∞',\n",
       "  'T64\\tFACILITY 2812 2817\\t–ú–∞–Ω–∞—Å',\n",
       "  'T65\\tCOUNTRY 2827 2835\\t–ö–∏—Ä–≥–∏–∑–∏–∏',\n",
       "  'T66\\tCOUNTRY 2889 2901\\t–∞–º–µ—Ä–∏–∫–∞–Ω—Å–∫–∏—Ö',\n",
       "  'T67\\tCOUNTRY 2745 2757\\t–∞–º–µ—Ä–∏–∫–∞–Ω—Å–∫–æ–π',\n",
       "  'T68\\tORGANIZATION 2998 3009\\t–†–ò–ê –ù–æ–≤–æ—Å—Ç–∏',\n",
       "  'T69\\tTIME 91 107\\t05/08/2008 10:35',\n",
       "  'T70\\tEVENT 410 417\\t–ê—Ä—Å–µ–Ω–∞–ª',\n",
       "  'T71\\tCITY 109 115\\t–ë–ò–®–ö–ï–ö',\n",
       "  'T72\\tORGANIZATION 128 142\\t–ù–æ–≤–æ—Å—Ç–∏-–ì—Ä—É–∑–∏—è',\n",
       "  'T73\\tCOUNTRY 316 324\\t–ö–∏—Ä–≥–∏–∑–∏–∏',\n",
       "  'T74\\tORGANIZATION 299 324\\t–ø—Ä–µ—Å—Å-—Å–ª—É–∂–±–∞ –ú–í–î –ö–∏—Ä–≥–∏–∑–∏–∏',\n",
       "  'T75\\tCOUNTRY 1051 1054\\t–°–®–ê',\n",
       "  'T76\\tORGANIZATION 1040 1054\\t–ø–æ—Å–æ–ª—å—Å—Ç–≤–∞ –°–®–ê',\n",
       "  'T77\\tPROFESSION 1028 1054\\t—Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –ø–æ—Å–æ–ª—å—Å—Ç–≤–∞ –°–®–ê',\n",
       "  'T78\\tPROFESSION 1101 1115\\t–≤–æ–µ–Ω–Ω–æ—Å–ª—É–∂–∞—â–∏—Ö',\n",
       "  'T79\\tNATIONALITY 1971 1982\\t–≥—Ä–∞–∂–¥–∞–Ω –°–®–ê',\n",
       "  'T80\\tPROFESSION 1166 1196\\t—Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞–º–∏ —Å–ø–µ—Ü–ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è',\n",
       "  'T81\\tCOUNTRY 2136 2139\\t–°–®–ê',\n",
       "  'T82\\tORGANIZATION 1850 1869\\t–ø—Ä–æ–∫—É—Ä–∞—Ç—É—Ä–∞ –ë–∏—à–∫–µ–∫–∞',\n",
       "  'T83\\tCITY 1862 1869\\t–ë–∏—à–∫–µ–∫–∞',\n",
       "  'T84\\tTIME 1871 1877\\t–°–µ–π—á–∞—Å',\n",
       "  'T85\\tORGANIZATION 1983 2020\\t–ø—Ä–∞–≤–æ–æ—Ö—Ä–∞–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ –æ—Ä–≥–∞–Ω–∞–º–∏ –ö–∏—Ä–≥–∏–∑–∏–∏',\n",
       "  'T86\\tCOUNTRY 2069 2077\\t–ö–∏—Ä–≥–∏–∑–∏–∏',\n",
       "  'T87\\tORGANIZATION 2125 2139\\t–ø–æ—Å–æ–ª—å—Å—Ç–≤–∞ –°–®–ê',\n",
       "  'T88\\tPROFESSION 2098 2139\\t–ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ–ª—å –ø—Ä–µ—Å—Å-—Å–ª—É–∂–±—ã –ø–æ—Å–æ–ª—å—Å—Ç–≤–∞ –°–®–ê',\n",
       "  'T89\\tORGANIZATION 2112 2139\\t–ø—Ä–µ—Å—Å-—Å–ª—É–∂–±—ã –ø–æ—Å–æ–ª—å—Å—Ç–≤–∞ –°–®–ê',\n",
       "  'T90\\tPROFESSION 2268 2282\\t–í–æ–µ–Ω–Ω–æ—Å–ª—É–∂–∞—â–∏–µ',\n",
       "  'T91\\tORGANIZATION 2395 2406\\t–º–∏–Ω–∏—Å—Ç–µ—Ä—Å—Ç–≤',\n",
       "  'T92\\tORGANIZATION 2329 2342\\t–ø—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–∞',\n",
       "  'T93\\tORGANIZATION 2417 2455\\t–∞–º–µ—Ä–∏–∫–∞–Ω—Å–∫–æ–µ –¥–∏–ø–ª–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –≤–µ–¥–æ–º—Å—Ç–≤–æ',\n",
       "  'T94\\tORGANIZATION 2430 2455\\t–¥–∏–ø–ª–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –≤–µ–¥–æ–º—Å—Ç–≤–æ',\n",
       "  'T95\\tORGANIZATION 2533 2545\\t–ø—Ä–µ—Å—Å-—Å–ª—É–∂–±–∞',\n",
       "  'T96\\tCOUNTRY 2559 2562\\t–°–®–ê',\n",
       "  'T97\\tORGANIZATION 2548 2562\\t–ü–æ—Å–æ–ª—å—Å—Ç–≤–æ –°–®–ê',\n",
       "  'T98\\tORGANIZATION 2732 2770\\t–ü—Ä–µ—Å—Å-—Å–ª—É–∂–±–∞ –∞–º–µ—Ä–∏–∫–∞–Ω—Å–∫–æ–π –≤–æ–µ–Ω–Ω–æ–π –±–∞–∑—ã',\n",
       "  'T100\\tORGANIZATION 2745 2770\\t–∞–º–µ—Ä–∏–∫–∞–Ω—Å–∫–æ–π –≤–æ–µ–Ω–Ω–æ–π –±–∞–∑—ã',\n",
       "  'T101\\tNATIONALITY 475 494\\t–≥—Ä–∞–∂–¥–∞–Ω–∏–Ω—É –ö–∏—Ä–≥–∏–∑–∏–∏',\n",
       "  'T102\\tPROFESSION 2902 2909\\t–≤–æ–µ–Ω–Ω—ã—Ö',\n",
       "  'T103\\tORGANIZATION 2970 2984\\t–ø–æ—Å–æ–ª—å—Å—Ç–≤–æ –°–®–ê',\n",
       "  'T104\\tNATIONALITY 210 224\\t–≥—Ä–∞–∂–¥–∞–Ω–∞–º–∏ –°–®–ê',\n",
       "  'T105\\tNATIONALITY 508 522\\t–≥—Ä–∞–∂–¥–∞–Ω–∞–º–∏ –°–®–ê',\n",
       "  'T106\\tEVENT 524 543\\t–æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã –∏ –∏–∑—ä—è—Ç—ã',\n",
       "  'T107\\tORGANIZATION 2501 2519\\t–∫–∏—Ä–≥–∏–∑—Å–∫–∏—Ö –≤–ª–∞—Å—Ç–µ–π',\n",
       "  'T108\\tCOUNTRY 2981 2984\\t–°–®–ê'],\n",
       " 'relations': ['R1\\tTAKES_PLACE_IN Arg1:T70 Arg2:T12',\n",
       "  'R2\\tAGE_IS Arg1:T101 Arg2:T13',\n",
       "  'R3\\tHEADQUARTERED_IN Arg1:T72 Arg2:T4',\n",
       "  'R4\\tHEADQUARTERED_IN Arg1:T5 Arg2:T6',\n",
       "  'R5\\tHEADQUARTERED_IN Arg1:T42 Arg2:T73',\n",
       "  'R6\\tORGANIZES Arg1:T5 Arg2:T70',\n",
       "  'R7\\tLOCATED_IN Arg1:T12 Arg2:T8',\n",
       "  'R8\\tLOCATED_IN Arg1:T8 Arg2:T6',\n",
       "  'R9\\tOWNER_OF Arg1:T101 Arg2:T12',\n",
       "  'R10\\tSUBEVENT_OF Arg1:T106 Arg2:T70',\n",
       "  'R11\\tHEADQUARTERED_IN Arg1:T82 Arg2:T83',\n",
       "  'R12\\tWORKPLACE Arg1:T88 Arg2:T89',\n",
       "  'R13\\tHEADQUARTERED_IN Arg1:T54 Arg2:T56',\n",
       "  'R14\\tALTERNATIVE_NAME Arg1:T56 Arg2:T55',\n",
       "  'R15\\tALTERNATIVE_NAME Arg1:T87 Arg2:T93',\n",
       "  'R16\\tALTERNATIVE_NAME Arg1:T81 Arg2:T57',\n",
       "  'R17\\tALTERNATIVE_NAME Arg1:T93 Arg2:T97',\n",
       "  'R18\\tALTERNATIVE_NAME Arg1:T57 Arg2:T96',\n",
       "  'R19\\tLOCATED_IN Arg1:T64 Arg2:T59',\n",
       "  'R20\\tORIGINS_FROM Arg1:T102 Arg2:T66',\n",
       "  'R21\\tOWNER_OF Arg1:T108 Arg2:T103',\n",
       "  'R22\\tORIGINS_FROM Arg1:T104 Arg2:T7',\n",
       "  'R23\\tALTERNATIVE_NAME Arg1:T1 Arg2:T104',\n",
       "  'R24\\tORIGINS_FROM Arg1:T105 Arg2:T15',\n",
       "  'R25\\tORIGINS_FROM Arg1:T101 Arg2:T14',\n",
       "  'R26\\tWORKPLACE Arg1:T77 Arg2:T76',\n",
       "  'R27\\tPART_OF Arg1:T74 Arg2:T42',\n",
       "  'R28\\tOWNER_OF Arg1:T96 Arg2:T97',\n",
       "  'R29\\tLOCATED_IN Arg1:T59 Arg2:T65',\n",
       "  'R30\\tPART_OF Arg1:T98 Arg2:T100',\n",
       "  'R31\\tOWNER_OF Arg1:T67 Arg2:T100',\n",
       "  'R32\\tOWNER_OF Arg1:T75 Arg2:T76',\n",
       "  'R33\\tPART_OF Arg1:T47 Arg2:T44',\n",
       "  'R34\\tORIGINS_FROM Arg1:T79 Arg2:T50',\n",
       "  'R35\\tHEADQUARTERED_IN Arg1:T93 Arg2:T57',\n",
       "  'R36\\tHEADQUARTERED_IN Arg1:T107 Arg2:T58',\n",
       "  'R37\\tHEADQUARTERED_IN Arg1:T85 Arg2:T51',\n",
       "  'R38\\tHEADQUARTERED_IN Arg1:T52 Arg2:T86'],\n",
       " 'links': ['N1\\tReference T5 Wikidata:Q813\\t–ö–∏—Ä–≥–∏–∑–∏—è',\n",
       "  'N2\\tReference T10 Wikidata:Q6589202\\t–º–∏–Ω–∏—Å—Ç–µ—Ä—Å—Ç–≤–æ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö –¥–µ–ª',\n",
       "  'N3\\tReference T12 Wikidata:Q13648730\\t–´–Ω—Ç—ã–º–∞–∫',\n",
       "  'N4\\tReference T20 Wikidata:NULL\\t',\n",
       "  'N5\\tReference T46 Wikidata:Q324782\\tBeretta',\n",
       "  'N6\\tReference T47 Wikidata:NULL\\t',\n",
       "  'N7\\tReference T48 Wikidata:Q1092499\\t–ø—Ä–æ–∫—É—Ä–∞—Ç—É—Ä–∞',\n",
       "  'N8\\tReference T49 Wikidata:Q821172\\t–†–ò–ê –ù–æ–≤–æ—Å—Ç–∏',\n",
       "  'N9\\tReference T52 Wikidata:NULL\\t',\n",
       "  'N10\\tReference T62 Wikidata:Q813\\t–ö–∏—Ä–≥–∏–∑–∏—è',\n",
       "  'N11\\tReference T64 Wikidata:Q32997\\t–ú–∞–Ω–∞—Å',\n",
       "  'N12\\tReference T71 Wikidata:Q9361\\t–ë–∏—à–∫–µ–∫',\n",
       "  'N13\\tReference T72 Wikidata:NULL\\t',\n",
       "  'N14\\tReference T4 Wikidata:Q230\\t–ì—Ä—É–∑–∏—è',\n",
       "  'N15\\tReference T74 Wikidata:NULL\\t',\n",
       "  'N16\\tReference T75 Wikidata:Q30\\t–°–®–ê',\n",
       "  'N17\\tReference T76 Wikidata:NULL\\t',\n",
       "  'N18\\tReference T77 Wikidata:NULL\\t',\n",
       "  'N19\\tReference T78 Wikidata:Q47064\\t–≤–æ–µ–Ω–Ω–æ—Å–ª—É–∂–∞—â–∏–π',\n",
       "  'N20\\tReference T80 Wikidata:NULL\\t',\n",
       "  'N21\\tReference T82 Wikidata:NULL\\t',\n",
       "  'N22\\tReference T88 Wikidata:NULL\\t',\n",
       "  'N23\\tReference T89 Wikidata:NULL\\t',\n",
       "  'N24\\tReference T91 Wikidata:Q192350\\t–º–∏–Ω–∏—Å—Ç–µ—Ä—Å—Ç–≤–æ',\n",
       "  'N25\\tReference T92 Wikidata:Q7188\\t–ø—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–æ',\n",
       "  'N26\\tReference T94 Wikidata:NULL\\t',\n",
       "  'N27\\tReference T95 Wikidata:NULL\\t',\n",
       "  'N28\\tReference T98 Wikidata:NULL\\t',\n",
       "  'N29\\tReference T100 Wikidata:Q245016\\t–≤–æ–µ–Ω–Ω–∞—è –±–∞–∑–∞',\n",
       "  'N30\\tReference T102 Wikidata:Q47064\\t–≤–æ–µ–Ω–Ω–æ—Å–ª—É–∂–∞—â–∏–π',\n",
       "  'N31\\tReference T101 Wikidata:NULL\\t',\n",
       "  'N32\\tReference T105 Wikidata:Q846570\\t',\n",
       "  'N33\\tReference T42 Wikidata:NULL\\t',\n",
       "  'N34\\tReference T59 Wikidata:Q9361\\t–ë–∏—à–∫–µ–∫',\n",
       "  'N35\\tReference T107 Wikidata:NULL\\t',\n",
       "  'N36\\tReference T85 Wikidata:Q813\\t–ö–∏—Ä–≥–∏–∑–∏—è',\n",
       "  'N37\\tReference T44 Wikidata:Q6589202\\t–º–∏–Ω–∏—Å—Ç–µ—Ä—Å—Ç–≤–æ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö –¥–µ–ª',\n",
       "  'N38\\tReference T28 Wikidata:Q6589202\\t–º–∏–Ω–∏—Å—Ç–µ—Ä—Å—Ç–≤–æ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö –¥–µ–ª',\n",
       "  'N39\\tReference T26 Wikidata:Q324782\\tBeretta',\n",
       "  'N40\\tReference T68 Wikidata:Q821172\\t–†–ò–ê –ù–æ–≤–æ—Å—Ç–∏',\n",
       "  'N41\\tReference T51 Wikidata:Q813\\t–ö–∏—Ä–≥–∏–∑–∏—è',\n",
       "  'N42\\tReference T61 Wikidata:Q813\\t–ö–∏—Ä–≥–∏–∑–∏—è',\n",
       "  'N43\\tReference T56 Wikidata:Q813\\t–ö–∏—Ä–≥–∏–∑–∏—è',\n",
       "  'N44\\tReference T14 Wikidata:Q813\\t–ö–∏—Ä–≥–∏–∑–∏—è',\n",
       "  'N45\\tReference T86 Wikidata:Q813\\t–ö–∏—Ä–≥–∏–∑–∏—è',\n",
       "  'N46\\tReference T65 Wikidata:Q813\\t–ö–∏—Ä–≥–∏–∑–∏—è',\n",
       "  'N47\\tReference T73 Wikidata:Q813\\t–ö–∏—Ä–≥–∏–∑–∏—è',\n",
       "  'N48\\tReference T55 Wikidata:Q813\\t–ö–∏—Ä–≥–∏–∑–∏—è',\n",
       "  'N49\\tReference T58 Wikidata:Q813\\t–ö–∏—Ä–≥–∏–∑–∏—è',\n",
       "  'N50\\tReference T6 Wikidata:Q813\\t–ö–∏—Ä–≥–∏–∑–∏—è',\n",
       "  'N51\\tReference T8 Wikidata:Q9361\\t–ë–∏—à–∫–µ–∫',\n",
       "  'N52\\tReference T83 Wikidata:Q9361\\t–ë–∏—à–∫–µ–∫',\n",
       "  'N53\\tReference T2 Wikidata:Q9361\\t–ë–∏—à–∫–µ–∫',\n",
       "  'N54\\tReference T57 Wikidata:Q30\\t–°–®–ê',\n",
       "  'N55\\tReference T96 Wikidata:Q30\\t–°–®–ê',\n",
       "  'N56\\tReference T15 Wikidata:Q30\\t–°–®–ê',\n",
       "  'N57\\tReference T108 Wikidata:Q30\\t–°–®–ê',\n",
       "  'N58\\tReference T7 Wikidata:Q30\\t–°–®–ê',\n",
       "  'N59\\tReference T81 Wikidata:Q30\\t–°–®–ê',\n",
       "  'N60\\tReference T30 Wikidata:Q30\\t–°–®–ê',\n",
       "  'N61\\tReference T67 Wikidata:Q30\\t–°–®–ê',\n",
       "  'N62\\tReference T50 Wikidata:Q30\\t–°–®–ê',\n",
       "  'N63\\tReference T66 Wikidata:Q30\\t–°–®–ê',\n",
       "  'N64\\tReference T60 Wikidata:Q30\\t–°–®–ê',\n",
       "  'N65\\tReference T90 Wikidata:Q47064\\t–≤–æ–µ–Ω–Ω–æ—Å–ª—É–∂–∞—â–∏–π',\n",
       "  'N66\\tReference T79 Wikidata:Q846570\\t',\n",
       "  'N67\\tReference T1 Wikidata:Q846570\\t',\n",
       "  'N68\\tReference T104 Wikidata:Q846570\\t',\n",
       "  'N69\\tReference T103 Wikidata:NULL\\t',\n",
       "  'N70\\tReference T87 Wikidata:NULL\\t',\n",
       "  'N71\\tReference T93 Wikidata:NULL\\t',\n",
       "  'N72\\tReference T97 Wikidata:NULL\\t',\n",
       "  'N73\\tReference T54 Wikidata:NULL\\t']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vVA333xvYoUn"
   },
   "source": [
    "The labels are already coded as integer ids to be easily usable by our model, but the correspondence with the actual categories is stored in the `features` of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T16:12:45.637537Z",
     "start_time": "2024-04-10T16:12:45.629037Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def transform_entities(entities):\n",
    "    markup = []\n",
    "    for i in entities:\n",
    "        splited = re.split('\\t', i)\n",
    "        data = re.split(' ', splited[1])\n",
    "        if \";\" in data[2]:\n",
    "            data[2] = data[2].split(\";\")[0]\n",
    "        markup.append({'id': splited[0],\n",
    "               'type': data[0],\n",
    "               'start': int(data[1]),\n",
    "               'stop': int(data[2]),\n",
    "               'text': splited[2]})\n",
    "    markup.sort(key=lambda x: x[\"start\"])\n",
    "    return markup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T16:12:45.680032Z",
     "start_time": "2024-04-10T16:12:45.640097Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'T1',\n",
       "  'type': 'NATIONALITY',\n",
       "  'start': 62,\n",
       "  'stop': 74,\n",
       "  'text': '–∞–º–µ—Ä–∏–∫–∞–Ω—Ü–∞–º–∏'},\n",
       " {'id': 'T2', 'type': 'CITY', 'start': 82, 'stop': 89, 'text': '–ë–∏—à–∫–µ–∫–µ'},\n",
       " {'id': 'T11', 'type': 'DATE', 'start': 91, 'stop': 101, 'text': '05/08/2008'},\n",
       " {'id': 'T69',\n",
       "  'type': 'TIME',\n",
       "  'start': 91,\n",
       "  'stop': 107,\n",
       "  'text': '05/08/2008 10:35'},\n",
       " {'id': 'T71', 'type': 'CITY', 'start': 109, 'stop': 115, 'text': '–ë–ò–®–ö–ï–ö'},\n",
       " {'id': 'T3', 'type': 'DATE', 'start': 117, 'stop': 126, 'text': '5 –∞–≤–≥—É—Å—Ç–∞'},\n",
       " {'id': 'T72',\n",
       "  'type': 'ORGANIZATION',\n",
       "  'start': 128,\n",
       "  'stop': 142,\n",
       "  'text': '–ù–æ–≤–æ—Å—Ç–∏-–ì—Ä—É–∑–∏—è'},\n",
       " {'id': 'T4', 'type': 'COUNTRY', 'start': 136, 'stop': 142, 'text': '–ì—Ä—É–∑–∏—è'},\n",
       " {'id': 'T5',\n",
       "  'type': 'ORGANIZATION',\n",
       "  'start': 145,\n",
       "  'stop': 179,\n",
       "  'text': '–ü—Ä–∞–≤–æ–æ—Ö—Ä–∞–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –æ—Ä–≥–∞–Ω—ã –ö–∏—Ä–≥–∏–∑–∏–∏'},\n",
       " {'id': 'T6',\n",
       "  'type': 'COUNTRY',\n",
       "  'start': 171,\n",
       "  'stop': 179,\n",
       "  'text': '–ö–∏—Ä–≥–∏–∑–∏–∏'},\n",
       " {'id': 'T104',\n",
       "  'type': 'NATIONALITY',\n",
       "  'start': 210,\n",
       "  'stop': 224,\n",
       "  'text': '–≥—Ä–∞–∂–¥–∞–Ω–∞–º–∏ –°–®–ê'},\n",
       " {'id': 'T7', 'type': 'COUNTRY', 'start': 221, 'stop': 224, 'text': '–°–®–ê'},\n",
       " {'id': 'T8', 'type': 'CITY', 'start': 227, 'stop': 234, 'text': '–ë–∏—à–∫–µ–∫–µ'},\n",
       " {'id': 'T9', 'type': 'DATE', 'start': 288, 'stop': 298, 'text': '–≤–æ –≤—Ç–æ—Ä–Ω–∏–∫'},\n",
       " {'id': 'T74',\n",
       "  'type': 'ORGANIZATION',\n",
       "  'start': 299,\n",
       "  'stop': 324,\n",
       "  'text': '–ø—Ä–µ—Å—Å-—Å–ª—É–∂–±–∞ –ú–í–î –ö–∏—Ä–≥–∏–∑–∏–∏'},\n",
       " {'id': 'T10',\n",
       "  'type': 'ORGANIZATION',\n",
       "  'start': 312,\n",
       "  'stop': 315,\n",
       "  'text': '–ú–í–î'},\n",
       " {'id': 'T42',\n",
       "  'type': 'ORGANIZATION',\n",
       "  'start': 312,\n",
       "  'stop': 324,\n",
       "  'text': '–ú–í–î –ö–∏—Ä–≥–∏–∑–∏–∏'},\n",
       " {'id': 'T73',\n",
       "  'type': 'COUNTRY',\n",
       "  'start': 316,\n",
       "  'stop': 324,\n",
       "  'text': '–ö–∏—Ä–≥–∏–∑–∏–∏'},\n",
       " {'id': 'T70', 'type': 'EVENT', 'start': 410, 'stop': 417, 'text': '–ê—Ä—Å–µ–Ω–∞–ª'},\n",
       " {'id': 'T12', 'type': 'CITY', 'start': 433, 'stop': 440, 'text': '–´–Ω—Ç—ã–º–∞–∫'},\n",
       " {'id': 'T13', 'type': 'AGE', 'start': 464, 'stop': 474, 'text': '66-–ª–µ—Ç–Ω–µ–º—É'},\n",
       " {'id': 'T101',\n",
       "  'type': 'NATIONALITY',\n",
       "  'start': 475,\n",
       "  'stop': 494,\n",
       "  'text': '–≥—Ä–∞–∂–¥–∞–Ω–∏–Ω—É –ö–∏—Ä–≥–∏–∑–∏–∏'},\n",
       " {'id': 'T14',\n",
       "  'type': 'COUNTRY',\n",
       "  'start': 486,\n",
       "  'stop': 494,\n",
       "  'text': '–ö–∏—Ä–≥–∏–∑–∏–∏'},\n",
       " {'id': 'T105',\n",
       "  'type': 'NATIONALITY',\n",
       "  'start': 508,\n",
       "  'stop': 522,\n",
       "  'text': '–≥—Ä–∞–∂–¥–∞–Ω–∞–º–∏ –°–®–ê'},\n",
       " {'id': 'T15', 'type': 'COUNTRY', 'start': 519, 'stop': 522, 'text': '–°–®–ê'},\n",
       " {'id': 'T106',\n",
       "  'type': 'EVENT',\n",
       "  'start': 524,\n",
       "  'stop': 543,\n",
       "  'text': '–æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã –∏ –∏–∑—ä—è—Ç—ã'},\n",
       " {'id': 'T16', 'type': 'NUMBER', 'start': 545, 'stop': 550, 'text': '—à–µ—Å—Ç—å'},\n",
       " {'id': 'T17', 'type': 'NUMBER', 'start': 631, 'stop': 633, 'text': '26'},\n",
       " {'id': 'T18',\n",
       "  'type': 'NUMBER',\n",
       "  'start': 652,\n",
       "  'stop': 667,\n",
       "  'text': '5,56 –º–∏–ª–ª–∏–º–µ—Ç—Ä–∞'},\n",
       " {'id': 'T19', 'type': 'NUMBER', 'start': 669, 'stop': 672, 'text': '–¥–≤–∞'},\n",
       " {'id': 'T20',\n",
       "  'type': 'PRODUCT',\n",
       "  'start': 690,\n",
       "  'stop': 697,\n",
       "  'text': '–ú–û–°–í–ï–ì–ê'},\n",
       " {'id': 'T63',\n",
       "  'type': 'NUMBER',\n",
       "  'start': 698,\n",
       "  'stop': 711,\n",
       "  'text': '12-–≥–æ –∫–∞–ª–∏–±—Ä–∞'},\n",
       " {'id': 'T21', 'type': 'NUMBER', 'start': 713, 'stop': 719, 'text': '—á–µ—Ç—ã—Ä–µ'},\n",
       " {'id': 'T22', 'type': 'NUMBER', 'start': 758, 'stop': 761, 'text': '–¥–≤–∞'},\n",
       " {'id': 'T23', 'type': 'NUMBER', 'start': 788, 'stop': 794, 'text': '—á–µ—Ç—ã—Ä–µ'},\n",
       " {'id': 'T24', 'type': 'NUMBER', 'start': 855, 'stop': 860, 'text': '—à–µ—Å—Ç—å'},\n",
       " {'id': 'T25',\n",
       "  'type': 'NUMBER',\n",
       "  'start': 880,\n",
       "  'stop': 893,\n",
       "  'text': '9 –º–∏–ª–ª–∏–º–µ—Ç—Ä–æ–≤'},\n",
       " {'id': 'T26',\n",
       "  'type': 'PRODUCT',\n",
       "  'start': 900,\n",
       "  'stop': 907,\n",
       "  'text': '–ë–µ—Ä–µ—Ç—Ç–∞'},\n",
       " {'id': 'T27', 'type': 'NUMBER', 'start': 909, 'stop': 913, 'text': '–æ–¥–Ω–∞'},\n",
       " {'id': 'T28',\n",
       "  'type': 'ORGANIZATION',\n",
       "  'start': 949,\n",
       "  'stop': 952,\n",
       "  'text': '–ú–í–î'},\n",
       " {'id': 'T77',\n",
       "  'type': 'PROFESSION',\n",
       "  'start': 1028,\n",
       "  'stop': 1054,\n",
       "  'text': '—Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –ø–æ—Å–æ–ª—å—Å—Ç–≤–∞ –°–®–ê'},\n",
       " {'id': 'T76',\n",
       "  'type': 'ORGANIZATION',\n",
       "  'start': 1040,\n",
       "  'stop': 1054,\n",
       "  'text': '–ø–æ—Å–æ–ª—å—Å—Ç–≤–∞ –°–®–ê'},\n",
       " {'id': 'T75', 'type': 'COUNTRY', 'start': 1051, 'stop': 1054, 'text': '–°–®–ê'},\n",
       " {'id': 'T29', 'type': 'NUMBER', 'start': 1098, 'stop': 1100, 'text': '10'},\n",
       " {'id': 'T78',\n",
       "  'type': 'PROFESSION',\n",
       "  'start': 1101,\n",
       "  'stop': 1115,\n",
       "  'text': '–≤–æ–µ–Ω–Ω–æ—Å–ª—É–∂–∞—â–∏—Ö'},\n",
       " {'id': 'T30', 'type': 'COUNTRY', 'start': 1136, 'stop': 1139, 'text': '–°–®–ê'},\n",
       " {'id': 'T80',\n",
       "  'type': 'PROFESSION',\n",
       "  'start': 1166,\n",
       "  'stop': 1196,\n",
       "  'text': '—Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞–º–∏ —Å–ø–µ—Ü–ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è'},\n",
       " {'id': 'T31', 'type': 'NUMBER', 'start': 1372, 'stop': 1375, 'text': '–î–≤–∞'},\n",
       " {'id': 'T32', 'type': 'NUMBER', 'start': 1382, 'stop': 1386, 'text': '2920'},\n",
       " {'id': 'T33',\n",
       "  'type': 'NUMBER',\n",
       "  'start': 1409,\n",
       "  'stop': 1424,\n",
       "  'text': '5,56 –º–∏–ª–ª–∏–º–µ—Ç—Ä–∞'},\n",
       " {'id': 'T34', 'type': 'NUMBER', 'start': 1426, 'stop': 1431, 'text': '10556'},\n",
       " {'id': 'T35',\n",
       "  'type': 'NUMBER',\n",
       "  'start': 1454,\n",
       "  'stop': 1467,\n",
       "  'text': '9 –º–∏–ª–ª–∏–º–µ—Ç—Ä–æ–≤'},\n",
       " {'id': 'T36', 'type': 'NUMBER', 'start': 1469, 'stop': 1472, 'text': '–¥–≤–∞'},\n",
       " {'id': 'T37',\n",
       "  'type': 'NUMBER',\n",
       "  'start': 1496,\n",
       "  'stop': 1510,\n",
       "  'text': '50 –º–∏–ª–ª–∏–º–µ—Ç—Ä–æ–≤'},\n",
       " {'id': 'T38', 'type': 'NUMBER', 'start': 1521, 'stop': 1524, 'text': '350'},\n",
       " {'id': 'T39',\n",
       "  'type': 'NUMBER',\n",
       "  'start': 1547,\n",
       "  'stop': 1561,\n",
       "  'text': '12 –º–∏–ª–ª–∏–º–µ—Ç—Ä–æ–≤'},\n",
       " {'id': 'T40', 'type': 'NUMBER', 'start': 1575, 'stop': 1578, 'text': '478'},\n",
       " {'id': 'T41', 'type': 'NUMBER', 'start': 1639, 'stop': 1643, 'text': '1000'},\n",
       " {'id': 'T43', 'type': 'NUMBER', 'start': 1650, 'stop': 1652, 'text': '66'},\n",
       " {'id': 'T45', 'type': 'NUMBER', 'start': 1702, 'stop': 1704, 'text': '57'},\n",
       " {'id': 'T46',\n",
       "  'type': 'PRODUCT',\n",
       "  'start': 1740,\n",
       "  'stop': 1747,\n",
       "  'text': '–ë–µ—Ä–µ—Ç—Ç–∞'},\n",
       " {'id': 'T47',\n",
       "  'type': 'ORGANIZATION',\n",
       "  'start': 1779,\n",
       "  'stop': 1795,\n",
       "  'text': '–ü—Ä–µ—Å—Å-—Å–ª—É–∂–±–∞ –ú–í–î'},\n",
       " {'id': 'T44',\n",
       "  'type': 'ORGANIZATION',\n",
       "  'start': 1792,\n",
       "  'stop': 1795,\n",
       "  'text': '–ú–í–î'},\n",
       " {'id': 'T48',\n",
       "  'type': 'ORGANIZATION',\n",
       "  'start': 1850,\n",
       "  'stop': 1861,\n",
       "  'text': '–ø—Ä–æ–∫—É—Ä–∞—Ç—É—Ä–∞'},\n",
       " {'id': 'T82',\n",
       "  'type': 'ORGANIZATION',\n",
       "  'start': 1850,\n",
       "  'stop': 1869,\n",
       "  'text': '–ø—Ä–æ–∫—É—Ä–∞—Ç—É—Ä–∞ –ë–∏—à–∫–µ–∫–∞'},\n",
       " {'id': 'T83', 'type': 'CITY', 'start': 1862, 'stop': 1869, 'text': '–ë–∏—à–∫–µ–∫–∞'},\n",
       " {'id': 'T84', 'type': 'TIME', 'start': 1871, 'stop': 1877, 'text': '–°–µ–π—á–∞—Å'},\n",
       " {'id': 'T49',\n",
       "  'type': 'ORGANIZATION',\n",
       "  'start': 1939,\n",
       "  'stop': 1950,\n",
       "  'text': '–†–ò–ê –ù–æ–≤–æ—Å—Ç–∏'},\n",
       " {'id': 'T79',\n",
       "  'type': 'NATIONALITY',\n",
       "  'start': 1971,\n",
       "  'stop': 1982,\n",
       "  'text': '–≥—Ä–∞–∂–¥–∞–Ω –°–®–ê'},\n",
       " {'id': 'T50', 'type': 'COUNTRY', 'start': 1979, 'stop': 1982, 'text': '–°–®–ê'},\n",
       " {'id': 'T85',\n",
       "  'type': 'ORGANIZATION',\n",
       "  'start': 1983,\n",
       "  'stop': 2020,\n",
       "  'text': '–ø—Ä–∞–≤–æ–æ—Ö—Ä–∞–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ –æ—Ä–≥–∞–Ω–∞–º–∏ –ö–∏—Ä–≥–∏–∑–∏–∏'},\n",
       " {'id': 'T51',\n",
       "  'type': 'COUNTRY',\n",
       "  'start': 2012,\n",
       "  'stop': 2020,\n",
       "  'text': '–ö–∏—Ä–≥–∏–∑–∏–∏'},\n",
       " {'id': 'T52',\n",
       "  'type': 'ORGANIZATION',\n",
       "  'start': 2055,\n",
       "  'stop': 2077,\n",
       "  'text': '–ø—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–∞ –ö–∏—Ä–≥–∏–∑–∏–∏'},\n",
       " {'id': 'T86',\n",
       "  'type': 'COUNTRY',\n",
       "  'start': 2069,\n",
       "  'stop': 2077,\n",
       "  'text': '–ö–∏—Ä–≥–∏–∑–∏–∏'},\n",
       " {'id': 'T53',\n",
       "  'type': 'DATE',\n",
       "  'start': 2087,\n",
       "  'stop': 2097,\n",
       "  'text': '–≤–æ –≤—Ç–æ—Ä–Ω–∏–∫'},\n",
       " {'id': 'T88',\n",
       "  'type': 'PROFESSION',\n",
       "  'start': 2098,\n",
       "  'stop': 2139,\n",
       "  'text': '–ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ–ª—å –ø—Ä–µ—Å—Å-—Å–ª—É–∂–±—ã –ø–æ—Å–æ–ª—å—Å—Ç–≤–∞ –°–®–ê'},\n",
       " {'id': 'T89',\n",
       "  'type': 'ORGANIZATION',\n",
       "  'start': 2112,\n",
       "  'stop': 2139,\n",
       "  'text': '–ø—Ä–µ—Å—Å-—Å–ª—É–∂–±—ã –ø–æ—Å–æ–ª—å—Å—Ç–≤–∞ –°–®–ê'},\n",
       " {'id': 'T87',\n",
       "  'type': 'ORGANIZATION',\n",
       "  'start': 2125,\n",
       "  'stop': 2139,\n",
       "  'text': '–ø–æ—Å–æ–ª—å—Å—Ç–≤–∞ –°–®–ê'},\n",
       " {'id': 'T81', 'type': 'COUNTRY', 'start': 2136, 'stop': 2139, 'text': '–°–®–ê'},\n",
       " {'id': 'T55',\n",
       "  'type': 'COUNTRY',\n",
       "  'start': 2185,\n",
       "  'stop': 2193,\n",
       "  'text': '–ö–∏—Ä–≥–∏–∑–∏–∏'},\n",
       " {'id': 'T54',\n",
       "  'type': 'ORGANIZATION',\n",
       "  'start': 2216,\n",
       "  'stop': 2234,\n",
       "  'text': '–∫–∏—Ä–≥–∏–∑—Å–∫–∏—Ö –≤–ª–∞—Å—Ç–µ–π'},\n",
       " {'id': 'T56',\n",
       "  'type': 'COUNTRY',\n",
       "  'start': 2216,\n",
       "  'stop': 2226,\n",
       "  'text': '–∫–∏—Ä–≥–∏–∑—Å–∫–∏—Ö'},\n",
       " {'id': 'T90',\n",
       "  'type': 'PROFESSION',\n",
       "  'start': 2268,\n",
       "  'stop': 2282,\n",
       "  'text': '–í–æ–µ–Ω–Ω–æ—Å–ª—É–∂–∞—â–∏–µ'},\n",
       " {'id': 'T92',\n",
       "  'type': 'ORGANIZATION',\n",
       "  'start': 2329,\n",
       "  'stop': 2342,\n",
       "  'text': '–ø—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–∞'},\n",
       " {'id': 'T91',\n",
       "  'type': 'ORGANIZATION',\n",
       "  'start': 2395,\n",
       "  'stop': 2406,\n",
       "  'text': '–º–∏–Ω–∏—Å—Ç–µ—Ä—Å—Ç–≤'},\n",
       " {'id': 'T57',\n",
       "  'type': 'COUNTRY',\n",
       "  'start': 2417,\n",
       "  'stop': 2429,\n",
       "  'text': '–∞–º–µ—Ä–∏–∫–∞–Ω—Å–∫–æ–µ'},\n",
       " {'id': 'T93',\n",
       "  'type': 'ORGANIZATION',\n",
       "  'start': 2417,\n",
       "  'stop': 2455,\n",
       "  'text': '–∞–º–µ—Ä–∏–∫–∞–Ω—Å–∫–æ–µ –¥–∏–ø–ª–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –≤–µ–¥–æ–º—Å—Ç–≤–æ'},\n",
       " {'id': 'T94',\n",
       "  'type': 'ORGANIZATION',\n",
       "  'start': 2430,\n",
       "  'stop': 2455,\n",
       "  'text': '–¥–∏–ø–ª–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –≤–µ–¥–æ–º—Å—Ç–≤–æ'},\n",
       " {'id': 'T58',\n",
       "  'type': 'COUNTRY',\n",
       "  'start': 2501,\n",
       "  'stop': 2511,\n",
       "  'text': '–∫–∏—Ä–≥–∏–∑—Å–∫–∏—Ö'},\n",
       " {'id': 'T107',\n",
       "  'type': 'ORGANIZATION',\n",
       "  'start': 2501,\n",
       "  'stop': 2519,\n",
       "  'text': '–∫–∏—Ä–≥–∏–∑—Å–∫–∏—Ö –≤–ª–∞—Å—Ç–µ–π'},\n",
       " {'id': 'T95',\n",
       "  'type': 'ORGANIZATION',\n",
       "  'start': 2533,\n",
       "  'stop': 2545,\n",
       "  'text': '–ø—Ä–µ—Å—Å-—Å–ª—É–∂–±–∞'},\n",
       " {'id': 'T97',\n",
       "  'type': 'ORGANIZATION',\n",
       "  'start': 2548,\n",
       "  'stop': 2562,\n",
       "  'text': '–ü–æ—Å–æ–ª—å—Å—Ç–≤–æ –°–®–ê'},\n",
       " {'id': 'T96', 'type': 'COUNTRY', 'start': 2559, 'stop': 2562, 'text': '–°–®–ê'},\n",
       " {'id': 'T60', 'type': 'COUNTRY', 'start': 2631, 'stop': 2634, 'text': '–°–®–ê'},\n",
       " {'id': 'T61',\n",
       "  'type': 'COUNTRY',\n",
       "  'start': 2637,\n",
       "  'stop': 2645,\n",
       "  'text': '–ö–∏—Ä–≥–∏–∑–∏—è'},\n",
       " {'id': 'T62',\n",
       "  'type': 'COUNTRY',\n",
       "  'start': 2720,\n",
       "  'stop': 2728,\n",
       "  'text': '–ö–∏—Ä–≥–∏–∑–∏–∏'},\n",
       " {'id': 'T98',\n",
       "  'type': 'ORGANIZATION',\n",
       "  'start': 2732,\n",
       "  'stop': 2770,\n",
       "  'text': '–ü—Ä–µ—Å—Å-—Å–ª—É–∂–±–∞ –∞–º–µ—Ä–∏–∫–∞–Ω—Å–∫–æ–π –≤–æ–µ–Ω–Ω–æ–π –±–∞–∑—ã'},\n",
       " {'id': 'T67',\n",
       "  'type': 'COUNTRY',\n",
       "  'start': 2745,\n",
       "  'stop': 2757,\n",
       "  'text': '–∞–º–µ—Ä–∏–∫–∞–Ω—Å–∫–æ–π'},\n",
       " {'id': 'T100',\n",
       "  'type': 'ORGANIZATION',\n",
       "  'start': 2745,\n",
       "  'stop': 2770,\n",
       "  'text': '–∞–º–µ—Ä–∏–∫–∞–Ω—Å–∫–æ–π –≤–æ–µ–Ω–Ω–æ–π –±–∞–∑—ã'},\n",
       " {'id': 'T64',\n",
       "  'type': 'FACILITY',\n",
       "  'start': 2812,\n",
       "  'stop': 2817,\n",
       "  'text': '–ú–∞–Ω–∞—Å'},\n",
       " {'id': 'T59',\n",
       "  'type': 'CITY',\n",
       "  'start': 2819,\n",
       "  'stop': 2835,\n",
       "  'text': '—Å—Ç–æ–ª–∏—Ü—ã –ö–∏—Ä–≥–∏–∑–∏–∏'},\n",
       " {'id': 'T65',\n",
       "  'type': 'COUNTRY',\n",
       "  'start': 2827,\n",
       "  'stop': 2835,\n",
       "  'text': '–ö–∏—Ä–≥–∏–∑–∏–∏'},\n",
       " {'id': 'T66',\n",
       "  'type': 'COUNTRY',\n",
       "  'start': 2889,\n",
       "  'stop': 2901,\n",
       "  'text': '–∞–º–µ—Ä–∏–∫–∞–Ω—Å–∫–∏—Ö'},\n",
       " {'id': 'T102',\n",
       "  'type': 'PROFESSION',\n",
       "  'start': 2902,\n",
       "  'stop': 2909,\n",
       "  'text': '–≤–æ–µ–Ω–Ω—ã—Ö'},\n",
       " {'id': 'T103',\n",
       "  'type': 'ORGANIZATION',\n",
       "  'start': 2970,\n",
       "  'stop': 2984,\n",
       "  'text': '–ø–æ—Å–æ–ª—å—Å—Ç–≤–æ –°–®–ê'},\n",
       " {'id': 'T108', 'type': 'COUNTRY', 'start': 2981, 'stop': 2984, 'text': '–°–®–ê'},\n",
       " {'id': 'T68',\n",
       "  'type': 'ORGANIZATION',\n",
       "  'start': 2998,\n",
       "  'stop': 3009,\n",
       "  'text': '–†–ò–ê –ù–æ–≤–æ—Å—Ç–∏'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_entities(datasets[\"train\"][0]['entities'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T16:12:45.705838Z",
     "start_time": "2024-04-10T16:12:45.681868Z"
    }
   },
   "outputs": [],
   "source": [
    "def transform(text, markup): \n",
    "    tokens = [text[0:markup[0]['start']]]\n",
    "    tags = ['O']\n",
    "    \n",
    "    for i in range(len(markup[:-1])):\n",
    "        tokens.append(text[markup[i]['start']:markup[i]['stop']])\n",
    "        tags.append(markup[i]['type'])\n",
    "        tokens.append(text[markup[i]['stop']:markup[i + 1]['start']])\n",
    "        tags.append('O')\n",
    "\n",
    "    tokens.append(text[markup[-1]['start']:markup[-1]['stop']])\n",
    "    tags.append(markup[-1]['type'])\n",
    "    tokens.append(text[markup[-1]['stop']:])\n",
    "    tags.append('O')\n",
    "    \n",
    "    final_tokens = []\n",
    "    final_tags = []\n",
    "    \n",
    "    for i in range(len(tokens)):\n",
    "        size = len(tokens[i].split())\n",
    "        final_tokens += tokens[i].split()\n",
    "        if tags[i] != \"O\":\n",
    "            final_tags.append(\"B-\" + tags[i])\n",
    "            final_tags += [\"I-\" + tags[i]] * (size - 1)\n",
    "        else:\n",
    "            final_tags += [tags[i]] * size\n",
    "        \n",
    "    return final_tokens, final_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T16:12:45.741563Z",
     "start_time": "2024-04-10T16:12:45.726322Z"
    }
   },
   "outputs": [],
   "source": [
    "tokens, entities = transform(datasets[\"train\"][0]['text'], transform_entities(datasets[\"train\"][0]['entities']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T16:12:45.766083Z",
     "start_time": "2024-04-10T16:12:45.743856Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(445, 445)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens), len(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T16:12:45.781264Z",
     "start_time": "2024-04-10T16:12:45.768824Z"
    },
    "id": "RddCu-oqYoUn",
    "outputId": "a4aa7160-f27b-476f-d1cc-074562f8e944"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-NATIONALITY',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-CITY',\n",
       " 'B-DATE',\n",
       " 'B-TIME',\n",
       " 'I-TIME',\n",
       " 'B-CITY',\n",
       " 'O',\n",
       " 'B-DATE',\n",
       " 'I-DATE',\n",
       " 'O',\n",
       " 'B-ORGANIZATION',\n",
       " 'B-COUNTRY',\n",
       " 'O',\n",
       " 'B-ORGANIZATION',\n",
       " 'I-ORGANIZATION',\n",
       " 'I-ORGANIZATION',\n",
       " 'B-COUNTRY',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-NATIONALITY',\n",
       " 'I-NATIONALITY',\n",
       " 'B-COUNTRY',\n",
       " 'O',\n",
       " 'B-CITY',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-DATE',\n",
       " 'I-DATE',\n",
       " 'B-ORGANIZATION',\n",
       " 'I-ORGANIZATION',\n",
       " 'I-ORGANIZATION',\n",
       " 'B-ORGANIZATION',\n",
       " 'B-ORGANIZATION',\n",
       " 'I-ORGANIZATION',\n",
       " 'B-COUNTRY',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-EVENT',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-CITY',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-AGE',\n",
       " 'B-NATIONALITY',\n",
       " 'I-NATIONALITY',\n",
       " 'B-COUNTRY',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-NATIONALITY',\n",
       " 'I-NATIONALITY',\n",
       " 'B-COUNTRY',\n",
       " 'O',\n",
       " 'B-EVENT',\n",
       " 'I-EVENT',\n",
       " 'I-EVENT',\n",
       " 'O',\n",
       " 'B-NUMBER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-NUMBER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-NUMBER',\n",
       " 'I-NUMBER',\n",
       " 'O',\n",
       " 'B-NUMBER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-PRODUCT',\n",
       " 'B-NUMBER',\n",
       " 'I-NUMBER',\n",
       " 'O',\n",
       " 'B-NUMBER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-NUMBER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-NUMBER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-NUMBER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-NUMBER',\n",
       " 'I-NUMBER',\n",
       " 'O',\n",
       " 'B-PRODUCT',\n",
       " 'O',\n",
       " 'B-NUMBER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-ORGANIZATION',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-PROFESSION',\n",
       " 'I-PROFESSION',\n",
       " 'I-PROFESSION',\n",
       " 'B-ORGANIZATION',\n",
       " 'I-ORGANIZATION',\n",
       " 'B-COUNTRY',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-NUMBER',\n",
       " 'B-PROFESSION',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-COUNTRY',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-PROFESSION',\n",
       " 'I-PROFESSION',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-NUMBER',\n",
       " 'O',\n",
       " 'B-NUMBER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-NUMBER',\n",
       " 'I-NUMBER',\n",
       " 'O',\n",
       " 'B-NUMBER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-NUMBER',\n",
       " 'I-NUMBER',\n",
       " 'O',\n",
       " 'B-NUMBER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-NUMBER',\n",
       " 'I-NUMBER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-NUMBER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-NUMBER',\n",
       " 'I-NUMBER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-NUMBER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-NUMBER',\n",
       " 'O',\n",
       " 'B-NUMBER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-NUMBER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-PRODUCT',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-ORGANIZATION',\n",
       " 'I-ORGANIZATION',\n",
       " 'B-ORGANIZATION',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-ORGANIZATION',\n",
       " 'B-ORGANIZATION',\n",
       " 'I-ORGANIZATION',\n",
       " 'B-CITY',\n",
       " 'O',\n",
       " 'B-TIME',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-ORGANIZATION',\n",
       " 'I-ORGANIZATION',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-NATIONALITY',\n",
       " 'I-NATIONALITY',\n",
       " 'B-COUNTRY',\n",
       " 'B-ORGANIZATION',\n",
       " 'I-ORGANIZATION',\n",
       " 'I-ORGANIZATION',\n",
       " 'B-COUNTRY',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-ORGANIZATION',\n",
       " 'I-ORGANIZATION',\n",
       " 'B-COUNTRY',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-DATE',\n",
       " 'I-DATE',\n",
       " 'B-PROFESSION',\n",
       " 'I-PROFESSION',\n",
       " 'I-PROFESSION',\n",
       " 'I-PROFESSION',\n",
       " 'B-ORGANIZATION',\n",
       " 'I-ORGANIZATION',\n",
       " 'I-ORGANIZATION',\n",
       " 'B-ORGANIZATION',\n",
       " 'I-ORGANIZATION',\n",
       " 'B-COUNTRY',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-COUNTRY',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-ORGANIZATION',\n",
       " 'I-ORGANIZATION',\n",
       " 'B-COUNTRY',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-PROFESSION',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-ORGANIZATION',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-ORGANIZATION',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-COUNTRY',\n",
       " 'B-ORGANIZATION',\n",
       " 'I-ORGANIZATION',\n",
       " 'I-ORGANIZATION',\n",
       " 'B-ORGANIZATION',\n",
       " 'I-ORGANIZATION',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-COUNTRY',\n",
       " 'B-ORGANIZATION',\n",
       " 'I-ORGANIZATION',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-ORGANIZATION',\n",
       " 'O',\n",
       " 'B-ORGANIZATION',\n",
       " 'I-ORGANIZATION',\n",
       " 'B-COUNTRY',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-COUNTRY',\n",
       " 'O',\n",
       " 'B-COUNTRY',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-COUNTRY',\n",
       " 'O',\n",
       " 'B-ORGANIZATION',\n",
       " 'I-ORGANIZATION',\n",
       " 'I-ORGANIZATION',\n",
       " 'I-ORGANIZATION',\n",
       " 'B-COUNTRY',\n",
       " 'B-ORGANIZATION',\n",
       " 'I-ORGANIZATION',\n",
       " 'I-ORGANIZATION',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-FACILITY',\n",
       " 'O',\n",
       " 'B-CITY',\n",
       " 'I-CITY',\n",
       " 'B-COUNTRY',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-COUNTRY',\n",
       " 'B-PROFESSION',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-ORGANIZATION',\n",
       " 'I-ORGANIZATION',\n",
       " 'B-COUNTRY',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-ORGANIZATION',\n",
       " 'I-ORGANIZATION',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z30lbCjLYoUn"
   },
   "source": [
    "So for the NER tags, 0 corresponds to 'O', 1 to 'B-PER' etc... On top of the 'O' (which means no special entity), there are four labels for NER here, each prefixed with 'B-' (for beginning) or 'I-' (for intermediate), that indicate if the token is the first one for the current group with the label or not:\n",
    "- 'PER' for person\n",
    "- 'ORG' for organization\n",
    "- 'LOC' for location\n",
    "- 'MISC' for miscellaneous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TYqXmDFdYoUn"
   },
   "source": [
    "Since the labels are lists of `ClassLabel`, the actual names of the labels are nested in the `feature` attribute of the object above:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WHUmphG3IrI3"
   },
   "source": [
    "To get a sense of what the data looks like, the following function will show some examples picked randomly in the dataset (automatically decoding the labels in passing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T16:12:45.798823Z",
     "start_time": "2024-04-10T16:12:45.786611Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class OwnDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.dataset[idx]\n",
    "        text = item['text']\n",
    "        tokens, entities = transform(item['text'], transform_entities(item['entities']))\n",
    "        return {\"text\": text,\n",
    "                \"tokens\": tokens,\n",
    "                \"ner_tags\": entities}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T16:12:45.816568Z",
     "start_time": "2024-04-10T16:12:45.807446Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = OwnDataset(datasets['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T16:12:45.829852Z",
     "start_time": "2024-04-10T16:12:45.819904Z"
    },
    "id": "i3j8APAoIrI3"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "\n",
    "    df = pd.DataFrame(columns=[\"text\", \"tokens\", \"ner_tags\"])\n",
    "    for idx in range(num_examples):\n",
    "        df.at[idx, \"text\"] = dataset[picks[idx]][\"text\"]\n",
    "        df.at[idx, \"tokens\"] = dataset[picks[idx]][\"tokens\"]\n",
    "        df.at[idx, \"ner_tags\"] = dataset[picks[idx]][\"ner_tags\"]\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T16:12:45.918304Z",
     "start_time": "2024-04-10T16:12:45.836184Z"
    },
    "id": "SZy5tRB_IrI7",
    "outputId": "ba8f2124-e485-488f-8c0c-254f34f24f13",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>ner_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>–ü—Ä–µ–º—å–µ—Ä-–º–∏–Ω–∏—Å—Ç—Ä –°–ª–æ–≤–µ–Ω–∏–∏ –ú–∞—Ä—å—è–Ω –®–∞—Ä–µ—Ü –ø–æ–¥–∞–ª –≤ –æ—Ç—Å—Ç–∞–≤–∫—É\\n–ú–∞—Ä—å—è–Ω –®–∞—Ä–µ—Ü\\n–í –ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫, 27 —è–Ω–≤–∞—Ä—è 2020 –≥–æ–¥–∞, –ø—Ä–µ–º—å–µ—Ä-–º–∏–Ω–∏—Å—Ç—Ä –°–ª–æ–≤–µ–Ω–∏–∏ –ú–∞—Ä—å—è–Ω –®–∞—Ä–µ—Ü –ø–æ–¥–∞–ª –≤ –æ—Ç—Å—Ç–∞–≤–∫—É –∏ –ø—Ä–∏–∑–≤–∞–ª –∫ –¥–æ—Å—Ä–æ—á–Ω—ã–º –≤—ã–±–æ—Ä–∞–º:\\n–° —ç—Ç–æ–π –∫–æ–∞–ª–∏—Ü–∏–µ–π, —Å —ç—Ç–æ–π —Å–∏—Ç—É–∞—Ü–∏–µ–π –≤ –ø–∞—Ä–ª–∞–º–µ–Ω—Ç–µ, —è –Ω–µ –º–æ–≥—É –æ–ø—Ä–∞–≤–¥–∞—Ç—å –æ–∂–∏–¥–∞–Ω–∏—è –ª—é–¥–µ–π. –Ø –º–æ–≥ –±—ã –∏—Ö –≤—ã–ø–æ–ª–Ω–∏—Ç—å –ø–æ—Å–ª–µ –≤—ã–±–æ—Ä–æ–≤. C–∞–º—ã–º —á–µ—Å—Ç–Ω—ã–º –≤–∞—Ä–∏–∞–Ω—Ç–æ–º —Å—Ç–∞–Ω–µ—Ç –ø—Ä–æ–≤–µ–¥–µ–Ω–∏–µ –¥–æ—Å—Ä–æ—á–Ω—ã—Ö –≤—ã–±–æ—Ä–æ–≤ –≤ –ì–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω–æ–µ —Å–æ–±—Ä–∞–Ω–∏–µ. –¶–∏—Ç–∞—Ç–∞ —Å–∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞–Ω–∞ –ø–æ —Ä–∞–∑–Ω—ã–º –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º.\\n–†–∞–Ω–µ–µ –≤ –æ—Ç—Å—Ç–∞–≤–∫—É –ø–æ–¥–∞–ª –º–∏–Ω–∏—Å—Ç—Ä–∞ —Ñ–∏–Ω–∞–Ω—Å–æ–≤ –ê–Ω–¥—Ä–µ–π –ë–µ—Ä—Ç–æ–Ω—á–µ–ª—å. –ü–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –°–ú–ò, –≤–µ—Ä–æ—è—Ç–Ω–æ–π –ø—Ä–∏—á–∏–Ω–æ–π –æ—Ç—Å—Ç–∞–≤–∫–∏ –≥–ª–∞–≤—ã –ú–∏–Ω—Ñ–∏–Ω–∞ —Å—Ç–∞–ª–∏ —Ä–∞–∑–Ω–æ–≥–ª–∞—Å–∏—è, —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å –æ—Ç–º–µ–Ω–æ–π –∑–∞–∫–æ–Ω–æ–ø—Ä–æ–µ–∫—Ç–∞ –æ —Å—Ç—Ä–∞—Ö–æ–≤–∞–Ω–∏–∏ –∑–¥–æ—Ä–æ–≤—å—è.\\n\\n–ü—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–æ –≤–æ –≥–ª–∞–≤–µ —Å –ú–∞—Ä—å—è–Ω–æ–º –®–∞—Ä–µ—Ü–æ–º, –ª–∏–¥–µ—Ä–æ–º —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–π –ø–∞—Ä—Ç–∏–∏ LM≈† (–°–ø–∏—Å–æ–∫ –ú–∞—Ä—å—è–Ω–∞ –®–∞—Ä–µ—Ü–∞), —Å–ª–æ–≤–µ–Ω—Å–∫–∏–π –ø–∞—Ä–ª–∞–º–µ–Ω—Ç —É—Ç–≤–µ—Ä–¥–∏–ª –≤ —Å–µ–Ω—Ç—è–±—Ä–µ 2018 –≥–æ–¥–∞ –ø–æ—Å–ª–µ –¥–ª–∏—Ç–µ–ª—å–Ω—ã—Ö –ø–µ—Ä–µ–≥–æ–≤–æ—Ä–æ–≤.\\n\\n–ë—ã–≤—à–∏–π –∞–∫—Ç—ë—Ä –∏ –∫–æ–º–∏–∫ 42-–ª–µ—Ç–Ω–∏–π –ú–∞—Ä—å—è–Ω –®–∞—Ä–µ—Ü —Ä–∞–±–æ—Ç–∞–ª –º—ç—Ä–æ–º –≥–æ—Ä–æ–¥–∞ –ö–∞–º–Ω–∏–∫ –≤ —Ç–µ—á–µ–Ω–∏–µ –¥–≤—É—Ö —Å—Ä–æ–∫–æ–≤. –®–∞—Ä–µ—Ü —è–≤–ª—è–µ—Ç—Å—è —Å–∞–º—ã–º –º–æ–ª–æ–¥—ã–º –≤ –∏—Å—Ç–æ—Ä–∏–∏ –ø—Ä–µ–º—å–µ—Ä-–º–∏–Ω–∏—Å—Ç—Ä–æ–º –°–ª–æ–≤–µ–Ω–∏–∏. –ù–∏ –æ–¥–Ω–∏—Ö –æ–±—â–µ–≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã—Ö –≤—ã–±–æ—Ä–æ–≤ –æ–Ω –Ω–µ –≤—ã–∏–≥—Ä—ã–≤–∞–ª.\\n</td>\n",
       "      <td>[–ü—Ä–µ–º—å–µ—Ä-–º–∏–Ω–∏—Å—Ç—Ä, –ü—Ä–µ–º—å–µ—Ä-–º–∏–Ω–∏—Å—Ç—Ä, –°–ª–æ–≤–µ–Ω–∏–∏, –°–ª–æ–≤–µ–Ω–∏–∏, –ú–∞—Ä—å—è–Ω, –®–∞—Ä–µ—Ü, –ø–æ–¥–∞–ª, –≤, –æ—Ç—Å—Ç–∞–≤–∫—É, –ú–∞—Ä—å—è–Ω, –®–∞—Ä–µ—Ü, –í, –ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫,, 27, —è–Ω–≤–∞—Ä—è, 2020, –≥–æ–¥–∞, ,, –ø—Ä–µ–º—å–µ—Ä-–º–∏–Ω–∏—Å—Ç—Ä, –ø—Ä–µ–º—å–µ—Ä-–º–∏–Ω–∏—Å—Ç—Ä, –°–ª–æ–≤–µ–Ω–∏–∏, –°–ª–æ–≤–µ–Ω–∏–∏, –ú–∞—Ä—å—è–Ω, –®–∞—Ä–µ—Ü, –ø–æ–¥–∞–ª, –≤, –æ—Ç—Å—Ç–∞–≤–∫—É, –∏, –ø—Ä–∏–∑–≤–∞–ª, –∫, –¥–æ—Å—Ä–æ—á–Ω—ã–º, –≤—ã–±–æ—Ä–∞–º:, –°, —ç—Ç–æ–π, –∫–æ–∞–ª–∏—Ü–∏–µ–π,, —Å, —ç—Ç–æ–π, —Å–∏—Ç—É–∞—Ü–∏–µ–π, –≤, –ø–∞—Ä–ª–∞–º–µ–Ω—Ç–µ, ,, —è, –Ω–µ, –º–æ–≥—É, –æ–ø—Ä–∞–≤–¥–∞—Ç—å, –æ–∂–∏–¥–∞–Ω–∏—è, –ª—é–¥–µ–π., –Ø, –º–æ–≥, –±—ã, –∏—Ö, –≤—ã–ø–æ–ª–Ω–∏—Ç—å, –ø–æ—Å–ª–µ, –≤—ã–±–æ—Ä–æ–≤., C–∞–º—ã–º, —á–µ—Å—Ç–Ω—ã–º, –≤–∞—Ä–∏–∞–Ω—Ç–æ–º, —Å—Ç–∞–Ω–µ—Ç, –ø—Ä–æ–≤–µ–¥–µ–Ω–∏–µ, –¥–æ—Å—Ä–æ—á–Ω—ã—Ö, –≤—ã–±–æ—Ä–æ–≤, –≤, –ì–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω–æ–µ, —Å–æ–±—Ä–∞–Ω–∏–µ, ., –¶–∏—Ç–∞—Ç–∞, —Å–∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞–Ω–∞, –ø–æ, —Ä–∞–∑–Ω—ã–º, –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º., –†–∞–Ω–µ–µ, –≤, –æ—Ç—Å—Ç–∞–≤–∫—É, –ø–æ–¥–∞–ª, –º–∏–Ω–∏—Å—Ç—Ä–∞, —Ñ–∏–Ω–∞–Ω—Å–æ–≤, –º–∏–Ω–∏—Å—Ç—Ä–∞, —Ñ–∏–Ω–∞–Ω—Å–æ–≤, –ê–Ω–¥—Ä–µ–π, –ë–µ—Ä—Ç–æ–Ω—á–µ–ª—å, ., –ü–æ, –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, –°–ú–ò,, –≤–µ—Ä–æ—è—Ç–Ω–æ–π, –ø—Ä–∏—á–∏–Ω–æ–π, –æ—Ç—Å—Ç–∞–≤–∫–∏, –≥–ª–∞–≤—ã, –ú–∏–Ω—Ñ–∏–Ω–∞, –ú–∏–Ω—Ñ–∏–Ω–∞, —Å—Ç–∞–ª–∏, —Ä–∞–∑–Ω–æ–≥–ª–∞—Å–∏—è,, —Å–≤—è–∑–∞–Ω–Ω—ã–µ, —Å, –æ—Ç–º–µ–Ω–æ–π, –∑–∞–∫–æ–Ω–æ–ø—Ä–æ–µ–∫—Ç–∞, –æ, —Å—Ç—Ä–∞—Ö–æ–≤–∞–Ω–∏–∏, –∑–¥–æ—Ä–æ–≤—å—è, ., ...]</td>\n",
       "      <td>[B-PROFESSION, B-PROFESSION, I-PROFESSION, B-COUNTRY, B-PERSON, I-PERSON, B-EVENT, I-EVENT, I-EVENT, B-PERSON, I-PERSON, B-DATE, I-DATE, I-DATE, I-DATE, I-DATE, I-DATE, O, B-PROFESSION, B-PROFESSION, I-PROFESSION, B-COUNTRY, B-PERSON, I-PERSON, B-EVENT, I-EVENT, I-EVENT, O, O, O, O, O, O, O, O, O, O, O, O, B-ORGANIZATION, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-ORGANIZATION, I-ORGANIZATION, O, O, O, O, O, O, O, B-EVENT, I-EVENT, I-EVENT, B-PROFESSION, I-PROFESSION, B-PROFESSION, O, B-PERSON, I-PERSON, O, O, O, O, O, O, B-EVENT, B-PROFESSION, I-PROFESSION, B-ORGANIZATION, O, O, O, O, O, B-LAW, I-LAW, I-LAW, I-LAW, O, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>–†—É–∫–æ–ø–∏—Å—å –ê–Ω–Ω—ã –§—Ä–∞–Ω–∫ —É—à–ª–∞ —Å –º–æ–ª–æ—Ç–∫–∞ –∑–∞ 140 —Ç—ã—Å—è—á –µ–≤—Ä–æ\\n–ê–Ω–Ω–∞ –§—Ä–∞–Ω–∫\\n–ù–∞ –∞—É–∫—Ü–∏–æ–Ω–µ –≤ –ù–∏–¥–µ—Ä–ª–∞–Ω–¥–∞—Ö —Ä—É–∫–æ–ø–∏—Å—å —Å—Ç–∏—Ö–æ—Ç–≤–æ—Ä–µ–Ω–∏—è –ê–Ω–Ω—ã –§—Ä–∞–Ω–∫ –∏–∑ –≤–æ—Å—å–º–∏ —Å—Ç—Ä–æ—á–µ–∫ –ø—Ä–æ–¥–∞–Ω–∞ –∑–∞ 140 —Ç—ã—Å—è—á –µ–≤—Ä–æ.\\n\\n–°—Ç–∏—Ö–æ—Ç–≤–æ—Ä–µ–Ω–∏–µ, –¥–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –º–∞—Ä—Ç–æ–º 1942 –≥–æ–¥–∞, –±—ã–ª–æ –Ω–∞–ø–∏—Å–∞–Ω–æ –Ω–µ–∑–∞–¥–æ–ª–≥–æ –¥–æ —Ç–æ–≥–æ, –∫–∞–∫ –ê–Ω–Ω–µ –∏ –µ—ë —Å–µ–º—å–µ –ø—Ä–∏—à–ª–æ—Å—å —É–∫—Ä—ã—Ç—å—Å—è –æ—Ç –Ω–∞—Ü–∏—Å—Ç–æ–≤ –≤ —Å–µ–∫—Ä–µ—Ç–Ω–æ–π –∫–≤–∞—Ä—Ç–∏—Ä–µ –≤ –ê–º—Å—Ç–µ—Ä–¥–∞–º–µ.\\n\\n–ö —Å—Ç–∏—Ö–æ—Ç–≤–æ—Ä–µ–Ω–∏—é –ø—Ä–∏–ª–æ–∂–µ–Ω–æ –ø–∏—Å—å–º–æ –æ –µ–≥–æ –ø–æ–¥–ª–∏–Ω–Ω–æ—Å—Ç–∏ –∞–≤—Ç–æ—Ä—Å—Ç–≤–∞ —à–∫–æ–ª—å–Ω–æ–π –ø–æ–¥—Ä—É–≥–∏ –ê–Ω–Ω—ã, –ñ–∞–∫–ª–∏–Ω –≤–∞–Ω –ú–∞–∞—Ä—Å–µ–Ω. –°—Ç–∏—Ö–æ—Ç–≤–æ—Ä–µ–Ω–∏–µ –ø–æ—Å–≤—è—â–µ–Ω–æ —Å–µ—Å—Ç—Ä–µ –≤–∞–Ω –ú–∞–∞—Ä—Å–µ–Ω, –ö—Ä–∏—Å—Ç–∏–∞–Ω–µ.\\n\\n–°—Ç–∞—Ä—Ç–æ–≤–∞—è —Ü–µ–Ω–∞ –ª–æ—Ç–∞ —Å–æ—Å—Ç–∞–≤–∏–ª–∞ 50 —Ç—ã—Å—è—á –µ–≤—Ä–æ. –ú–∞–∞—Ç—å–µ –ú–æ—Å—Ç–∞—Ä—Ç, –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ–ª—å —Ñ–æ–Ω–¥–∞ –ê–Ω–Ω—ã –§—Ä–∞–Ω–∫, —Å–∫–∞–∑–∞–ª, —á—Ç–æ –ø–æ–¥–ª–∏–Ω–Ω–æ—Å—Ç—å —Ä—É–∫–æ–ø–∏—Å–∏ –Ω–µ –≤—ã–∑—ã–≤–∞–µ—Ç —Å–æ–º–Ω–µ–Ω–∏–π.\\n\\n–ò—Å—Ç–æ—Ä–∏—è –æ —Ç—Ä–∞–≥–∏—á–µ—Å–∫–æ–π —Å—É–¥—å–±–µ 15-–ª–µ—Ç–Ω–µ–π –µ–≤—Ä–µ–π—Å–∫–æ–π –¥–µ–≤–æ—á–∫–∏ –ê–Ω–Ω—ã –§—Ä–∞–Ω–∫ –æ–±–æ—à–ª–∞ –≤–µ—Å—å –º–∏—Ä. –ê–Ω–Ω–∞ –ø–æ–≥–∏–±–ª–∞ –≤ –Ω–∞—Ü–∏—Å—Ç—Å–∫–æ–º –∫–æ–Ω—Ü–ª–∞–≥–µ—Ä–µ –Ω–µ–∑–∞–¥–æ–ª–≥–æ –¥–æ –∫–æ–Ω—Ü–∞ –≤–æ–π–Ω—ã, –Ω–æ –µ—ë –æ—Ç–µ—Ü –û—Ç—Ç–æ –≤—ã–∂–∏–ª –∏ –ø–æ—Å–ª–µ –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏—è –∏–∑ –ª–∞–≥–µ—Ä—è –æ–ø—É–±–ª–∏–∫–æ–≤–∞–ª –µ—ë –¥–Ω–µ–≤–Ω–∏–∫.\\n\\n¬´–î–Ω–µ–≤–Ω–∏–∫ –ê–Ω–Ω—ã –§—Ä–∞–Ω–∫¬ª –ø—Ä–µ–≤—Ä–∞—Ç–∏–ª—Å—è –≤ –æ–¥–∏–Ω –∏–∑ —Å–∞–º—ã—Ö —è—Ä–∫–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤ –•–æ–ª–æ–∫–æ—Å—Ç–∞. –í 2009 –≥–æ–¥—É ¬´–î–Ω–µ–≤–Ω–∏–∫ –ê–Ω–Ω—ã –§—Ä–∞–Ω–∫¬ª –±—ã–ª –≤–Ω–µ—Å—ë–Ω –≤ —Å–ø–∏—Å–æ–∫ –í—Å–µ–º–∏—Ä–Ω–æ–≥–æ –º–µ–º–æ—Ä–∏–∞–ª—å–Ω–æ–≥–æ –Ω–∞—Å–ª–µ–¥–∏—è –Æ–ù–ï–°–ö–û.\\n</td>\n",
       "      <td>[–†—É–∫–æ–ø–∏—Å—å, –ê–Ω–Ω—ã, –§—Ä–∞–Ω–∫, –ê–Ω–Ω—ã, –§—Ä–∞–Ω–∫, —É—à–ª–∞, —Å, –º–æ–ª–æ—Ç–∫–∞, –∑–∞, 140, —Ç—ã—Å—è—á, –µ–≤—Ä–æ, –ê–Ω–Ω–∞, –§—Ä–∞–Ω–∫, –ù–∞, –∞—É–∫—Ü–∏–æ–Ω–µ, –≤, –ù–∏–¥–µ—Ä–ª–∞–Ω–¥–∞—Ö, —Ä—É–∫–æ–ø–∏—Å—å, —Å—Ç–∏—Ö–æ—Ç–≤–æ—Ä–µ–Ω–∏—è, –ê–Ω–Ω—ã, –§—Ä–∞–Ω–∫, –ê–Ω–Ω—ã, –§—Ä–∞–Ω–∫, –∏–∑, –≤–æ—Å—å–º–∏, —Å—Ç—Ä–æ—á–µ–∫, –ø—Ä–æ–¥–∞–Ω–∞, –∑–∞, 140, —Ç—ã—Å—è—á, –µ–≤—Ä–æ, ., –°—Ç–∏—Ö–æ—Ç–≤–æ—Ä–µ–Ω–∏–µ,, –¥–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ, –º–∞—Ä—Ç–æ–º, 1942, –≥–æ–¥–∞, ,, –±—ã–ª–æ, –Ω–∞–ø–∏—Å–∞–Ω–æ, –Ω–µ–∑–∞–¥–æ–ª–≥–æ, –¥–æ, —Ç–æ–≥–æ,, –∫–∞–∫, –ê–Ω–Ω–µ, –∏, –µ—ë, —Å–µ–º—å–µ, –ø—Ä–∏—à–ª–æ—Å—å, —É–∫—Ä—ã—Ç—å—Å—è, –æ—Ç, –Ω–∞—Ü–∏—Å—Ç–æ–≤, –≤, —Å–µ–∫—Ä–µ—Ç–Ω–æ–π, –∫–≤–∞—Ä—Ç–∏—Ä–µ, –≤, –ê–º—Å—Ç–µ—Ä–¥–∞–º–µ, ., –ö, —Å—Ç–∏—Ö–æ—Ç–≤–æ—Ä–µ–Ω–∏—é, –ø—Ä–∏–ª–æ–∂–µ–Ω–æ, –ø–∏—Å—å–º–æ, –æ, –µ–≥–æ, –ø–æ–¥–ª–∏–Ω–Ω–æ—Å—Ç–∏, –∞–≤—Ç–æ—Ä—Å—Ç–≤–∞, —à–∫–æ–ª—å–Ω–æ–π, –ø–æ–¥—Ä—É–≥–∏, –ê–Ω–Ω—ã, ,, –ñ–∞–∫–ª–∏–Ω, –≤–∞–Ω, –ú–∞–∞—Ä—Å–µ–Ω, ., –°—Ç–∏—Ö–æ—Ç–≤–æ—Ä–µ–Ω–∏–µ, –ø–æ—Å–≤—è—â–µ–Ω–æ, —Å–µ—Å—Ç—Ä–µ, –≤–∞–Ω, –ú–∞–∞—Ä—Å–µ–Ω, ,, –ö—Ä–∏—Å—Ç–∏–∞–Ω–µ, ., –°—Ç–∞—Ä—Ç–æ–≤–∞—è, —Ü–µ–Ω–∞, –ª–æ—Ç–∞, —Å–æ—Å—Ç–∞–≤–∏–ª–∞, 50, —Ç—ã—Å—è—á, –µ–≤—Ä–æ, ., –ú–∞–∞—Ç—å–µ, –ú–æ—Å—Ç–∞—Ä—Ç, ,, –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ–ª—å, —Ñ–æ–Ω–¥–∞, –ê–Ω–Ω—ã, –§—Ä–∞–Ω–∫, —Ñ–æ–Ω–¥–∞, –ê–Ω–Ω—ã, ...]</td>\n",
       "      <td>[B-WORK_OF_ART, I-WORK_OF_ART, I-WORK_OF_ART, B-PERSON, I-PERSON, B-EVENT, I-EVENT, I-EVENT, O, B-MONEY, I-MONEY, I-MONEY, B-PERSON, I-PERSON, O, O, O, B-COUNTRY, B-WORK_OF_ART, I-WORK_OF_ART, I-WORK_OF_ART, I-WORK_OF_ART, B-PERSON, I-PERSON, O, B-NUMBER, O, B-EVENT, O, B-MONEY, I-MONEY, I-MONEY, O, O, O, B-DATE, I-DATE, I-DATE, O, O, O, O, O, O, O, B-PERSON, O, O, O, O, O, O, B-IDEOLOGY, O, O, O, O, B-CITY, O, O, O, O, O, O, O, O, O, O, O, B-PERSON, O, B-PERSON, I-PERSON, I-PERSON, O, O, O, O, B-PERSON, I-PERSON, O, B-PERSON, O, O, O, O, O, B-MONEY, I-MONEY, I-MONEY, O, B-PERSON, I-PERSON, O, B-PROFESSION, I-PROFESSION, I-PROFESSION, I-PROFESSION, B-ORGANIZATION, I-ORGANIZATION, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>–ö–æ—Ä–æ–ª—å –ë–µ–ª—å–≥–∏–∏ –ê–ª—å–±–µ—Ä—Ç II –æ—Ç—Ä—ë–∫—Å—è –æ—Ç –ø—Ä–µ—Å—Ç–æ–ª–∞ –≤ –ø–æ–ª—å–∑—É —Å—ã–Ω–∞\\n\\n\\n–°–µ–≥–æ–¥–Ω—è, –≤ –¥–µ–Ω—å –ù–∞—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ –ø—Ä–∞–∑–¥–Ω–∏–∫–∞ –ë–µ–ª—å–≥–∏–∏, –∫–æ—Ä–æ–ª—å –ê–ª—å–±–µ—Ä—Ç II –ø–æ–¥–ø–∏—Å–∞–ª –∞–∫—Ç –æ–± –æ—Ç—Ä–µ—á–µ–Ω–∏–∏ –æ—Ç –ø—Ä–µ—Å—Ç–æ–ª–∞ –≤ –ø–æ–ª—å–∑—É —Å–≤–æ–µ–≥–æ —Å—ã–Ω–∞ –ø—Ä–∏–Ω—Ü–∞ –§–∏–ª–∏–ø–ø–∞. –§–∏–ª–∏–ø–ø —Å—Ç–∞–Ω–µ—Ç —Å–µ–¥—å–º—ã–º –ø–æ —Å—á—ë—Ç—É –∫–æ—Ä–æ–ª—ë–º –ë–µ–ª—å–≥–∏–∏.\\n\\n–û–± –æ—Ç—Ä–µ—á–µ–Ω–∏–∏ 79-–ª–µ—Ç–Ω–∏–π –º–æ–Ω–∞—Ä—Ö –∑–∞—è–≤–∏–ª –µ—â—ë 3 –∏—é–ª—è –≤ –ø—Ä—è–º–æ–º —ç—Ñ–∏—Ä–µ –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —Ç–µ–ª–µ–≤–∏–¥–µ–Ω–∏—è. –°–≤–æ—ë —Ä–µ—à–µ–Ω–∏–µ –æ–Ω –æ–±—ä—è—Å–Ω–∏–ª –ø—Ä–µ–∫–ª–æ–Ω–Ω—ã–º –≤–æ–∑—Ä–∞—Å—Ç–æ–º –∏ –ø—Ä–æ–±–ª–µ–º–∞–º–∏ —Å–æ –∑–¥–æ—Ä–æ–≤—å–µ–º.\\n\\n–¶–µ—Ä–µ–º–æ–Ω–∏—è –ø–µ—Ä–µ–¥–∞—á–∏ –≤–ª–∞—Å—Ç–∏ –ø—Ä–æ—à–ª–∞ –æ—Ç –ê–ª—å–±–µ—Ä—Ç–∞ –∫ –§–∏–ª–∏–ø–ø—É –ø—Ä–æ—à–ª–∞ –≤ –ö–æ—Ä–æ–ª–µ–≤—Å–∫–æ–º –¥–≤–æ—Ä—Ü–µ –ë—Ä—é—Å—Å–µ–ª—è. –ù–∞ —Ü–µ—Ä–µ–º–æ–Ω–∏–∏ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤–æ–≤–∞–ª–∏ —á–ª–µ–Ω—ã –º–æ–Ω–∞—Ä—à–µ–π —Å–µ–º—å–∏ –∏ —Ñ–µ–¥–µ—Ä–∞–ª—å–Ω–æ–≥–æ –ø—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–∞ –ë–µ–ª—å–≥–∏–∏.\\n\\n–ü–æ–∑–∂–µ —Å–∞–º –§–∏–ª–∏–ø–ø –ø—Ä–∏–Ω—ë—Å –∫–ª—è—Ç–≤—É –Ω–∞ –≤–µ—Ä–Ω–æ—Å—Ç—å –∫–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏–∏ –∏ –Ω–∞—Ä–æ–¥—É –ø–µ—Ä–µ–¥ —á–ª–µ–Ω–∞–º–∏ –æ–±–µ–∏—Ö –ø–∞–ª–∞—Ç —Ñ–µ–¥–µ—Ä–∞–ª—å–Ω–æ–≥–æ –ø–∞—Ä–ª–∞–º–µ–Ω—Ç–∞. 53-–ª–µ—Ç–Ω–∏–π –ø—Ä–∏–Ω—Ü –ø–æ–ª—É—á–∏–ª –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ –û–∫—Å—Ñ–æ—Ä–¥—Å–∫–æ–º –∏ –°—Ç—ç–Ω—Ñ–æ—Ä–¥—Å–∫–æ–º —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–∞—Ö. –û–Ω —Ç–∞–∫–∂–µ –ø—Ä–æ—à—ë–ª –ª—ë—Ç–Ω—É—é –ø–æ–¥–≥–æ—Ç–æ–≤–∫—É –≤ –∫–∞—á–µ—Å—Ç–≤–µ –ø–∏–ª–æ—Ç–∞ –±–µ–ª—å–≥–∏–π—Å–∫–∏—Ö –≤–æ–µ–Ω–Ω–æ-–≤–æ–∑–¥—É—à–Ω—ã—Ö —Å–∏–ª. –£ –Ω–µ–≥–æ –∏ —É –µ–≥–æ –∂–µ–Ω—ã ‚Äî –ú–∞—Ç–∏–ª—å–¥—ã ‚Äî —á–µ—Ç–≤–µ—Ä–æ –¥–µ—Ç–µ–π.\\n\\n–ù–∞–∫–∞–Ω—É–Ω–µ, 20 –∏—é–ª—è, –∫–æ—Ä–æ–ª—å –ê–ª—å–±–µ—Ä—Ç II –≤—ã—Å—Ç—É–ø–∏–ª —Å —Ç–µ–ª–µ–æ–±—Ä–∞—â–µ–Ω–∏–µ–º –∫ –±–µ–ª—å–≥–∏–π—Ü–∞–º. –û–Ω –ø–æ–±–ª–∞–≥–æ–¥–∞—Ä–∏–ª –Ω–∞—Ä–æ–¥ –∑–∞ –ø—Ä–∏–≤—è–∑–∞–Ω–Ω–æ—Å—Ç—å –∏ –ø–æ–¥–¥–µ—Ä–∂–∫—É –≤ —Ç–µ—á–µ–Ω–∏–µ 20 –ª–µ—Ç, –±—É–¥—É—á–∏ –∫–æ—Ä–æ–ª—ë–º —Å—Ç—Ä–∞–Ω—ã. –ê–ª—å–±–µ—Ä—Ç II –ø–æ–≤–µ–ª–µ–ª –æ–∫–∞–∑–∞—Ç—å ¬´–≤—Å–µ–º–µ—Ä–Ω—É—é –ø–æ–º–æ—â—å –∏ –ø–æ–¥–¥–µ—Ä–∂–∫—É –±—É–¥—É—â–∏–º –∫–æ—Ä–æ–ª—é –§–∏–ª–∏–ø–ø—É –∏ –∫–æ—Ä–æ–ª–µ–≤–µ –ú–∞—Ç–∏–ª—å–¥–µ¬ª. –ú–æ–Ω–∞—Ä—Ö —Ç–∞–∫–∂–µ –ø—Ä–∏–∑–≤–∞–ª –±–µ–ª—å–≥–∏–π—Ü–µ–≤ –∫ –µ–¥–∏–Ω—Å—Ç–≤—É, –ø–æ–¥—á–µ—Ä–∫–Ω—É–≤ –µ—ë ¬´—Ü–µ–Ω–Ω–æ–µ –¥–µ–º–æ–∫—Ä–∞—Ç–∏—á–µ—Å–∫–æ–µ –±–æ–≥–∞—Ç—Å—Ç–≤–æ¬ª ‚Äî –ø–ª—é—Ä–∞–ª–∏–∑–º:\\n–î–∞–≤–∞–π—Ç–µ –ø—Ä–æ–¥–æ–ª–∂–∏–º –∫—Ä–µ–ø–∫–æ –≤–µ—Ä–∏—Ç—å –≤ –ï–≤—Ä–æ–ø—É. –í –Ω–∞—à–µ–º –º–∏—Ä–µ –µ–≤—Ä–æ–ø–µ–π—Å–∫–æ–µ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–æ (—Å–æ–∑–∏–¥–∞–Ω–∏–µ) –±–æ–ª–µ–µ —á–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ. –í–æ –º–Ω–æ–≥–∏—Ö —Å—Ñ–µ—Ä–∞—Ö –º—ã –º–æ–∂–µ–º –¥–æ—Å—Ç–∏—á—å –Ω–∞—à–∏—Ö —Ü–µ–ª–µ–π —Ç–æ–ª—å–∫–æ –Ω–∞ –æ–±—â–µ–µ–≤—Ä–æ–ø–µ–π—Å–∫–æ–º —É—Ä–æ–≤–Ω–µ.\\n</td>\n",
       "      <td>[–ö–æ—Ä–æ–ª—å, –ö–æ—Ä–æ–ª—å, –ë–µ–ª—å–≥–∏–∏, –ë–µ–ª—å–≥–∏–∏, –ê–ª—å–±–µ—Ä—Ç, II, II, –æ—Ç—Ä—ë–∫—Å—è, –æ—Ç, –ø—Ä–µ—Å—Ç–æ–ª–∞, –≤, –ø–æ–ª—å–∑—É, —Å—ã–Ω–∞, –°–µ–≥–æ–¥–Ω—è, ,, –≤, –¥–µ–Ω—å, –ù–∞—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ, –ø—Ä–∞–∑–¥–Ω–∏–∫–∞, –ë–µ–ª—å–≥–∏–∏, –ù–∞—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ, –ø—Ä–∞–∑–¥–Ω–∏–∫–∞, –ë–µ–ª—å–≥–∏–∏, ,, –∫–æ—Ä–æ–ª—å, –ê–ª—å–±–µ—Ä—Ç, II, II, –ø–æ–¥–ø–∏—Å–∞–ª, –∞–∫—Ç, –æ–±, –æ—Ç—Ä–µ—á–µ–Ω–∏–∏, –æ—Ç, –ø—Ä–µ—Å—Ç–æ–ª–∞, –≤, –ø–æ–ª—å–∑—É, —Å–≤–æ–µ–≥–æ, —Å—ã–Ω–∞, –ø—Ä–∏–Ω—Ü–∞, –§–∏–ª–∏–ø–ø–∞, ., –§–∏–ª–∏–ø–ø, —Å—Ç–∞–Ω–µ—Ç, —Å–µ–¥—å–º—ã–º, –ø–æ, —Å—á—ë—Ç—É, –∫–æ—Ä–æ–ª—ë–º, –∫–æ—Ä–æ–ª—ë–º, –ë–µ–ª—å–≥–∏–∏, –ë–µ–ª—å–≥–∏–∏, ., –û–±, –æ—Ç—Ä–µ—á–µ–Ω–∏–∏, 79-–ª–µ—Ç–Ω–∏–π, –º–æ–Ω–∞—Ä—Ö, –∑–∞—è–≤–∏–ª, –µ—â—ë, 3, –∏—é–ª—è, –≤, –ø—Ä—è–º–æ–º, —ç—Ñ–∏—Ä–µ, –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ, —Ç–µ–ª–µ–≤–∏–¥–µ–Ω–∏—è., –°–≤–æ—ë, —Ä–µ—à–µ–Ω–∏–µ, –æ–Ω, –æ–±—ä—è—Å–Ω–∏–ª, –ø—Ä–µ–∫–ª–æ–Ω–Ω—ã–º, –≤–æ–∑—Ä–∞—Å—Ç–æ–º, –∏, –ø—Ä–æ–±–ª–µ–º–∞–º–∏, —Å–æ, –∑–¥–æ—Ä–æ–≤—å–µ–º., –¶–µ—Ä–µ–º–æ–Ω–∏—è, –ø–µ—Ä–µ–¥–∞—á–∏, –≤–ª–∞—Å—Ç–∏, –ø—Ä–æ—à–ª–∞, –æ—Ç, –ê–ª—å–±–µ—Ä—Ç–∞, –∫, –§–∏–ª–∏–ø–ø—É, –ø—Ä–æ—à–ª–∞, –≤, –ö–æ—Ä–æ–ª–µ–≤—Å–∫–æ–º, –¥–≤–æ—Ä—Ü–µ, –ö–æ—Ä–æ–ª–µ–≤—Å–∫–æ–º, –¥–≤–æ—Ä—Ü–µ, –ë—Ä—é—Å—Å–µ–ª—è, –ë—Ä—é—Å—Å–µ–ª—è, ., –ù–∞, —Ü–µ—Ä–µ–º–æ–Ω–∏–∏, –ø—Ä–∏—Å—É—Ç—Å—Ç–≤–æ–≤–∞–ª–∏, —á–ª–µ–Ω—ã, –º–æ–Ω–∞—Ä—à–µ–π, —Å–µ–º—å–∏, –º–æ–Ω–∞—Ä—à–µ–π, —Å–µ–º—å–∏, –∏, ...]</td>\n",
       "      <td>[B-PROFESSION, B-PROFESSION, I-PROFESSION, B-COUNTRY, B-PERSON, I-PERSON, B-ORDINAL, B-EVENT, I-EVENT, I-EVENT, O, O, O, B-DATE, O, B-DATE, I-DATE, B-EVENT, I-EVENT, I-EVENT, B-EVENT, I-EVENT, B-COUNTRY, O, B-PROFESSION, B-PERSON, I-PERSON, B-ORDINAL, B-EVENT, I-EVENT, O, B-EVENT, I-EVENT, I-EVENT, O, O, O, O, B-PROFESSION, B-PERSON, O, B-PERSON, O, B-ORDINAL, O, O, B-PROFESSION, B-PROFESSION, I-PROFESSION, B-COUNTRY, O, O, B-EVENT, B-AGE, B-PROFESSION, O, O, B-DATE, I-DATE, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-EVENT, I-EVENT, I-EVENT, O, O, B-PERSON, O, B-PERSON, O, O, B-FACILITY, I-FACILITY, B-FACILITY, I-FACILITY, I-FACILITY, B-CITY, O, O, B-EVENT, O, B-PROFESSION, B-FAMILY, I-FAMILY, B-PROFESSION, O, O, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>–°—É—Ä–∫–æ–≤ –ø–æ–¥–∞–ª –≤ –æ—Ç—Å—Ç–∞–≤–∫—É\\n–í–ª–∞–¥–∏—Å–ª–∞–≤ –°—É—Ä–∫–æ–≤\\n8 –º–∞—è 2013 –≥–æ–¥–∞ –ü—Ä–µ–∑–∏–¥–µ–Ω—Ç –†–æ—Å—Å–∏–∏ –í–ª–∞–¥–∏–º–∏—Ä –ü—É—Ç–∏–Ω –ø–æ–¥–ø–∏—Å–∞–ª –£–∫–∞–∑ ¬´–û –°—É—Ä–∫–æ–≤–µ –í. –Æ.¬ª, –∫–æ—Ç–æ—Ä—ã–º –æ—Ç–ø—Ä–∞–≤–∏–ª —á–∏–Ω–æ–≤–Ω–∏–∫–∞ –≤ –æ—Ç—Å—Ç–∞–≤–∫—É:\\n –í —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å –ø—É–Ω–∫—Ç–æ–º –¥ —Å—Ç–∞—Ç—å–∏ 83 –ö–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏–∏ –†–æ—Å—Å–∏–π—Å–∫–æ–π –§–µ–¥–µ—Ä–∞—Ü–∏–∏ –æ—Å–≤–æ–±–æ–¥–∏—Ç—å –°—É—Ä–∫–æ–≤–∞ –í–ª–∞–¥–∏—Å–ª–∞–≤–∞ –Æ—Ä—å–µ–≤–∏—á–∞ –æ—Ç –¥–æ–ª–∂–Ω–æ—Å—Ç–∏ –ó–∞–º–µ—Å—Ç–∏—Ç–µ–ª—è –ü—Ä–µ–¥—Å–µ–¥–∞—Ç–µ–ª—è –ü—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–∞ –†–æ—Å—Å–∏–π—Å–∫–æ–π –§–µ–¥–µ—Ä–∞—Ü–∏–∏ –†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è –ê–ø–ø–∞—Ä–∞—Ç–∞ –ü—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–∞ –†–æ—Å—Å–∏–π—Å–∫–æ–π –§–µ–¥–µ—Ä–∞—Ü–∏–∏ –ø–æ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–º—É –∂–µ–ª–∞–Ω–∏—é \\n\\n–ü—Ä–µ—Å—Å-—Å–µ–∫—Ä–µ—Ç–∞—Ä—å –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç–∞ –î–º–∏—Ç—Ä–∏–π –ü–µ—Å–∫–æ–≤ —Å–æ–æ–±—â–∏–ª, —á—Ç–æ –°—É—Ä–∫–æ–≤ –ø–æ–¥–∞–ª –≤ –æ—Ç—Å—Ç–∞–≤–∫—É –ø–æ—Å–ª–µ —Å–æ–≤–µ—â–∞–Ω–∏—è —Å –≥–ª–∞–≤–æ–π –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–∞ –ø–æ –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—é –º–∞–π—Å–∫–∏—Ö —É–∫–∞–∑–æ–≤:\\n–†–µ—à–µ–Ω–∏–µ –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç–∞ –æ –ø–æ–¥–ø–∏—Å–∞–Ω–∏–∏ –∑–∞—è–≤–ª–µ–Ω–∏—è —Å–≤—è–∑–∞–Ω–æ —Å —Ç–µ–º–∞—Ç–∏–∫–æ–π –ø–µ—Ä–≤–æ–æ—á–µ—Ä–µ–¥–Ω—ã—Ö –∑–∞–¥–∞—á –ø–æ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –º–∞–π—Å–∫–∏—Ö —É–∫–∞–∑–æ–≤ –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç–∞ –∏ –ø—Ä–µ–¥–≤—ã–±–æ—Ä–Ω—ã—Ö –æ–±–µ—â–∞–Ω–∏–π, –∏ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–∏ –≤ –ë–µ–ª–æ–º –¥–æ–º–µ –∫–æ–º–∏—Å—Å–∏–∏, –∫–æ—Ç–æ—Ä–∞—è –∑–∞–Ω–∏–º–∞–ª–∞—Å—å —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–µ–π —ç—Ç–∏—Ö —É–∫–∞–∑–æ–≤.\\n\\n–ü—Ä–∏—á—ë–º –≤ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è—Ö –°–ú–ò –æ–Ω –ø–æ–¥—á—ë—Ä–∫–∏–≤–∞–ª, —á—Ç–æ –°—É—Ä–∫–æ–≤ —É—à—ë–ª —Å–æ —Å–≤–æ–µ–≥–æ –ø–æ—Å—Ç–∞ –ø–æ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–º—É –∂–µ–ª–∞–Ω–∏—é:\\n–ü—Ä–µ–∑–∏–¥–µ–Ω—Ç —É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏–ª –ø—Ä–æ—Å—å–±—É –°—É—Ä–∫–æ–≤–∞ –æ–± —É–≤–æ–ª—å–Ω–µ–Ω–∏–∏ –ø–æ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–º—É –∂–µ–ª–∞–Ω–∏—é. –≠—Ç–∞ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∞ –≤–∫–ª—é—á–µ–Ω–∞ –≤ —Ç–µ–∫—Å—Ç —É–∫–∞–∑–∞.\\n\\n–í–ª–∞–¥–∏–º–∏—Ä –ú–∞—Ä–∫–∏–Ω\\n–ó–∞–º–µ—á–∞–Ω–∏–µ –ø—Ä–µ—Å—Å-—Å–µ–∫—Ä–µ—Ç–∞—Ä—è –ø—Ä–æ–∑–≤—É—á–∞–ª–æ –≤–∞–∂–Ω–æ –µ—â—ë –∏ –≤ —Ä–∞–∑—Ä–µ–∑–µ –¥–æ—Å—Ç–∏–≥—à–µ–≥–æ –≤—á–µ—Ä–∞ –ø–∏–∫–∞ –∫–æ–Ω—Ñ–ª–∏–∫—Ç–∞ –º–µ–∂–¥—É –í–ª–∞–¥–∏—Å–ª–∞–≤–æ–º –°—É—Ä–∫–æ–≤—ã–º –∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ–ª—è –°–ª–µ–¥—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∫–æ–º–∏—Ç–µ—Ç–∞ –†–æ—Å—Å–∏–∏ –í–ª–∞–¥–∏–º–∏—Ä–∞ –ú–∞—Ä–∫–∏–Ω–∞.\\n–ò–º–µ–Ω–Ω–æ —Å –Ω–∏–º –ø–µ—Ä–≤–æ–Ω–∞—á–∞–ª—å–Ω–æ –∂—É—Ä–Ω–∞–ª–∏—Å—Ç—ã —Å–≤—è–∑—ã–≤–∞–ª–∏ –æ—Ç—Å—Ç–∞–≤–∫—É.\\n\\n–ù–µ—Å–∫–æ–ª—å–∫–æ –¥–Ω–µ–π –Ω–∞–∑–∞–¥ –≤ —Ö–æ–¥–µ –≤—ã—Å—Ç—É–ø–ª–µ–Ω–∏—è –≤ –õ–æ–Ω–¥–æ–Ω—Å–∫–æ–π —à–∫–æ–ª–µ —ç–∫–æ–Ω–æ–º–∏–∫–∏ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –∞–ø–ø–∞—Ä–∞—Ç–∞ –ü—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–∞ —Å–¥–µ–ª–∞–ª –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω–æ —Å–∫–∞–Ω–¥–∞–ª—å–Ω–æ–µ –∑–∞—è–≤–ª–µ–Ω–∏–µ, —Ä–∞—Å–∫—Ä–∏—Ç–∏–∫–æ–≤–∞–≤ —Ä–∞–±–æ—Ç—É —Å–ª–µ–¥—Å—Ç–≤–µ–Ω–Ω—ã—Ö –æ—Ä–≥–∞–Ω–æ–≤ –ø–æ –¥–µ–ª—É –∫–æ—Ä—Ä—É–ø—Ü–∏–∏ –∏ —Ä–∞—Å—Ç—Ä–∞—Ç–∞—Ö –≤ ¬´–°–∫–æ–ª–∫–æ–≤–æ¬ª:\\n–°–ö —Å–ª–∏—à–∫–æ–º —Ç–æ—Ä–æ–ø–∏—Ç—Å—è, —Ç–∞–∫ –≥—Ä–æ–º–∫–æ –∑–∞—è–≤–ª—è—è –æ –∑–ª–æ—É–ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è—Ö¬ª –≤ ¬´–°–∫–æ–ª–∫–æ–≤–æ¬ª. —Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ —Å–≤–æ–µ–π —ç–Ω–µ—Ä–≥–∏—á–Ω–æ–π —Ä–∞–±–æ—Ç–æ–π –ø–æ–¥—Ä—ã–≤–∞—é—Ç —Ä–µ–ø—É—Ç–∞—Ü–∏—é —Ñ–æ–Ω–¥–∞.\\n\\n–í –æ—Ç–≤–µ—Ç –í–ª–∞–¥–∏–º–∏—Ä –ú–∞—Ä–∫–∏–Ω –æ–ø—É–±–ª–∏–∫–æ–≤–∞–ª —Å—Ç–∞—Ç—å—é –≤ ¬´–ò–∑–≤–µ—Å—Ç–∏—è—Ö¬ª –ø–æ–¥ –∑–∞–≥–æ–ª–æ–≤–∫–æ–º ¬´–ì–ª—è–¥—è –∏–∑ –õ–æ–Ω–¥–æ–Ω–∞, –Ω–µ—á–∞ –Ω–∞ –∑–µ—Ä–∫–∞–ª–æ –ø–µ–Ω—è—Ç—å¬ª, –≥–¥–µ –∂—ë—Å—Ç–∫–æ –æ—Ç–≤–µ—Ç–∏–ª –°—É—Ä–∫–æ–≤—É:\\n–ù—É–∂–Ω–æ –∑–∞–º–µ—Ç–∏—Ç—å, —á—Ç–æ –Ω—ã–Ω—á–µ —É ¬´—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã—Ö –º–µ–Ω–µ–¥–∂–µ—Ä–æ–≤¬ª –Ω–æ–≤–∞—è –º–æ–¥–∞. –ß—É—Ç—å –≥–¥–µ –æ–±—ã—Å–∫ –≤ –º–Ω–æ–≥–æ—ç—Ç–∞–∂–Ω—ã—Ö —Ö–æ—Ä–æ–º–∞—Ö –≤–∏—Ü–µ-–≥—É–±–µ—Ä–Ω–∞—Ç–æ—Ä–∞ –Ω–µ–±–æ–≥–∞—Ç–æ–π –æ–±–ª–∞—Å—Ç–∏, —Ç–∞–∫ —Å—Ä–∞–∑—É –µ–≥–æ –∫–æ–ª–ª–µ–≥–∏ –∫—Ä–∏—á–∞—Ç –æ –ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–æ–º –∑–∞–∫–∞–∑–µ, —Å–∞—Ç—Ä–∞–ø–∞—Ö –∏–∑ –°–ª–µ–¥—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∫–æ–º–∏—Ç–µ—Ç–∞ –∏ –∏–∑ –°—á–µ—Ç–Ω–æ–π –ø–∞–ª–∞—Ç—ã. –ú–æ–¥–Ω–æ –Ω—ã–Ω—á–µ –±—ã—Ç—å —Å—É–≥—É–±–æ –ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–∏–º —É–∑–Ω–∏–∫–æ–º, —Å—Ä–∞–∑—É –º–æ–∂–Ω–æ —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞—Ç—å –Ω–∞ –≤–Ω–∏–º–∞–Ω–∏–µ BBC, –∞ —Ç–æ –∏ –Ω–∞ –ø–æ–¥–¥–µ—Ä–∂–∫—É Amnesty International. –í–æ–∑–º–æ–∂–Ω–æ, –∏–º–µ–Ω–Ω–æ –ø–æ—ç—Ç–æ–º—É –∫—É—Ä–∞—Ç–æ—Ä—ã –æ—Å–æ–±–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã—Ö –º–µ–Ω–µ–¥–∂–µ—Ä–æ–≤ –ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞—é—Ç –≤—ã—Å—Ç—É–ø–∞—Ç—å —Å –∞—Ä–∏–µ–π –º–æ—Å–∫–æ–≤—Å–∫–æ–≥–æ –≥–æ—Å—Ç—è —Å—Ä–∞–∑—É –≤ –õ–æ–Ω–¥–æ–Ω–µ, —Å—Ä–µ–¥–∏ —Ü–µ–ª–µ–≤–æ–π –∞—É–¥–∏—Ç–æ—Ä–∏–∏. –≠—Ç–æ—Ç —Å—Ç–æ–Ω —É –Ω–∏—Ö –ø–µ—Å–Ω–µ–π –∑–æ–≤–µ—Ç—Å—è. –ò –ø–µ—Å–Ω—è-—Ç–æ –∫–∞–∫–∞—è –∂–∞–ª–æ—Å—Ç–ª–∏–≤–∞—è...\\n\\n–í–ª–∞–¥–∏—Å–ª–∞–≤ –°—É—Ä–∫–æ–≤\\n–í–ª–∞–¥–∏–º–∏—Ä –ü—É—Ç–∏–Ω\\n–í—á–µ—Ä–∞ –°—É—Ä–∫–æ–≤ –ø—Ä–µ–Ω–µ–±—Ä–µ–∂–∏—Ç–µ–ª—å–Ω–æ –æ—Ç–æ–∑–≤–∞–ª—Å—è –æ —Å—Ç–∞—Ç—å–µ –ú–∞—Ä–∫–∏–Ω–∞, —Å–∫–∞–∑–∞–≤ –∂—É—Ä–Ω–∞–ª–∏—Å—Ç–∞–º:\\n–Ø –≥—Ä–∞—Ñ–æ–º–∞–Ω–∏—é –Ω–µ –∫–æ–º–º–µ–Ω—Ç–∏—Ä—É—é.\\n\\n–ü–æ–∑–∂–µ –í–ª–∞–¥–∏—Å–ª–∞–≤ –æ—Å—Ç–∞–≤–∏–ª –≤ —Å–≤–æ—ë–º –º–∏–∫—Ä–æ–±–ª–æ–≥–µ –≤ –¢–≤–∏—Ç—Ç–µ—Ä –∑–∞–ø–∏—Å—å, –∫–æ—Ç–æ—Ä–∞—è –º–≥–Ω–æ–≤–µ–Ω–Ω–æ –ø—Ä–µ–≤—Ä–∞—Ç–∏–ª–∞—Å—å –≤ –∞–Ω–µ–∫–¥–æ—Ç:\\n–ó–≤–æ–Ω–∏–ª –ú–∞—Ä–∫–∏–Ω. –°–ø—Ä–æ—Å–∏–ª, –ø–æ—á–µ–º—É —è –Ω–∞–∑–≤–∞–ª –µ–≥–æ —Ç–≤–æ—Ä–µ–Ω–∏–µ –≥—Ä–∞—Ñ–æ–º–∞–Ω–∏–µ–π, –≤–µ–¥—å –æ–Ω –∂–µ –Ω–µ –≥—Ä–∞—Ñ... –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∏–∑–ª–∏—à–Ω–∏.\\n\\n–î–º–∏—Ç—Ä–∏–π –ü–µ—Å–∫–æ–≤\\n–û–¥–Ω–∞–∫–æ –ü–µ—Å–∫–æ–≤ –Ω–∞—Å—Ç–∞–∏–≤–∞–µ—Ç –Ω–∞ –¥—Ä—É–≥–æ–π –≤–µ—Ä—Å–∏–∏ –ø—Ä–∏—á–∏–Ω –æ—Ç—Å—Ç–∞–≤–∫–∏.\\n\\n–í—á–µ—Ä–∞, 7 –º–∞—è 2013 –≥–æ–¥–∞, –í–ª–∞–¥–∏–º–∏—Ä –ü—É—Ç–∏–Ω –ø—Ä–æ–≤—ë–ª —Å–æ–≤–µ—â–∞–Ω–∏–µ —Å —á–ª–µ–Ω–∞–º–∏ –ø—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–∞, –Ω–∞ –∫–æ—Ç–æ—Ä–æ–º —Ä–∞—Å–∫—Ä–∏—Ç–∏–∫–æ–≤–∞–ª —á–∏–Ω–æ–≤–Ω–∏–∫–æ–≤ –∑–∞ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—É—é –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –≤ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ —Å–≤–æ–∏—Ö –º–∞–π—Å–∫–∏—Ö —É–∫–∞–∑–æ–≤.–ü—Ä–∏—Å—É—Ç—Å—Ç–≤–æ–≤–∞–≤—à–∏–π –Ω–∞ –∑–∞—Å–µ–¥–∞–Ω–∏–∏ –°—É—Ä–∫–æ–≤ –Ω–µ —Å–æ–≥–ª–∞—Å–∏–ª—Å—è —Å –í–ª–∞–¥–∏–º–∏—Ä–æ–º –ü—É—Ç–∏–Ω—ã –ø–æ –Ω–µ–∫–æ—Ç–æ—Ä—ã–º –≤–æ–ø—Ä–æ—Å–∞–º, –≤—Å—Ç—É–ø–∏–≤ —Å –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç–æ–º –≤ –ø–æ–ª–µ–º–∏–∫—É.\\n–¢–µ–º –Ω–µ –º–µ–Ω–µ–µ –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º —Å–æ–≤–µ—â–∞–Ω–∏—è –°—É—Ä–∫–æ–≤ –∑–∞–≤–µ—Ä–∏–ª –ü—É—Ç–∏–Ω–∞, —á—Ç–æ –ø—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–æ —Å–æ–≤–º–µ—Å—Ç–Ω–æ —Å –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ü–∏–µ–π –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç–∞ —Å–¥–µ–ª–∞–µ—Ç –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ–µ –¥–ª—è —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è –Ω–µ–¥–æ—Å—Ç–∞—Ç–∫–æ–≤ –≤ —ç—Ç–æ–π —Å—Ñ–µ—Ä–µ.\\n\\n–°–∞–º –í–ª–∞–¥–∏—Å–ª–∞–≤ –°—É—Ä–∫–æ–≤ –∑–∞—è–≤–∏–ª, —á—Ç–æ –∑–∞—è–≤–ª–µ–Ω–∏–µ –æ–± –æ—Ç—Å—Ç–∞–≤–∫–µ –ø–æ–¥–∞–ª –µ—â—ë 26 –∞–ø—Ä–µ–ª—è 2013 –≥–æ–¥–∞, –æ–¥–Ω–∞–∫–æ –Ω–µ —Å—Ç–∞–ª —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—è—Ç—å—Å—è –æ –ø—Ä–∏—á–∏–Ω–∞—Ö, —Å–∫–∞–∑–∞–≤ –ª–∏—à—å —á—Ç–æ —Å–æ–æ–±—â–∏—Ç –æ–± —ç—Ç–æ–º, –∫–æ–≥–¥–∞ —Å—Ç–∞–Ω–µ—Ç –≤–æ–∑–º–æ–∂–Ω–æ.\\n–≠—Ç—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ–¥—Ç–≤–µ—Ä–¥–∏–ª–∞ –ø—Ä–µ—Å—Å-—Å–µ–∫—Ä–µ—Ç–∞—Ä—å –ø—Ä–µ–º—å–µ—Ä–∞ –ù–∞—Ç–∞–ª—å—è –¢–∏–º–∞–∫–æ–≤–∞, —Å–æ–æ–±—â–∏–≤, —á—Ç–æ –î–º–∏—Ç—Ä–∏–π –ú–µ–¥–≤–µ–¥–µ–≤ –±—ã–ª –≤ –∫—É—Ä—Å–µ –≤–æ–∑–º–æ–∂–Ω–æ–π –æ—Ç—Å—Ç–∞–≤–∫–∏.\\n\\n–ê—Ä–∫–∞–¥–∏–π –î–≤–æ—Ä–∫–æ–≤–∏—á\\n–≠–∫—Å–ø–µ—Ä—Ç—ã –∑–∞—Ç—Ä—É–¥–Ω—è—é—Ç—Å—è —Å–∫–∞–∑–∞—Ç—å, –∫—Ç–æ —Å–º–µ–Ω–∏—Ç –°—É—Ä–∫–æ–≤–∞, –æ–¥–Ω–∞–∫–æ –∏–∑ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω–æ–π –Ω–∞ —Å–∞–π—Ç–µ –∫–∞–±–∏–Ω–µ—Ç–∞ –º–∏–Ω–∏—Å—Ç—Ä–æ–≤ —Å–ª–µ–¥—É–µ—Ç, —á—Ç–æ –æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏ –í–ª–∞–¥–∏—Å–ª–∞–≤–∞ –°—É—Ä–∫–æ–≤–∞ –Ω–∞ –ø–µ—Ä–∏–æ–¥ –µ–≥–æ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è –≤–æ–∑–ª–∞–≥–∞—é—Ç—Å—è –Ω–∞ –≤–∏—Ü–µ-–ø—Ä–µ–º—å–µ—Ä–∞ –ê—Ä–∫–∞–¥–∏—è –î–≤–æ—Ä–∫–æ–≤–∏—á–∞:\\n–ù–∞ –ø–µ—Ä–∏–æ–¥ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è –≤–æ–ø—Ä–æ—Å—ã, –∑–∞–∫—Ä–µ–ø–ª–µ–Ω–Ω—ã–µ –Ω–∞—Å—Ç–æ—è—â–∏–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º –æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–µ–π –∑–∞ –í. –Æ. –°—É—Ä–∫–æ–≤—ã–º, —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç –ê. –í. –î–≤–æ—Ä–∫–æ–≤–∏—á\\n\\n–ù–∞–±–ª—é–¥–∞—Ç–µ–ª–∏ –æ—Ü–µ–Ω–∏–≤–∞—é—Ç –æ—Ç—Å—Ç–∞–≤–∫—É –°—É—Ä–∫–æ–≤–∞ –ø–æ-—Ä–∞–∑–Ω–æ–º—É.\\n\\n–í–ª–∞–¥–∏—Å–ª–∞–≤ –°—É—Ä–∫–æ–≤ –∏ –î–º–∏—Ç—Ä–∏–π –ú–µ–¥–≤–µ–¥–µ–≤\\n–¢–∞–∫ –¥–µ–ø—É—Ç–∞—Ç –ì–æ—Å–¥—É–º—ã –æ—Ç ¬´–°–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ–π –†–æ—Å—Å–∏–∏¬ª –ò–ª—å—è –ü–æ–Ω–æ–º–∞—Ä—ë–≤ –Ω–∞–∑–≤–∞–ª –µ—ë —Å–µ—Ä—å–µ–∑–Ω—ã–º —É–¥–∞—Ä–æ–º –ø–æ –ø—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤—É –î–º–∏—Ç—Ä–∏—è –ú–µ–¥–≤–µ–¥–µ–≤–∞:\\n–£–≤–æ–ª—å–Ω–µ–Ω–∏–µ –°—É—Ä–∫–æ–≤–∞ ‚Äî —Å–∞–º—ã–π —Å–µ—Ä—å–µ–∑–Ω—ã–π —É–¥–∞—Ä –ø–æ –ø—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤—É –ú–µ–¥–≤–µ–¥–µ–≤–∞. –ù–µ –∑–Ω–∞—é, —ç—Ç–æ –∏–Ω–∏—Ü–∏–∞—Ç–∏–≤–∞ –í–ª–∞–¥–∏–º–∏—Ä–∞ –ü—É—Ç–∏–Ω–∞, –∏–ª–∏ —Å–∞–º–æ–≥–æ –°—É—Ä–∫–æ–≤–∞, –Ω–æ –æ–Ω (–°—É—Ä–∫–æ–≤) –±—ã–ª –∫–ª—é—á–µ–≤—ã–º —á–µ–ª–æ–≤–µ–∫–æ–º —É –î–º–∏—Ç—Ä–∏—è –ú–µ–¥–≤–µ–¥–µ–≤–∞.\\n\\n–í–ª–∞–¥–∏—Å–ª–∞–≤ –°—É—Ä–∫–æ–≤\\n–í–ª–∞–¥–∏—Å–ª–∞–≤ –°—É—Ä–∫–æ–≤ –Ω–∞ —Å—ä–µ–∑–¥–µ ¬´–ù–∞—à–∏—Ö¬ª\\n–í–ª–∞–¥–∏—Å–ª–∞–≤ –°—É—Ä–∫–æ–≤, –î–º–∏—Ç—Ä–∏–π –†–æ–≥–æ–∑–∏–Ω –∏ –ê—Ä–∫–∞–¥–∏–π –î–≤–æ—Ä–∫–æ–≤–∏—á\\n–†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –∞–ø–ø–∞—Ä–∞—Ç–∞ –ü—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–∞ –†–æ—Å—Å–∏–π—Å–∫–æ–π –§–µ–¥–µ—Ä–∞—Ü–∏–∏ –∞–≤—Ç–æ—Ä –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏ —Å—É–≤–µ—Ä–µ–Ω–Ω–æ–π –¥–µ–º–æ–∫—Ä–∞—Ç–∏–∏ –í–ª–∞–¥–∏—Å–ª–∞–≤ –Æ—Ä—å–µ–≤–∏—á –°—É—Ä–∫–æ–≤ —Ä–æ–¥–∏–ª—Å—è 21 —Å–µ–Ω—Ç—è–±—Ä—è 1964 –≥–æ–¥–∞.\\n–ü–æ –Ω–µ–∫–æ—Ç–æ—Ä—ã–º –¥–∞–Ω–Ω—ã–º, –µ–≥–æ –∏–º—è –ø—Ä–∏ —Ä–æ–∂–¥–µ–Ω–∏–∏ ‚Äî –î—É–¥–∞–µ–≤ –ê—Å–ª–∞–º–±–µ–∫ –ê–Ω–¥–∞—Ä–±–µ–∫–æ–≤–∏—á.\\n\\n–î–æ–ø–æ–¥–ª–∏–Ω–Ω–æ–µ –º–µ—Å—Ç–æ —Ä–æ–∂–¥–µ–Ω–∏—è –í–ª–∞–¥–∏—Å–ª–∞–≤–∞ –°—É—Ä–∫–æ–≤–∞ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ.\\n–ü–æ –¥–∞–Ω–Ω—ã–º —Å–∞–π—Ç–∞ –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç–∞ –†–æ—Å—Å–∏–∏, –í–ª–∞–¥–∏—Å–ª–∞–≤ –°—É—Ä–∫–æ–≤ —Ä–æ–¥–∏–ª—Å—è –≤ —Å–µ–ª–µ –°–æ–ª–Ω—Ü–µ–≤–µ –õ–∏–ø–µ—Ü–∫–æ–π –æ–±–ª–∞—Å—Ç–∏.\\n–ü–æ –¥—Ä—É–≥–∏–º –¥–∞–Ω–Ω—ã–º ‚Äî –≤ —Å–µ–ª–µ –î—É–±–∞-–Æ—Ä—Ç –ß–µ—á–µ–Ω–æ-–ò–Ω–≥—É—à—Å–∫–æ–π –ê–≤—Ç–æ–Ω–æ–º–Ω–æ–π –†–µ—Å–ø—É–±–ª–∏–∫–∏.\\n\\n–û—Ç–µ—Ü –í–ª–∞–¥–∏—Å–ª–∞–≤–∞ –°—É—Ä–∫–æ–≤–∞ ‚Äî –î—É–¥–∞–µ–≤ –ê–Ω–¥–∞—Ä–±–µ–∫ –î–∞–Ω–∏–ª—å–±–µ–∫–æ–≤–∏—á (–∫–ª–∏—á–∫–∞ –Æ—Ä–∏–π), –ø–æ –Ω–µ–∫–æ—Ç–æ—Ä—ã–º –¥–∞–Ω–Ω—ã–º, –∫–∞–∫ –∏ –º–∞—Ç—å ‚Äî –°—É—Ä–∫–æ–≤–∞ –ó–æ—è –ê–Ω—Ç–æ–Ω–æ–≤–Ω–∞ —Ä–∞–±–æ—Ç–∞–ª —É—á–∏—Ç–µ–ª–µ–º –≤ –¥—É–±–∞-—é—Ä—Ç—Å–∫–æ–π —à–∫–æ–ª–µ.\\n\\n–ü–æ—Å–ª–µ —Ä–∞–∑–≤–æ–¥–∞ —Ä–æ–¥–∏—Ç–µ–ª–µ–π –≤ –≤–æ–∑—Ä–∞—Å—Ç–µ –ø—è—Ç–∏ –ª–µ—Ç –æ—Å—Ç–∞–ª—Å—è —Å –º–∞—Ç–µ—Ä—å—é –∏ –ø–µ—Ä–µ–µ—Ö–∞–ª –≤ –≥–æ—Ä–æ–¥ –°–∫–æ–ø–∏–Ω –†—è–∑–∞–Ω—Å–∫–æ–π –æ–±–ª–∞—Å—Ç–∏.\\n\\n–£—á–∏–ª—Å—è –≤ –ú–æ—Å–∫–æ–≤—Å–∫–æ–º –∏–Ω—Å—Ç–∏—Ç—É—Ç–µ —Å—Ç–∞–ª–∏ –∏ —Å–ø–ª–∞–≤–æ–≤ (–ú–ò–°–∏–°) –≤ 1982‚Äî1983 –≥–æ–¥–∞—Ö –∏ —Ç—Ä–∏ –≥–æ–¥–∞ ‚Äî –≤ –ú–æ—Å–∫–æ–≤—Å–∫–æ–º –∏–Ω—Å—Ç–∏—Ç—É—Ç–µ –∫—É–ª—å—Ç—É—Ä—ã –Ω–∞ —Ñ–∞–∫—É–ª—å—Ç–µ—Ç–µ —Ä–µ–∂–∏—Å—Å—É—Ä—ã –º–∞—Å—Å–æ–≤—ã—Ö —Ç–µ–∞—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π, –Ω–æ –Ω–µ –æ–∫–æ–Ω—á–∏–ª —ç—Ç–∏ –≤—É–∑—ã.\\n\\n–í 1987 –≥–æ–¥—É –≤–æ–∑–≥–ª–∞–≤–∏–ª —Ä–µ–∫–ª–∞–º–Ω—ã–π –æ—Ç–¥–µ–ª –¶–µ–Ω—Ç—Ä–∞ –º–µ–∂–æ—Ç—Ä–∞—Å–ª–µ–≤—ã—Ö –Ω–∞—É—á–Ω–æ-—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ–≥—Ä–∞–º–º (–¶–µ–Ω—Ç—Ä –≤–æ–∑–≥–ª–∞–≤–ª—è–ª –ú–∏—Ö–∞–∏–ª –•–æ–¥–æ—Ä–∫–æ–≤—Å–∫–∏–π) ‚Äî –§–æ–Ω–¥–∞ –º–æ–ª–æ–¥—ë–∂–Ω–æ–π –∏–Ω–∏—Ü–∏–∞—Ç–∏–≤—ã –ø—Ä–∏ –§—Ä—É–Ω–∑–µ–Ω—Å–∫–æ–º —Ä–∞–π–∫–æ–º–µ –í–õ–ö–°–ú.\\n–°–Ω–∞—á–∞–ª–∞ —Ä–∞–±–æ—Ç–∞–ª —Ç–∞–º –≤ –∫–∞—á–µ—Å—Ç–≤–µ —Ç–µ–ª–æ—Ö—Ä–∞–Ω–∏—Ç–µ–ª—è –•–æ–¥–æ—Ä–∫–æ–≤—Å–∫–æ–≥–æ.\\n\\n–í 1988 –≥–æ–¥—É –≤–æ–∑–≥–ª–∞–≤–ª—è–ª –∞–≥–µ–Ω—Ç—Å—Ç–≤–æ —Ä—ã–Ω–æ—á–Ω—ã—Ö –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–π ¬´–ú–µ—Ç–∞–ø—Ä–µ—Å—Å¬ª.\\n\\n–í –∫–æ–Ω—Ü–µ 1990-—Ö –≥–æ–¥–æ–≤ –æ–∫–æ–Ω—á–∏–ª –ú–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç –≤ –ú–æ—Å–∫–≤–µ.\\n\\n–í 1992 –≥–æ–¥—É ‚Äî –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç, –≤–∏—Ü–µ-–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç –†–æ—Å—Å–∏–π—Å–∫–æ–π –∞—Å—Å–æ—Ü–∏–∞—Ü–∏–∏ —Ä–µ–∫–ª–∞–º–æ–¥–∞—Ç–µ–ª–µ–π.\\n\\n–í 1991‚Äî1996 –≥–æ–¥–∞—Ö –∑–∞–Ω–∏–º–∞–ª —Ä—É–∫–æ–≤–æ–¥—è—â–∏–µ –¥–æ–ª–∂–Ω–æ—Å—Ç–∏ –≤ –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–∏ –∫—Ä–µ–¥–∏—Ç–Ω–æ-—Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏–π ¬´–ú–µ–Ω–∞—Ç–µ–ø¬ª (–∫–æ—Ç–æ—Ä–æ–µ –≤ —Ç–æ –≤—Ä–µ–º—è –≤–æ–∑–≥–ª–∞–≤–ª—è–ª –ú–∏—Ö–∞–∏–ª –•–æ–¥–æ—Ä–∫–æ–≤—Å–∫–∏–π), –≤ –¥–∞–ª—å–Ω–µ–π—à–µ–º ‚Äî –±–∞–Ω–∫–∞ ¬´–ú–µ–Ω–∞—Ç–µ–ø¬ª.\\n–í 1996‚Äî1997 –≥–æ–¥–∞—Ö ‚Äî –∑–∞–º–µ—Å—Ç–∏—Ç–µ–ª—å —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è, —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –î–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç–∞ –ø–æ —Å–≤—è–∑—è–º —Å –æ–±—â–µ—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å—é –ó–ê–û ¬´–†–æ—Å–ø—Ä–æ–º¬ª; –ø–µ—Ä–≤—ã–π –∑–∞–º–µ—Å—Ç–∏—Ç–µ–ª—å –ø—Ä–µ–¥—Å–µ–¥–∞—Ç–µ–ª—è –°–æ–≤–µ—Ç–∞ –ö–æ–º–º–µ—Ä—á–µ—Å–∫–æ–≥–æ –∏–Ω–Ω–æ–≤–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ –±–∞–Ω–∫–∞ ¬´–ê–ª—å—Ñ–∞-–ë–∞–Ω–∫¬ª.\\n–í 1998‚Äî1999 –≥–æ–¥–∞—Ö ‚Äî –ø–µ—Ä–≤—ã–π –∑–∞–º–µ—Å—Ç–∏—Ç–µ–ª—å –≥–µ–Ω–µ—Ä–∞–ª—å–Ω–æ–≥–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∞, –¥–∏—Ä–µ–∫—Ç–æ—Ä –ø–æ —Å–≤—è–∑—è–º —Å –æ–±—â–µ—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å—é –û–ê–û ¬´–û–±—â–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ —Ä–æ—Å—Å–∏–π—Å–∫–æ–µ —Ç–µ–ª–µ–≤–∏–¥–µ–Ω–∏–µ¬ª.\\n\\n–î–æ–ª–≥–∏–µ –≥–æ–¥—ã –°—É—Ä–∫–æ–≤ –æ—Å—Ç–∞–≤–∞–ª—Å—è –æ–¥–Ω–∏–º –∏–∑ —Å–∞–º—ã—Ö –≤–ª–∏—è—Ç–µ–ª—å–Ω—ã—Ö —Ä–æ—Å—Å–∏–π—Å–∫–∏—Ö –ø–æ–ª–∏—Ç–∏–∫–æ–≤.\\n\\n–í 1999 –≥–æ–¥—É ‚Äî –ø–æ–º–æ—â–Ω–∏–∫ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è –ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ü–∏–∏ –ü—Ä–µ–∑–∏–¥–µ–Ω—Ç–∞ –†–æ—Å—Å–∏–π—Å–∫–æ–π –§–µ–¥–µ—Ä–∞—Ü–∏–∏.\\n–° –∞–≤–≥—É—Å—Ç–∞ 1999 –≥–æ–¥–∞ ‚Äî –∑–∞–º–µ—Å—Ç–∏—Ç–µ–ª—å —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è –ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ü–∏–∏ –ü—Ä–µ–∑–∏–¥–µ–Ω—Ç–∞ –†–æ—Å—Å–∏–π—Å–∫–æ–π –§–µ–¥–µ—Ä–∞—Ü–∏–∏.\\n–°—á–∏—Ç–∞–µ—Ç—Å—è –æ–¥–Ω–∏–º –∏–∑ —Å–æ–∑–¥–∞—Ç–µ–ª–µ–π –∏ –∏–¥–µ–æ–ª–æ–≥–æ–≤ –ø–∞—Ä—Ç–∏–∏ ¬´–ï–¥–∏–Ω–∞—è –†–æ—Å—Å–∏—è¬ª. –∏–Ω—Ç–µ—Ä–≤—å—é –∞–≥–µ–Ω—Ç—Å—Ç–≤—É –ò–Ω—Ç–µ—Ä—Ñ–∞–∫—Å 27 –¥–µ–∫–∞–±—Ä—è 2011 –ø—Ä–∏ –æ—Ç—Å—Ç–∞–≤–∫–µ —Å –ø–æ—Å—Ç–∞ –∑–∞–º–≥–ª–∞–≤—ã –ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ü–∏–∏ –ü—Ä–µ–∑–∏–¥–µ–Ω—Ç–∞ –†–æ—Å—Å–∏–∏ –°—É—Ä–∫–æ–≤ —É—Ç–≤–µ—Ä–∂–¥–∞–ª, —á—Ç–æ: ¬´–Ø –±—ã–ª –≤ —á–∏—Å–ª–µ —Ç–µ—Ö, –∫—Ç–æ –ø–æ–º–æ–≥–∞–ª –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç—É –ï–ª—å—Ü–∏–Ω—É –æ—Å—É—â–µ—Å—Ç–≤–∏—Ç—å –º–∏—Ä–Ω—ã–π –ø–µ—Ä–µ—Ö–æ–¥ –≤–ª–∞—Å—Ç–∏. –í —á–∏—Å–ª–µ —Ç–µ—Ö, –∫—Ç–æ –ø–æ–º–æ–≥–∞–ª –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç—É –ü—É—Ç–∏–Ω—É —Å—Ç–∞–±–∏–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø–æ–ª–∏—Ç–∏—á–µ—Å–∫—É—é —Å–∏—Å—Ç–µ–º—É¬ª.\\n\\n–° –º–∞—Ä—Ç–∞ 2004 –≥–æ–¥–∞ ‚Äî –∑–∞–º–µ—Å—Ç–∏—Ç–µ–ª—å —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è –ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ü–∏–∏ –ü—Ä–µ–∑–∏–¥–µ–Ω—Ç–∞ –†–æ—Å—Å–∏–π—Å–∫–æ–π –§–µ–¥–µ—Ä–∞—Ü–∏–∏ ‚Äî –ø–æ–º–æ—â–Ω–∏–∫ –ü—Ä–µ–∑–∏–¥–µ–Ω—Ç–∞ –†–æ—Å—Å–∏–π—Å–∫–æ–π –§–µ–¥–µ—Ä–∞—Ü–∏–∏.\\n–û–¥–∏–Ω –∏–∑ –≤–¥–æ—Ö–Ω–æ–≤–∏—Ç–µ–ª–µ–π –ø—Ä–æ–µ–∫—Ç–æ–≤ ¬´–ò–¥—É—â–∏–µ –≤–º–µ—Å—Ç–µ¬ª (2000) –∏ –¥–≤–∏–∂–µ–Ω–∏—è ¬´–ù–∞—à–∏¬ª (2005 –≥–æ–¥).\\n–° 15 –º–∞—è 2008 –≥–æ–¥–∞ ‚Äî –ø–µ—Ä–≤—ã–π –∑–∞–º–µ—Å—Ç–∏—Ç–µ–ª—å —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ü–∏–∏ –ü—Ä–µ–∑–∏–¥–µ–Ω—Ç–∞ –†–æ—Å—Å–∏–π—Å–∫–æ–π –§–µ–¥–µ—Ä–∞—Ü–∏–∏.\\n–° 2010 –≥–æ–¥–∞ ‚Äî —á–ª–µ–Ω –ø–æ–ø–µ—á–∏—Ç–µ–ª—å—Å–∫–æ–≥–æ —Å–æ–≤–µ—Ç–∞ –§–æ–Ω–¥–∞ ¬´–°–∫–æ–ª–∫–æ–≤–æ¬ª.\\n27 –¥–µ–∫–∞–±—Ä—è 2011 –≥–æ–¥–∞ ‚Äî –Ω–∞–∑–Ω–∞—á–µ–Ω –≤–∏—Ü–µ-–ø—Ä–µ–º—å–µ—Ä–æ–º –ü—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–∞ –†–§.\\n</td>\n",
       "      <td>[–°—É—Ä–∫–æ–≤, –ø–æ–¥–∞–ª, –≤, –æ—Ç—Å—Ç–∞–≤–∫—É, –í–ª–∞–¥–∏—Å–ª–∞–≤, –°—É—Ä–∫–æ–≤, 8, –º–∞—è, 2013, –≥–æ–¥–∞, –ü—Ä–µ–∑–∏–¥–µ–Ω—Ç, –†–æ—Å—Å–∏–∏, –ü—Ä–µ–∑–∏–¥–µ–Ω—Ç, –†–æ—Å—Å–∏–∏, –í–ª–∞–¥–∏–º–∏—Ä, –ü—É—Ç–∏–Ω, –ø–æ–¥–ø–∏—Å–∞–ª, –£–∫–∞–∑, –£–∫–∞–∑, ¬´–û, –°—É—Ä–∫–æ–≤–µ, –í., –Æ., –û, –°—É—Ä–∫–æ–≤–µ, –í., –Æ., –°—É—Ä–∫–æ–≤–µ, –í., –Æ., ¬ª,, –∫–æ—Ç–æ—Ä—ã–º, –æ—Ç–ø—Ä–∞–≤–∏–ª, —á–∏–Ω–æ–≤–Ω–∏–∫–∞, –≤, –æ—Ç—Å—Ç–∞–≤–∫—É, :, –í, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏, —Å, –ø—É–Ω–∫—Ç–æ–º, –¥, —Å—Ç–∞—Ç—å–∏, 83, –ö–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏–∏, –†–æ—Å—Å–∏–π—Å–∫–æ–π, –§–µ–¥–µ—Ä–∞—Ü–∏–∏, —Å—Ç–∞—Ç—å–∏, 83, –ö–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏–∏, –†–æ—Å—Å–∏–π—Å–∫–æ–π, –§–µ–¥–µ—Ä–∞—Ü–∏–∏, —Å—Ç–∞—Ç—å–∏, 83, –ö–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏–∏, –†–æ—Å—Å–∏–π—Å–∫–æ–π, –§–µ–¥–µ—Ä–∞—Ü–∏–∏, 83, –ö–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏–∏, –†–æ—Å—Å–∏–π—Å–∫–æ–π, –§–µ–¥–µ—Ä–∞—Ü–∏–∏, –ö–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏–∏, –†–æ—Å—Å–∏–π—Å–∫–æ–π, –§–µ–¥–µ—Ä–∞—Ü–∏–∏, –æ—Å–≤–æ–±–æ–¥–∏—Ç—å, –°—É—Ä–∫–æ–≤–∞, –í–ª–∞–¥–∏—Å–ª–∞–≤–∞, –Æ—Ä—å–µ–≤–∏—á–∞, –æ—Ç, –¥–æ–ª–∂–Ω–æ—Å—Ç–∏, –ó–∞–º–µ—Å—Ç–∏—Ç–µ–ª—è, –ü—Ä–µ–¥—Å–µ–¥–∞—Ç–µ–ª—è, –ü—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–∞, –†–æ—Å—Å–∏–π—Å–∫–æ–π, –§–µ–¥–µ—Ä–∞—Ü–∏–∏, –ó–∞–º–µ—Å—Ç–∏—Ç–µ–ª—è, –ü—Ä–µ–¥—Å–µ–¥–∞—Ç–µ–ª—è, –ü—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–∞, –ü—Ä–µ–¥—Å–µ–¥–∞—Ç–µ–ª—è, –ü—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–∞, –†–æ—Å—Å–∏–π—Å–∫–æ–π, –§–µ–¥–µ—Ä–∞—Ü–∏–∏, –ü—Ä–µ–¥—Å–µ–¥–∞—Ç–µ–ª—è, –ü—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–∞, –ü—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–∞, –†–æ—Å—Å–∏–π—Å–∫–æ–π, –§–µ–¥–µ—Ä–∞—Ü–∏–∏, –†–æ—Å—Å–∏–π—Å–∫–æ–π, –§–µ–¥–µ—Ä–∞—Ü–∏–∏, –†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è, –ê–ø–ø–∞—Ä–∞—Ç–∞, –ü—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–∞, –†–æ—Å—Å–∏–π—Å–∫–æ–π, –§–µ–¥–µ—Ä–∞—Ü–∏–∏, –ê–ø–ø–∞—Ä–∞—Ç–∞, –ü—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–∞, –†–æ—Å—Å–∏–π—Å–∫–æ–π, –§–µ–¥–µ—Ä–∞—Ü–∏–∏, –ü—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–∞, –†–æ—Å—Å–∏–π—Å–∫–æ–π, ...]</td>\n",
       "      <td>[B-PERSON, O, O, B-EVENT, B-PERSON, I-PERSON, B-DATE, I-DATE, I-DATE, I-DATE, B-PROFESSION, I-PROFESSION, B-PROFESSION, B-COUNTRY, B-PERSON, I-PERSON, B-EVENT, I-EVENT, B-LAW, I-LAW, I-LAW, I-LAW, I-LAW, B-LAW, I-LAW, I-LAW, I-LAW, B-PERSON, I-PERSON, I-PERSON, O, O, O, B-PROFESSION, O, B-EVENT, O, O, O, O, B-LAW, I-LAW, I-LAW, I-LAW, I-LAW, I-LAW, I-LAW, B-LAW, I-LAW, I-LAW, I-LAW, I-LAW, B-LAW, I-LAW, I-LAW, I-LAW, I-LAW, B-ORDINAL, B-LAW, I-LAW, I-LAW, B-LAW, B-COUNTRY, I-COUNTRY, O, B-PERSON, I-PERSON, I-PERSON, O, O, B-PROFESSION, I-PROFESSION, I-PROFESSION, I-PROFESSION, I-PROFESSION, B-PROFESSION, I-PROFESSION, I-PROFESSION, B-PROFESSION, I-PROFESSION, I-PROFESSION, I-PROFESSION, B-PROFESSION, I-PROFESSION, B-ORGANIZATION, I-ORGANIZATION, I-ORGANIZATION, B-COUNTRY, I-COUNTRY, B-PROFESSION, I-PROFESSION, I-PROFESSION, I-PROFESSION, I-PROFESSION, B-ORGANIZATION, I-ORGANIZATION, I-ORGANIZATION, I-ORGANIZATION, B-ORGANIZATION, I-ORGANIZATION, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>–í –∞–ø—Ä–µ–ª–µ –≤—ã—à–µ–ª —Å–±–æ—Ä–Ω–∏–∫ —Å—Ç–∏—Ö–æ–≤ –¥–ª—è –¥–æ—à–∫–æ–ª—å–Ω–∏–∫–æ–≤ ¬´–ù–∞—à–∏ –¥–Ω–∏¬ª\\n\\n–í –∞–ø—Ä–µ–ª–µ 2014 –≥–æ–¥–∞ –≤—ã—à–ª–∞ –∫–Ω–∏–≥–∞ –Æ–ª–∏–∏ –°—ã—Ä—ã—Ö ''¬´–ù–∞—à–∏ –¥–Ω–∏. –°—Ç–∏—Ö–∏ –¥–ª—è –¥–æ—à–∫–æ–ª—å–Ω–∏–∫–æ–≤ –Ω–∞ –∫–∞–∂–¥—ã–π –¥–µ–Ω—å¬ª''. –í –∏–ª–ª—é—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–≤—Ç–æ—Ä–æ–º —Å–±–æ—Ä–Ω–∏–∫ –≤–æ—à–ª–∏ –∫–æ—Ä–æ—Ç–∫–∏–µ —Å—Ç–∏—Ö–∏ –∏–∑ 2-4 —Å—Ç—Ä–æ—á–µ–∫, –æ–ø–∏—Å—ã–≤–∞—é—â–∏–µ —Å–∞–º—ã–µ –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ —Ç–µ–º—ã, –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–µ —Ä–æ–¥–∏—Ç–µ–ª—è–º: –∫–∞–∫ –Ω–∞—É—á–∏—Ç—å –¥–µ—Ç–µ–π –æ–¥–µ–≤–∞—Ç—å—Å—è, —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ –µ—Å—Ç—å, –ø—Ä–∞–≤–∏–ª—å–Ω–æ —Å–µ–±—è –≤–µ—Å—Ç–∏. –ü–æ –º–Ω–µ–Ω–∏—é –∞–≤—Ç–æ—Ä–∞ ‚Äî —ç—Ç–æ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ ¬´–ø–µ–¥–∞–≥–æ–≥–∏—á–µ—Å–∫–∏–µ¬ª —Å—Ç–∏—Ö–∏, —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞—é—â–∏–µ –æ —Ç–æ–º, ¬´—á—Ç–æ —Ç–∞–∫–æ–µ —Ö–æ—Ä–æ—à–æ –∏ —á—Ç–æ —Ç–∞–∫–æ–µ –ø–ª–æ—Ö–æ¬ª.\\n\\n–í –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ –∫ –∫–Ω–∏–≥–µ —Å–∫–∞–∑–∞–Ω–æ:\\n –ù–∞—à–∏ –¥–Ω–∏ —Å —É—Ç—Ä–∞ –¥–æ –≤–µ—á–µ—Ä–∞ –Ω–∞–ø–æ–ª–Ω–µ–Ω—ã –¥–µ–ª–∞–º–∏ –ø–æ—Å—Ç—É–ø–∫–∞–º–∏ —Å–ª–æ–≤–∞–º–∏ –∏ —ç–º–æ—Ü–∏—è–º–∏ –ê –∫–∞–∫ –≤—Å—ë –¥–µ–ª–∞—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω–æ –æ–± —ç—Ç–æ–º –∏ –∫–Ω–∏–≥–∞ –ù–∞–¥–µ—é—Å—å –æ–Ω–∞ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—Ç –≤–∞—à–µ —Å–µ–º–µ–π–Ω–æ–µ —á—Ç–µ–Ω–∏–µ –∏ —Å—Ç–∞–Ω–µ—Ç –ø–æ–≤–æ–¥–æ–º –∫ –ø—Ä–∏—è—Ç–Ω—ã–º –∏ –ø–æ–ª–µ–∑–Ω—ã–º –±–µ—Å–µ–¥–∞–º –Ø –≤–µ—Ä—é –≤ —Ç–æ —á—Ç–æ —É—á–∏—Ç—å —Ö–æ—Ä–æ—à–µ–º—É –º–æ–∂–Ω–æ —á–µ—Ä–µ–∑ –µ–∂–µ–¥–Ω–µ–≤–Ω–æ —á–∏—Ç–∞–µ–º—ã–µ —Å—Ç–∏—Ö–∏ –∞ –Ω–µ —Ç–æ–ª—å–∫–æ —á–µ—Ä–µ–∑ –ø–æ—Å—Ç–æ—è–Ω–Ω—ã–µ –Ω–∞–ø–æ–º–∏–Ω–∞–Ω–∏—è –í –Ω–∞–ø–∏—Å–∞–Ω–Ω—ã—Ö –±—É–∫–≤–∞—Ö –µ—Å—Ç—å —Å–≤–æ—è –º–∞–≥–∏—è —Å—Ç–∏—Ö–∏ –∑–∞–ø–æ–º–∏–Ω–∞—é—Ç—Å—è —Å–∞–º–∏ —Å–æ–±–æ–π –∏ —Å–ª—É–∂–∞—Ç —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ–º –∫ –¥–µ–π—Å—Ç–≤–∏—é \\n\\n–°—Ç–∏—Ö–∏ –æ—Ç–ª–∏—á–∞–µ—Ç –ø—Ä–æ—Å—Ç–æ—Ç–∞ –∏ –ª—ë–≥–∫–æ—Å—Ç—å –¥–ª—è –∑–∞–ø–æ–º–∏–Ω–∞–Ω–∏—è:\\n–ú–∞–º–∞, –ø–∞–ø–∞, –±—Ä–∞—Ç –∏ —è ‚Äî–í–æ—Ç –≤–µ—Å—ë–ª–∞—è —Å–µ–º—å—è.¬´–° –¥–æ–±—Ä—ã–º —É—Ç—Ä–æ–º, –¥–µ—Ç–≤–æ—Ä–∞¬ª, ‚Äî–º–∞–º–∞ –≥–æ–≤–æ—Ä–∏—Ç —Å —É—Ç—Ä–∞.\\n\\n–ö–∞–∂–¥–æ–µ —Å—Ç–∏—Ö–æ—Ç–≤–æ—Ä–µ–Ω–∏–µ —Å–æ–ø—Ä–æ–≤–æ–∂–¥–∞–µ—Ç—Å—è –∞–≤—Ç–æ—Ä—Å–∫–æ–π –∏–ª–ª—é—Å—Ç—Ä–∞—Ü–∏–µ–π, –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω–æ–π –≤ –¥–µ—Ç—Å–∫–æ–º —Å—Ç–∏–ª–µ. –ß–µ—Ä–µ–∑ –≤—Å—é –∫–Ω–∏–≥—É –ø—Ä–æ—Ö–æ–¥–∏—Ç –∂–∏–∑–Ω—å –¥—Ä—É–∂–Ω–æ–π —Å–µ–º—å–∏, –∫–æ—Ç–æ—Ä–∞—è –º–æ–∂–µ—Ç –ø–æ—Å–ª—É–∂–∏—Ç—å –æ–±—Ä–∞–∑—Ü–æ–º –¥–ª—è –ø–æ–¥—Ä–∞–∂–∞–Ω–∏—è.\\n\\n–ö–Ω–∏–≥–∞ ¬´–ù–∞—à–∏ –¥–Ω–∏¬ª –¥–æ—Å—Ç—É–ø–Ω–∞ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-–º–∞–≥–∞–∑–∏–Ω–∞—Ö, –∞ —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é –º–æ–∂–Ω–æ —á–∏—Ç–∞—Ç—å –æ–Ω–ª–∞–π–Ω –±–µ—Å–ø–ª–∞—Ç–Ω–æ. –ê–≤—Ç–æ—Ä –æ—Ç–º–µ—á–∞–µ—Ç, —á—Ç–æ —Ö–æ—á–µ—Ç —Å–¥–µ–ª–∞—Ç—å –∫–Ω–∏–≥—É –¥–æ—Å—Ç—É–ø–Ω–æ–π –¥–ª—è –≤—Å–µ—Ö, –ø–æ—ç—Ç–æ–º—É –µ—Å–ª–∏ –≤ —Å–µ–º—å–µ –µ—Å—Ç—å —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω—ã–π –ø–ª–∞–Ω—à–µ—Ç, —Ä–æ–¥–∏—Ç–µ–ª–∏ –º–æ–≥—É—Ç —á–∏—Ç–∞—Ç—å –¥–µ—Ç—è–º —Å –ø–æ–º–æ—â—å—é –Ω–µ–≥–æ.\\n\\n–ö–Ω–∏–≥–∞ –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω–∞ –¥–ª—è —á—Ç–µ–Ω–∏—è –≤–∑—Ä–æ—Å–ª—ã–º–∏ –¥–µ—Ç—è–º –∏ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –¥–µ—Ç–µ–π –æ—Ç –¥–≤—É—Ö –¥–æ —à–µ—Å—Ç–∏-—Å–µ–º–∏ –ª–µ—Ç.\\n\\n–Æ–ª–∏—è –°—ã—Ä—ã—Ö —Ä–æ–¥–∏–ª–∞—Å—å –≤ –†—è–∑–∞–Ω–∏, –∂–∏–≤—ë—Ç –∏ —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ –ö—Ä—ã–º—É.\\n–ü–æ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—é ‚Äî –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞ –∏ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã. –ó–∞–∫–æ–Ω—á–∏–ª–∞ —Ñ–∞–∫—É–ª—å—Ç–µ—Ç —Å–ª–∞–≤—è–Ω—Å–∫–æ–π —Ñ–∏–ª–æ–ª–æ–≥–∏–∏ –¢–∞–≤—Ä–∏—á–µ—Å–∫–æ–≥–æ –ù–∞—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ –£–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–∞. –ò–º–µ–µ—Ç –¥–≤–æ–∏—Ö –¥–µ—Ç–µ–π. –î–∏–∑–∞–π–Ω–µ—Ä –ø–æ –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏, –æ—Å–Ω–æ–≤–∞—Ç–µ–ª—å –∏ –∞—Ä—Ç-–¥–∏—Ä–µ–∫—Ç–æ—Ä –¥–∏–∑–∞–π–Ω-–≥—Ä—É–ø–ø—ã ¬´–î–∏–∫–æ–≤–∏–Ω–∞¬ª. –ê–≤—Ç–æ—Ä –∫–Ω–∏–≥ –ø–æ —à—Ä–∏—Ñ—Ç–∞–º –∏ –≤–µ–±-–¥–∏–∑–∞–π–Ω—É, –∞ —Ç–∞–∫–∂–µ –¥–µ—Ç—Å–∫–∏—Ö –∫–Ω–∏–≥, –∏–∑–¥–∞–≤–∞–µ–º—ã—Ö –ø–æ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ ¬´–ø–æ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—é¬ª. –ê–≤—Ç–æ—Ä –º–µ—Ç–æ–¥–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è —á—Ç–µ–Ω–∏—é ¬´–£—á–∏–º—Å—è —á–∏—Ç–∞—Ç—å —Å –ª—é–±–æ–≤—å—é¬ª. –ú–Ω–æ–≥–∏–µ –∫–Ω–∏–≥–∏ –Æ–ª–∏–∏ –¥–æ—Å—Ç—É–ø–Ω—ã –¥–ª—è —á—Ç–µ–Ω–∏—è –æ–Ω–ª–∞–π–Ω.\\n</td>\n",
       "      <td>[–í, –∞–ø—Ä–µ–ª–µ, –≤—ã—à–µ–ª, —Å–±–æ—Ä–Ω–∏–∫, —Å—Ç–∏—Ö–æ–≤, –¥–ª—è, –¥–æ—à–∫–æ–ª—å–Ω–∏–∫–æ–≤, ¬´, –ù–∞—à–∏, –¥–Ω–∏, ¬ª, –í, –∞–ø—Ä–µ–ª–µ, 2014, –≥–æ–¥–∞, –≤—ã—à–ª–∞, –∫–Ω–∏–≥–∞, –Æ–ª–∏–∏, –°—ã—Ä—ã—Ö, ''¬´, –ù–∞—à–∏, –¥–Ω–∏., –°—Ç–∏—Ö–∏, –¥–ª—è, –¥–æ—à–∫–æ–ª—å–Ω–∏–∫–æ–≤, –Ω–∞, –∫–∞–∂–¥—ã–π, –¥–µ–Ω—å, ¬ª''., –í, –∏–ª–ª—é—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π, –∞–≤—Ç–æ—Ä–æ–º, —Å–±–æ—Ä–Ω–∏–∫, –≤–æ—à–ª–∏, –∫–æ—Ä–æ—Ç–∫–∏–µ, —Å—Ç–∏—Ö–∏, –∏–∑, 2-4, —Å—Ç—Ä–æ—á–µ–∫,, –æ–ø–∏—Å—ã–≤–∞—é—â–∏–µ, —Å–∞–º—ã–µ, –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ, —Ç–µ–º—ã,, –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–µ, —Ä–æ–¥–∏—Ç–µ–ª—è–º:, –∫–∞–∫, –Ω–∞—É—á–∏—Ç—å, –¥–µ—Ç–µ–π, –æ–¥–µ–≤–∞—Ç—å—Å—è,, —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ, –µ—Å—Ç—å,, –ø—Ä–∞–≤–∏–ª—å–Ω–æ, —Å–µ–±—è, –≤–µ—Å—Ç–∏., –ü–æ, –º–Ω–µ–Ω–∏—é, –∞–≤—Ç–æ—Ä–∞, ‚Äî, —ç—Ç–æ, –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ, ¬´–ø–µ–¥–∞–≥–æ–≥–∏—á–µ—Å–∫–∏–µ¬ª, —Å—Ç–∏—Ö–∏,, —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞—é—â–∏–µ, –æ, —Ç–æ–º,, ¬´—á—Ç–æ, —Ç–∞–∫–æ–µ, —Ö–æ—Ä–æ—à–æ, –∏, —á—Ç–æ, —Ç–∞–∫–æ–µ, –ø–ª–æ—Ö–æ¬ª., –í, –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏, –∫, –∫–Ω–∏–≥–µ, —Å–∫–∞–∑–∞–Ω–æ:, –ù–∞—à–∏, –¥–Ω–∏, —Å, —É—Ç—Ä–∞, –¥–æ, –≤–µ—á–µ—Ä–∞, –Ω–∞–ø–æ–ª–Ω–µ–Ω—ã, –¥–µ–ª–∞–º–∏, –ø–æ—Å—Ç—É–ø–∫–∞–º–∏, —Å–ª–æ–≤–∞–º–∏, –∏, —ç–º–æ—Ü–∏—è–º–∏, –ê, –∫–∞–∫, –≤—Å—ë, –¥–µ–ª–∞—Ç—å, –ø—Ä–∞–≤–∏–ª—å–Ω–æ, –æ–±, —ç—Ç–æ–º, –∏, –∫–Ω–∏–≥–∞, –ù–∞–¥–µ—é—Å—å, –æ–Ω–∞, ...]</td>\n",
       "      <td>[B-DATE, I-DATE, O, O, O, O, O, O, B-WORK_OF_ART, I-WORK_OF_ART, O, B-DATE, I-DATE, I-DATE, I-DATE, O, O, B-PERSON, I-PERSON, O, B-WORK_OF_ART, I-WORK_OF_ART, I-WORK_OF_ART, I-WORK_OF_ART, I-WORK_OF_ART, I-WORK_OF_ART, I-WORK_OF_ART, I-WORK_OF_ART, O, O, O, O, O, O, O, O, O, B-NUMBER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>–ü—É—Ç–∏–Ω –Ω–∞–∑–Ω–∞—á–∏–ª –≤—Ä–µ–º–µ–Ω–Ω—ã–º –≥—É–±–µ—Ä–Ω–∞—Ç–æ—Ä–æ–º –ú–æ—Å–∫–æ–≤—Å–∫–æ–π –æ–±–ª–∞—Å—Ç–∏ –µ–¥–∏–Ω–æ—Ä–æ—Å—Å–∞ –ê–Ω–¥—Ä–µ—è –í–æ—Ä–æ–±—å—ë–≤–∞\\n–í–ª–∞–¥–∏–º–∏—Ä –ü—É—Ç–∏–Ω –∏ –ê–Ω–¥—Ä–µ–π –í–æ—Ä–æ–±—å—ë–≤.\\n8 –Ω–æ—è–±—Ä—è 2012 –≥–æ–¥–∞ –í–ª–∞–¥–∏–º–∏—Ä –ü—É—Ç–∏–Ω –ø–æ–¥–ø–∏—Å–∞–ª —É–∫–∞–∑, —Å–æ–≥–ª–∞—Å–Ω–æ –∫–æ—Ç–æ—Ä–æ–º—É —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å —Ñ—Ä–∞–∫—Ü–∏–∏ ¬´–ï–¥–∏–Ω–∞—è –†–æ—Å—Å–∏—è¬ª –≤ –ì–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω–æ–π –î—É–º–µ –ê–Ω–¥—Ä–µ–π –í–æ—Ä–æ–±—å—ë–≤ –Ω–∞–∑–Ω–∞—á–µ–Ω –Ω–∞ –¥–æ–ª–∂–Ω–æ—Å—Ç—å –∏—Å–ø–æ–ª–Ω—è—é—â–µ–≥–æ –æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏ –≥—É–±–µ—Ä–Ω–∞—Ç–æ—Ä–∞ –ú–æ—Å–∫–æ–≤—Å–∫–æ–π –æ–±–ª–∞—Å—Ç–∏.\\n\\n–û–± —ç—Ç–æ–º –ü—Ä–µ–∑–∏–¥–µ–Ω—Ç –†–æ—Å—Å–∏–∏ —Å–æ–æ–±—â–∏–ª –¥–µ–ø—É—Ç–∞—Ç—É –≤–æ –≤—Ä–µ–º—è –ª–∏—á–Ω–æ–π –≤—Å—Ç—Ä–µ—á–∏ –≤ –ö—Ä–µ–º–ª–µ:\\n—Ö–æ—Ç–µ–ª –±—ã –í–∞–º –ø—Ä–µ–¥–ª–æ–∂–∏—Ç—å –¥—Ä—É–≥—É—é —Ä–∞–±–æ—Ç—É, —Å–≤—è–∑–∞–Ω–Ω—É—é —Å –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é, –∏–º–µ—è –≤ –≤–∏–¥—É ‚Äì –í—ã, –Ω–∞–≤–µ—Ä–Ω–æ–µ, —É–∂–µ –¥–æ–≥–∞–¥–∞–ª–∏—Å—å ‚Äì –¥–æ–ª–∂–Ω–æ—Å—Ç—å –∏—Å–ø–æ–ª–Ω—è—é—â–µ–≥–æ –æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏ –≥—É–±–µ—Ä–Ω–∞—Ç–æ—Ä–∞ –ú–æ—Å–∫–æ–≤—Å–∫–æ–π –æ–±–ª–∞—Å—Ç–∏.\\n\\n–í –æ—Ç–≤–µ—Ç –Ω–∞ —á—Ç–æ –≤–∏–∑–∞–≤–∏ –ø–æ–¥—Ç–≤–µ—Ä–¥–∏–ª —Å–æ–≥–ª–∞—Å–∏–µ:\\n–°–ø–∞—Å–∏–±–æ, –í–ª–∞–¥–∏–º–∏—Ä –í–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á, –∑–∞ –≤—ã—Å–æ–∫–æ–µ –¥–æ–≤–µ—Ä–∏–µ. –Ø —Å–æ–≥–ª–∞—Å–µ–Ω, —è –≥–æ—Ç–æ–≤. –ò, –∫–æ–Ω–µ—á–Ω–æ, —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞—é, –∫–∞–∫ –∏ –ø—Ä–µ–∂–¥–µ, –Ω–∞ –í–∞—à—É –ø–æ–¥–¥–µ—Ä–∂–∫—É. –ü–æ–Ω–∏–º–∞—é, —á—Ç–æ —Ä–µ–≥–∏–æ–Ω –±–æ–ª—å—à–æ–π, –Ω–µ–ø—Ä–æ—Å—Ç–æ–π, –Ω–æ –≥–æ—Ç–æ–≤ —Ä–∞–±–æ—Ç–∞—Ç—å. –ü—Ä–µ–¥—ã–¥—É—â–∞—è –∫–æ–º–∞–Ω–¥–∞ –ø–æ–¥ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ–º –°–µ—Ä–≥–µ—è –®–æ–π–≥—É –ø–æ–¥–≥–æ—Ç–æ–≤–∏–ª–∞ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —á—ë—Ç–∫–∏–π, –ø–æ–Ω—è—Ç–Ω—ã–π –ø–ª–∞–Ω, –∏ –º—ã –±—É–¥–µ–º –µ–≥–æ —Ä–µ–∞–ª–∏–∑–æ–≤—ã–≤–∞—Ç—å.\\n\\n–ê–Ω–¥—Ä–µ–π –í–æ—Ä–æ–±—å—ë–≤ –±—É–¥–µ—Ç –∏—Å–ø–æ–ª–Ω—è—Ç—å –æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏ –≥–ª–∞–≤—ã —Ä–µ–≥–∏–æ–Ω–∞ –¥–æ –ø—Ä—è–º—ã—Ö –≤—ã–±–æ—Ä–æ–≤ –≥—É–±–µ—Ä–Ω–∞—Ç–æ—Ä–∞, –∫–æ—Ç–æ—Ä—ã–µ —Å–æ—Å—Ç–æ—è—Ç—Å—è –≤ —Å–µ–Ω—Ç—è–±—Ä–µ 2013 –≥–æ–¥–∞.\\n\\n–°–ª–µ–¥—É–µ—Ç –æ—Ç–º–µ—Ç–∏—Ç—å, —á—Ç–æ 42-–ª–µ—Ç–Ω–∏–π –ê–Ω–¥—Ä–µ–π –í–æ—Ä–æ–±—å—ë–≤ ‚Äî —Å—ã–Ω –±–ª–∏–∂–∞–π—à–µ–≥–æ —Å–æ—Ä–∞—Ç–Ω–∏–∫–∞ –°–µ—Ä–≥–µ—è –®–æ–π–≥—É, –æ–¥–Ω–æ–≥–æ –∏–∑ –æ—Å–Ω–æ–≤–∞—Ç–µ–ª–µ–π –ú–∏–Ω–∏—Å—Ç–µ—Ä—Å—Ç–≤–∞ –ø–æ —á—Ä–µ–∑–≤—ã—á–∞–π–Ω—ã–º —Å–∏—Ç—É–∞—Ü–∏—è–º –†–æ—Å—Å–∏–∏ –Æ—Ä–∏—è –í–æ—Ä–æ–±—å—ë–≤–∞.\\n–í 2012 –≥–æ–¥—É –≤ —ç—Ñ–∏—Ä–µ —Ç–µ–ª–µ–∫–∞–Ω–∞–ª–∞ ¬´–î–æ–∂–¥—å¬ª –ê–Ω–¥—Ä–µ–π –í–æ—Ä–æ–±—å—ë–≤ –Ω–∞–∑—ã–≤–∞–ª –°–µ—Ä–≥–µ—è –®–æ–π–≥—É —Å–≤–æ–∏–º –∫—Ä—ë—Å—Ç–Ω—ã–º –æ—Ç—Ü–æ–º –≤ –ø–æ–ª–∏—Ç–∏–∫–µ.\\n</td>\n",
       "      <td>[–ü—É—Ç–∏–Ω, –Ω–∞–∑–Ω–∞—á–∏–ª, –≤—Ä–µ–º–µ–Ω–Ω—ã–º, –≥—É–±–µ—Ä–Ω–∞—Ç–æ—Ä–æ–º, –≤—Ä–µ–º–µ–Ω–Ω—ã–º, –≥—É–±–µ—Ä–Ω–∞—Ç–æ—Ä–æ–º, –ú–æ—Å–∫–æ–≤—Å–∫–æ–π, –æ–±–ª–∞—Å—Ç–∏, –≥—É–±–µ—Ä–Ω–∞—Ç–æ—Ä–æ–º, –ú–æ—Å–∫–æ–≤—Å–∫–æ–π, –æ–±–ª–∞—Å—Ç–∏, –µ–¥–∏–Ω–æ—Ä–æ—Å—Å–∞, –ê–Ω–¥—Ä–µ—è, –í–æ—Ä–æ–±—å—ë–≤–∞, –í–ª–∞–¥–∏–º–∏—Ä, –ü—É—Ç–∏–Ω, –∏, –ê–Ω–¥—Ä–µ–π, –í–æ—Ä–æ–±—å—ë–≤, ., 8, –Ω–æ—è–±—Ä—è, 2012, –≥–æ–¥–∞, –í–ª–∞–¥–∏–º–∏—Ä, –ü—É—Ç–∏–Ω, –ø–æ–¥–ø–∏—Å–∞–ª, —É–∫–∞–∑, ,, —Å–æ–≥–ª–∞—Å–Ω–æ, –∫–æ—Ç–æ—Ä–æ–º—É, —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å, —Ñ—Ä–∞–∫—Ü–∏–∏, ¬´–ï–¥–∏–Ω–∞—è, –†–æ—Å—Å–∏—è, —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å, —Ñ—Ä–∞–∫—Ü–∏–∏, ¬´–ï–¥–∏–Ω–∞—è, –†–æ—Å—Å–∏—è¬ª, –≤, –ì–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω–æ–π, –î—É–º–µ, –ï–¥–∏–Ω–∞—è, –†–æ—Å—Å–∏—è, ¬ª, –≤, –ì–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω–æ–π, –î—É–º–µ, –ê–Ω–¥—Ä–µ–π, –í–æ—Ä–æ–±—å—ë–≤, –Ω–∞–∑–Ω–∞—á–µ–Ω, –Ω–∞, –¥–æ–ª–∂–Ω–æ—Å—Ç—å, –∏—Å–ø–æ–ª–Ω—è—é—â–µ–≥–æ, –æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏, –≥—É–±–µ—Ä–Ω–∞—Ç–æ—Ä–∞, –∏—Å–ø–æ–ª–Ω—è—é—â–µ–≥–æ, –æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏, –≥—É–±–µ—Ä–Ω–∞—Ç–æ—Ä–∞, –ú–æ—Å–∫–æ–≤—Å–∫–æ–π, –æ–±–ª–∞—Å—Ç–∏, –≥—É–±–µ—Ä–Ω–∞—Ç–æ—Ä–∞, –ú–æ—Å–∫–æ–≤—Å–∫–æ–π, –æ–±–ª–∞—Å—Ç–∏, ., –û–±, —ç—Ç–æ–º, –ü—Ä–µ–∑–∏–¥–µ–Ω—Ç, –ü—Ä–µ–∑–∏–¥–µ–Ω—Ç, –†–æ—Å—Å–∏–∏, –†–æ—Å—Å–∏–∏, —Å–æ–æ–±—â–∏–ª, –¥–µ–ø—É—Ç–∞—Ç—É, –≤–æ, –≤—Ä–µ–º—è, –ª–∏—á–Ω–æ–π, –≤—Å—Ç—Ä–µ—á–∏, –≤, –ö—Ä–µ–º–ª–µ, :, —Ö–æ—Ç–µ–ª, –±—ã, –í–∞–º, –ø—Ä–µ–¥–ª–æ–∂–∏—Ç—å, –¥—Ä—É–≥—É—é, —Ä–∞–±–æ—Ç—É,, —Å–≤—è–∑–∞–Ω–Ω—É—é, —Å, –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π, –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é,, –∏–º–µ—è, –≤, –≤–∏–¥—É, ‚Äì, –í—ã,, –Ω–∞–≤–µ—Ä–Ω–æ–µ,, —É–∂–µ, –¥–æ–≥–∞–¥–∞–ª–∏—Å—å, ‚Äì, –¥–æ–ª–∂–Ω–æ—Å—Ç—å, ...]</td>\n",
       "      <td>[B-PERSON, B-EVENT, B-PROFESSION, I-PROFESSION, B-PROFESSION, I-PROFESSION, I-PROFESSION, I-PROFESSION, B-PROFESSION, B-STATE_OR_PROVINCE, I-STATE_OR_PROVINCE, B-IDEOLOGY, B-PERSON, I-PERSON, B-PERSON, I-PERSON, O, B-PERSON, I-PERSON, O, B-DATE, I-DATE, I-DATE, I-DATE, B-PERSON, I-PERSON, B-EVENT, I-EVENT, O, O, O, B-PROFESSION, I-PROFESSION, I-PROFESSION, I-PROFESSION, B-PROFESSION, I-PROFESSION, I-PROFESSION, I-PROFESSION, I-PROFESSION, I-PROFESSION, I-PROFESSION, B-ORGANIZATION, I-ORGANIZATION, O, O, B-ORGANIZATION, I-ORGANIZATION, B-PERSON, I-PERSON, B-EVENT, I-EVENT, I-EVENT, B-PROFESSION, I-PROFESSION, I-PROFESSION, B-PROFESSION, I-PROFESSION, I-PROFESSION, I-PROFESSION, I-PROFESSION, B-PROFESSION, B-STATE_OR_PROVINCE, I-STATE_OR_PROVINCE, O, O, O, B-PROFESSION, B-PROFESSION, I-PROFESSION, B-COUNTRY, O, B-PROFESSION, O, O, B-EVENT, I-EVENT, O, B-FACILITY, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>–ü–æ–ª–∏—Ü–∏—è –Ω–µ –≤–ø—É—Å—Ç–∏–ª–∞ –î–∂–∏–≥–∞—Ä—Ö–∞–Ω—è–Ω–∞ –≤ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—É—é –∫–≤–∞—Ä—Ç–∏—Ä—É\\n–ú–æ—Å–∫–æ–≤—Å–∫–∏–π –¥—Ä–∞–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ç–µ–∞—Ç—Ä –ø–æ–¥ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ–º –ê—Ä–º–µ–Ω–∞ –î–∂–∏–≥–∞—Ä—Ö–∞–Ω—è–Ω–∞\\n–ü–æ—Å–ª–µ –≤—ã–ø–∏—Å–∫–∏ –∏–∑ –±–æ–ª—å–Ω–∏—Ü—ã –Ω–∞—Ä–æ–¥–Ω—ã–π –∞—Ä—Ç–∏—Å—Ç –°–°–°–† –ê—Ä–º–µ–Ω –î–∂–∏–≥–∞—Ä—Ö–∞–Ω—è–Ω –Ω–µ—Å–∫–æ–ª—å–∫–æ –¥–Ω–µ–π –∂–∏–ª –≤ —Å–≤–æ—ë–º —Ä–∞–±–æ—á–µ–º –∫–∞–±–∏–Ω–µ—Ç–µ –≤ —Ç–µ–∞—Ç—Ä–µ. –ü–æ—Ç–æ–º –¥—Ä—É–∑—å—è —Å–Ω—è–ª–∏ –µ–º—É —Ç—Ä—ë—Ö–∫–æ–º–Ω–∞—Ç–Ω—É—é –∫–≤–∞—Ä—Ç–∏—Ä—É –Ω–∞ –õ–æ–º–æ–Ω–æ—Å–æ–≤—Å–∫–æ–º –ø—Ä–æ—Å–ø–µ–∫—Ç–µ. –ê 30 –æ–∫—Ç—è–±—Ä—è –∞–∫—Ç—ë—Ä –ø–æ–ø—ã—Ç–∞–ª—Å—è –ø–æ–ø–∞—Å—Ç—å –≤ –∫–≤–∞—Ä—Ç–∏—Ä—É –Ω–∞ –ú–æ–ª–æ–¥–æ–≥–≤–∞—Ä–¥–µ–π—Å–∫–æ–π —É–ª–∏—Ü–µ –ú–æ—Å–∫–≤—ã, —á—Ç–æ–±—ã –∑–∞–±—Ä–∞—Ç—å –∫–∞–∫–∏–µ-—Ç–æ –≤–µ—â–∏, –æ–¥–Ω–∞–∫–æ –ø–æ–ª–∏—Ü–∏—è –µ–≥–æ –∑–∞–¥–µ—Ä–∂–∞–ª–∞.\\n\\n¬´–≠—Ç–æ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å –∂–µ–Ω—ã –ê—Ä–º–µ–Ω–∞ –ë–æ—Ä–∏—Å–æ–≤–∏—á–∞, –Ω–∏–∫–∞–∫–∏—Ö –ø—Ä–∞–≤ —É –î–∂–∏–≥–∞—Ä—Ö–∞–Ω—è–Ω–∞ –Ω–∞ —ç—Ç—É –∫–≤–∞—Ä—Ç–∏—Ä—É –Ω–µ—Ç. –ê –æ–Ω –≤–º–µ—Å—Ç–µ —Å–æ —Å–≤–æ–∏–º –¥—Ä—É–≥–æ–º –ê—Ä—Ç—É—Ä–æ–º –°–æ–≥–æ–º–æ–Ω—è–Ω–æ–º —Ö–æ—Ç–µ–ª–∏ –≤—Å–∫—Ä—ã—Ç—å –∑–∞–º–∫–∏, –≤–∑–ª–æ–º–∞—Ç—å –¥–≤–µ—Ä—å –∏ –ø—Ä–æ–Ω–∏–∫–Ω—É—Ç—å —Ç—É–¥–∞. –†–∞–∑—É–º–µ–µ—Ç—Å—è, –ø—Ä–∏–±—ã–≤—à–∏–π –ø–æ –≤—ã–∑–æ–≤—É –Ω–∞—Ä—è–¥ –ø–æ–ª–∏—Ü–∏–∏ —Å—Ö–≤–∞—Ç–∏–ª –∞–∫—Ç—ë—Ä–∞, –∏ –∫–≤–∞—Ä—Ç–∏—Ä—É —Ö–æ—Ç—å –∏ —Å –±–æ–µ–º, –Ω–æ —É–¥–∞–ª–æ—Å—å –æ—Ç—Å—Ç–æ—è—Ç—å –æ—Ç –ø–æ—Å—è–≥–∞—Ç–µ–ª—å—Å—Ç–≤–∞¬ª, ‚Äì —Ä–∞—Å—Å–∫–∞–∑–∞–ª–∞ –±–ª–∏–∑–∫–∞—è –ø–æ–¥—Ä—É–≥–∞ —Å—É–ø—Ä—É–≥–∏ –î–∂–∏–≥–∞—Ä—Ö–∞–Ω—è–Ω–∞ –í–∏—Ç–∞–ª–∏–Ω—ã –¶—ã–º–±–∞–ª—é–∫-–†–æ–º–∞–Ω–æ–≤—Å–∫–æ–π.\\n\\n–†–∞–Ω–µ–µ —Å—Ç–∞–ª–æ –∏–∑–≤–µ—Å—Ç–Ω–æ, —á—Ç–æ –¶—ã–º–±–∞–ª—é–∫-–†–æ–º–∞–Ω–æ–≤—Å–∫–∞—è —Å–±–µ–∂–∞–ª–∞ –∏–∑ –†–æ—Å—Å–∏–∏. –û–± —ç—Ç–æ–º –≤ —ç—Ñ–∏—Ä–µ —Ç–æ–∫-—à–æ—É –ê–Ω–¥—Ä–µ—è –ú–∞–ª–∞—Ö–æ–≤–∞ ¬´–ü—Ä—è–º–æ–π —ç—Ñ–∏—Ä¬ª 30 –æ–∫—Ç—è–±—Ä—è –∑–∞—è–≤–∏–ª–∞ –µ—ë –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ–ª—å –≠–ª–∏–Ω–∞ –ú–∞–∑—É—Ä. –û—Ç–º–µ—á–∞–µ—Ç—Å—è, —á—Ç–æ –¶—ã–º–±–∞–ª—é–∫-–†–æ–º–∞–Ω–æ–≤—Å–∫–∞—è –ø–æ–∫–∏–Ω—É–ª–∞ —Å—Ç—Ä–∞–Ω—É –≤–º–µ—Å—Ç–µ —Å–æ —Å–≤–æ–∏–º–∏ —Ä–æ–¥–∏—Ç–µ–ª—è–º–∏ ¬´–≤ –æ–±—Å—Ç–∞–Ω–æ–≤–∫–µ —Å—Ç—Ä–æ–∂–∞–π—à–µ–π —Å–µ–∫—Ä–µ—Ç–Ω–æ—Å—Ç–∏¬ª. –ü—Ä–µ–¥–ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ, –æ–Ω–∏ –Ω–∞–ø—Ä–∞–≤–∏–ª–∏—Å—å –≤ –ù—å—é-–ô–æ—Ä–∫, –¢–µ–ª—å-–ê–≤–∏–≤ –∏–ª–∏ –ö–∏–µ–≤.\\n\\n26 –æ–∫—Ç—è–±—Ä—è –≤ –ú–æ—Å–∫–æ–≤—Å–∫–æ–º –¥—Ä–∞–º–∞—Ç–∏—á–µ—Å–∫–æ–º —Ç–µ–∞—Ç—Ä–µ –ê—Ä–º–µ–Ω–∞ –î–∂–∏–≥–∞—Ä—Ö–∞–Ω—è–Ω–∞ –ø—Ä–æ—à–ª–∏ –æ–±—ã—Å–∫–∏. –≠—Ç–æ –±—ã–ª–æ —Å–≤—è–∑–∞–Ω–æ —Å –æ–±—Ä–∞—â–µ–Ω–∏–µ–º 82-–ª–µ—Ç–Ω–µ–≥–æ –∞–∫—Ç–µ—Ä–∞ –≤ –ø—Ä–∞–≤–æ–æ—Ö—Ä–∞–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –æ—Ä–≥–∞–Ω—ã —Å –∑–∞—è–≤–ª–µ–Ω–∏–µ–º –æ –∫—Ä–∞–∂–µ –æ–±—â–µ–≥—Ä–∞–∂–¥–∞–Ω—Å–∫–æ–≥–æ –ø–∞—Å–ø–æ—Ä—Ç–∞. –û–Ω –ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ—Ç –≤ —ç—Ç–æ–º —Å–≤–æ—é —Å—É–ø—Ä—É–≥—É, –∫–æ—Ç–æ—Ä–∞—è –º–ª–∞–¥—à–µ –Ω–µ–≥–æ –Ω–∞ 50 –ª–µ—Ç.\\n</td>\n",
       "      <td>[–ü–æ–ª–∏—Ü–∏—è, –Ω–µ, –≤–ø—É—Å—Ç–∏–ª–∞, –î–∂–∏–≥–∞—Ä—Ö–∞–Ω—è–Ω–∞, –≤, —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—É—é, –∫–≤–∞—Ä—Ç–∏—Ä—É, –ú–æ—Å–∫–æ–≤—Å–∫–∏–π, –¥—Ä–∞–º–∞—Ç–∏—á–µ—Å–∫–∏–π, —Ç–µ–∞—Ç—Ä, –ú–æ—Å–∫–æ–≤—Å–∫–∏–π, –¥—Ä–∞–º–∞—Ç–∏—á–µ—Å–∫–∏–π, —Ç–µ–∞—Ç—Ä, –ø–æ–¥, —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ–º, –ê—Ä–º–µ–Ω–∞, –î–∂–∏–≥–∞—Ä—Ö–∞–Ω—è–Ω–∞, –ü–æ—Å–ª–µ, –≤—ã–ø–∏—Å–∫–∏, –∏–∑, –±–æ–ª—å–Ω–∏—Ü—ã, –Ω–∞—Ä–æ–¥–Ω—ã–π, –∞—Ä—Ç–∏—Å—Ç, –°–°–°–†, –Ω–∞—Ä–æ–¥–Ω—ã–π, –∞—Ä—Ç–∏—Å—Ç, –∞—Ä—Ç–∏—Å—Ç, –°–°–°–†, –ê—Ä–º–µ–Ω, –î–∂–∏–≥–∞—Ä—Ö–∞–Ω—è–Ω, –Ω–µ—Å–∫–æ–ª—å–∫–æ, –¥–Ω–µ–π, –∂–∏–ª, –≤, —Å–≤–æ—ë–º, —Ä–∞–±–æ—á–µ–º, –∫–∞–±–∏–Ω–µ—Ç–µ, –≤, —Ç–µ–∞—Ç—Ä–µ., –ü–æ—Ç–æ–º, –¥—Ä—É–∑—å—è, —Å–Ω—è–ª–∏, –µ–º—É, —Ç—Ä—ë—Ö–∫–æ–º–Ω–∞—Ç–Ω—É—é, –∫–≤–∞—Ä—Ç–∏—Ä—É, –Ω–∞, –õ–æ–º–æ–Ω–æ—Å–æ–≤—Å–∫–æ–º, –ø—Ä–æ—Å–ø–µ–∫—Ç–µ, ., –ê, 30, –æ–∫—Ç—è–±—Ä—è, –∞–∫—Ç—ë—Ä, –ø–æ–ø—ã—Ç–∞–ª—Å—è, –ø–æ–ø–∞—Å—Ç—å, –≤, –∫–≤–∞—Ä—Ç–∏—Ä—É, –Ω–∞, –ú–æ–ª–æ–¥–æ–≥–≤–∞—Ä–¥–µ–π—Å–∫–æ–π, —É–ª–∏—Ü–µ, –ú–æ—Å–∫–≤—ã, ,, —á—Ç–æ–±—ã, –∑–∞–±—Ä–∞—Ç—å, –∫–∞–∫–∏–µ-—Ç–æ, –≤–µ—â–∏,, –æ–¥–Ω–∞–∫–æ, –ø–æ–ª–∏—Ü–∏—è, –µ–≥–æ, –∑–∞–¥–µ—Ä–∂–∞–ª–∞, ., ¬´–≠—Ç–æ, —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å, –∂–µ–Ω—ã, –ê—Ä–º–µ–Ω–∞, –ë–æ—Ä–∏—Å–æ–≤–∏—á–∞, ,, –Ω–∏–∫–∞–∫–∏—Ö, –ø—Ä–∞–≤, —É, –î–∂–∏–≥–∞—Ä—Ö–∞–Ω—è–Ω–∞, –Ω–∞, —ç—Ç—É, –∫–≤–∞—Ä—Ç–∏—Ä—É, –Ω–µ—Ç., –ê, –æ–Ω, –≤–º–µ—Å—Ç–µ, —Å–æ, —Å–≤–æ–∏–º, –¥—Ä—É–≥–æ–º, –ê—Ä—Ç—É—Ä–æ–º, –°–æ–≥–æ–º–æ–Ω—è–Ω–æ–º, —Ö–æ—Ç–µ–ª–∏, –≤—Å–∫—Ä—ã—Ç—å, –∑–∞–º–∫–∏,, –≤–∑–ª–æ–º–∞—Ç—å, –¥–≤–µ—Ä—å, –∏, –ø—Ä–æ–Ω–∏–∫–Ω—É—Ç—å, ...]</td>\n",
       "      <td>[B-ORGANIZATION, O, O, B-PERSON, O, O, O, B-ORGANIZATION, I-ORGANIZATION, I-ORGANIZATION, B-CITY, O, O, O, O, B-PERSON, I-PERSON, O, O, O, O, B-AWARD, I-AWARD, I-AWARD, B-AWARD, I-AWARD, B-PROFESSION, B-COUNTRY, B-PERSON, I-PERSON, B-DATE, I-DATE, O, O, O, O, O, O, O, O, O, O, O, B-NUMBER, O, O, B-LOCATION, I-LOCATION, O, O, B-DATE, I-DATE, B-PROFESSION, O, O, O, O, O, B-LOCATION, I-LOCATION, B-CITY, O, O, O, O, O, O, B-ORGANIZATION, O, B-EVENT, O, O, O, O, B-PERSON, I-PERSON, O, O, O, O, B-PERSON, O, O, O, O, O, O, O, O, O, O, B-PERSON, I-PERSON, O, O, O, O, O, O, O, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>–°–∫–æ—Ç–ª–µ–Ω–¥-–Ø—Ä–¥ –≤–ø–µ—Ä–≤—ã–µ –≤–æ–∑–≥–ª–∞–≤–∏–ª–∞ –∂–µ–Ω—â–∏–Ω–∞\\n–°–∫–æ—Ç–ª–µ–Ω–¥-–Ø—Ä–¥\\n–ü–æ–ª–∏—Ü–∏—é –õ–æ–Ω–¥–æ–Ω–∞ –≤–ø–µ—Ä–≤—ã–µ –∑–∞ 188 –ª–µ—Ç –≤–æ–∑–≥–ª–∞–≤–∏–ª–∞ –∂–µ–Ω—â–∏–Ω–∞. –ù–æ–≤—ã–º –≥–ª–∞–≤–æ–π –∫—Ä—É–ø–Ω–µ–π—à–µ–≥–æ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø–æ–ª–∏—Ü–∏–∏ –°–æ–µ–¥–∏–Ω—ë–Ω–Ω–æ–≥–æ –ö–æ—Ä–æ–ª–µ–≤—Å—Ç–≤–∞ —Å—Ç–∞–ª–∞ –ö—Ä–µ—Å—Å–∏–¥–∞ –î–∏–∫ (Cressida Dick), –±—ã–≤—à–∏–π —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –Ω–∞—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π –∞–Ω—Ç–∏—Ç–µ—Ä—Ä–æ—Ä–∏—Å—Ç–∏—á–µ—Å–∫–æ–π —Å–ª—É–∂–±—ã –í–µ–ª–∏–∫–æ–±—Ä–∏—Ç–∞–Ω–∏–∏.\\n\\n–°–æ–æ–±—â–∞–µ—Ç—Å—è, —á—Ç–æ 56-–ª–µ—Ç–Ω—è—è –î–∏–∫ –ø—Ä–∏–º–µ—Ç —ç—Ç–æ—Ç –ø–æ—Å—Ç —É –∑–∞–Ω–∏–º–∞–≤—à–µ–≥–æ –µ–≥–æ —Å 2011 –≥–æ–¥–∞ —Å—ç—Ä–∞ –ë–µ—Ä–Ω–∞—Ä–¥–∞ –•–æ–≥–∞–Ω–∞-–•–∞—É (Bernard Hogan-Howe). –î–æ –Ω–∞—Å—Ç–æ—è—â–µ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –æ–Ω–∞ –∑–∞–Ω–∏–º–∞–ª–∞ –ø–æ—Å—Ç –≤ –º–∏–Ω–∏—Å—Ç–µ—Ä—Å—Ç–≤–µ –∏–Ω–æ—Å—Ç—Ä–∞–Ω–Ω—ã—Ö –¥–µ–ª, –æ–¥–Ω–∞–∫–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –µ—ë —Ä–∞–±–æ—Ç—ã —Ç–∞–º –Ω–µ —Ä–∞—Å–∫—Ä—ã–≤–∞–µ—Ç—Å—è.\\n\\n–î–∏–∫ –æ—Ç–¥–∞–ª–∞ —Å–ª—É–∂–±–µ –≤ –°–∫–æ—Ç–ª–µ–Ω–¥-–Ø—Ä–¥–µ –±–æ–ª–µ–µ 30 –ª–µ—Ç, –Ω–æ –≤ 2014 –≥–æ–¥—É –ø–æ–∫–∏–Ω—É–ª–∞ –µ—ë. –í —Å–≤–æ—ë–º –ø–µ—Ä–≤–æ–º –∑–∞—è–≤–ª–µ–Ω–∏–∏ –ø–æ—Å–ª–µ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è –Ω–æ–≤—ã–π –≥–ª–∞–≤–∞ —Å—Ç–æ–ª–∏—á–Ω–æ–π –ø–æ–ª–∏—Ü–∏–∏ —Å–∫–∞–∑–∞–ª–∞, —á—Ç–æ –æ–Ω–∞ ¬´–ø—Ä–æ—Å—Ç–æ –≤ –≤–æ—Å—Ç–æ—Ä–≥–µ¬ª –∏ –æ—á–µ–Ω—å —Ä–∞–¥–∞ –≤–µ—Ä–Ω—É—Ç—å—Å—è:\\n–≠—Ç–æ –±–æ–ª—å—à–∞—è –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å –∏ —É–¥–∏–≤–∏—Ç–µ–ª—å–Ω–∞—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å. –Ø –∂–¥—É —Å –æ–≥—Ä–æ–º–Ω—ã–º –Ω–µ—Ç–µ—Ä–ø–µ–Ω–∏–µ–º, –∫–æ–≥–¥–∞ —Å–º–æ–≥—É –Ω–∞—á–∞—Ç—å –∑–∞—â–∏—â–∞—Ç—å –Ω–∞—Å–µ–ª–µ–Ω–∏–µ –õ–æ–Ω–¥–æ–Ω–∞ –∏ —Å–ª—É–∂–∏—Ç—å –µ–º—É.\\n\\n–§–æ—Ä–º–∞–ª—å–Ω–æ –¥–ª—è –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ —ç—Ç–æ—Ç –ø–æ—Å—Ç –î–∏–∫ –¥–æ–ª–∂–Ω–∞ –±—ã–ª–∞ –ø–æ–ª—É—á–∏—Ç—å –æ–¥–æ–±—Ä–µ–Ω–∏–µ –º—ç—Ä–∞ –õ–æ–Ω–¥–æ–Ω–∞ –°–∞–¥–∏–∫–∞ –•–∞–Ω–∞.\\n\\n–†–µ—à–µ–Ω–∏–µ –±—ã–ª–æ –ø—Ä–∏–Ω—è—Ç–æ —Å—Ç–æ–ª–∏—á–Ω—ã–º –≥—Ä–∞–¥–æ–Ω–∞—á–∞–ª—å–Ω–∏–∫–æ–º –Ω–µ—Å–º–æ—Ç—Ä—è –Ω–∞ –æ–±—Ä–∞—â–µ–Ω–∏–µ —Ä–æ–¥–Ω—ã—Ö –ø–æ–≥–∏–±—à–µ–≥–æ –≤ 2005 –≥–æ–¥—É –±—Ä–∞–∑–∏–ª—å—Ü–∞ –ñ–∞–Ω–∞-–®–∞—Ä–ª—è –¥–µ –ú–µ–Ω–µ–∑–∏—à–∞, –ø—Ä–∏–∑—ã–≤–∞—è –µ–≥–æ –æ—Ç–∫–∞–∑–∞—Ç—å –≤ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏–∏ –∫–∞–Ω–¥–∏–¥–∞—Ç—É—Ä—ã.\\n–ò–º–µ–Ω–Ω–æ –î–∏–∫ –∫–æ–º–∞–Ω–¥–æ–≤–∞–ª–∞ —Å–ø–µ—Ü–æ–ø–µ—Ä–∞—Ü–∏–µ–π –ø–æ—Å–ª–µ —Å–µ—Ä–∏–∏ –≤–∑—Ä—ã–≤–æ–≤ –≤ –õ–æ–Ω–¥–æ–Ω–µ, –≤ —Ö–æ–¥–µ –∫–æ—Ç–æ—Ä–æ–π –±—ã–ª —Å–ª—É—á–∞–π–Ω–æ —É–±–∏—Ç –±—Ä–∞–∑–∏–ª–µ—Ü, –ø–æ –æ—à–∏–±–∫–µ –ø—Ä–∏–Ω—è—Ç—ã–π –∑–∞ —Ç–µ—Ä—Ä–æ—Ä–∏—Å—Ç–∞.\\n–•–æ—Ç—è –≤ —Ö–æ–¥–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞–≤—à–µ–≥–æ –∑–∞ —ç—Ç–∏–º —Å—É–¥–µ–±–Ω–æ–≥–æ —Ä–∞–∑–±–∏—Ä–∞—Ç–µ–ª—å—Å—Ç–≤–∞ –ö—Ä–µ—Å—Å–∏–¥—É –ø—Ä–∏–∑–Ω–∞–ª–∏ –Ω–µ–≤–∏–Ω–æ–≤–Ω–æ–π, –º–Ω–æ–≥–∏–µ –ø–æ–ª–∞–≥–∞–ª–∏, —á—Ç–æ —ç—Ç–æ—Ç –∏–Ω—Ü–∏–¥–µ–Ω—Ç –ø–æ–ª–æ–∂–∏—Ç –∫–æ–Ω–µ—Ü –µ—ë –∫–∞—Ä—å–µ—Ä–µ.\\n–û–¥–Ω–∞–∫–æ –º—ç—Ä –¥–∞–ª —Å–≤–æ—ë —Å–æ–≥–ª–∞—Å–∏–µ, –Ω–∞–∑–≤–∞–≤ –≤—ã–±–æ—Ä –î–∏–∫ ¬´–∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–º —Ä–µ—à–µ–Ω–∏–µ–º¬ª.\\n\\n–° –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ–º –î–∏–∫ —Ç–µ–ø–µ—Ä—å —É–∂–µ –ø—è—Ç—å –≤—ã—Å—à–∏—Ö –ø–æ—Å—Ç–æ–≤ –≤ —Å–∏—Å—Ç–µ–º–µ —É–≥–æ–ª–æ–≤–Ω–æ–≥–æ –ø—Ä–∞–≤–æ—Å—É–¥–∏—è –≤ –í–µ–ª–∏–∫–æ–±—Ä–∏—Ç–∞–Ω–∏–∏ –≤–æ–∑–≥–ª–∞–≤–ª—è—é—Ç –∂–µ–Ω—â–∏–Ω—ã, –≤–∫–ª—é—á–∞—è –∫–æ—Ä–æ–ª–µ–≤—Å–∫—É—é –ø—Ä–æ–∫—É—Ä–æ—Ä—Å–∫—É—é —Å–ª—É–∂–±—É, –Ω–∞—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π —Å–æ–≤–µ—Ç –Ω–∞—á–∞–ª—å–Ω–∏–∫–æ–≤ –ø–æ–ª–∏—Ü–∏–∏ –∏ –Ω–∞—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ –∞–≥–µ–Ω—Ç—Å—Ç–≤–æ –ø–æ –ø—Ä–µ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏.\\n\\n–ù–æ–≤—ã–π –≥–ª–∞–≤–∞ –°–∫–æ—Ç–ª–µ–Ω–¥-–Ø—Ä–¥–∞ –±—É–¥–µ—Ç –ø—Ä–∏–≤–µ–¥–µ–Ω–∞ –∫ –ø—Ä–∏—Å—è–≥–µ –ø–µ—Ä–µ–¥ –∫–æ—Ä–æ–ª–µ–≤–æ–π, –µ–π –ø–æ–ª–∞–≥–∞–µ—Ç—Å—è –æ–∫–ª–∞–¥ –≤ —Ä–∞–∑–º–µ—Ä–µ 270 —Ç—ã—Å—è—á —Ñ—É–Ω—Ç–æ–≤ –≤ –≥–æ–¥ (–±–µ–∑ —É—á—ë—Ç–∞ –ø—Ä–µ–º–∏–π). –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ –±—É–¥–µ—Ç –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–æ –∫–æ—Ä–æ–ª–µ–≤—Å–∫–∏–º —É–∫–∞–∑–æ–º –Ω–∞ —Å—Ä–æ–∫ –≤ –ø—è—Ç—å –ª–µ—Ç, –∫–æ—Ç–æ—Ä—ã–π –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—Ä–æ–¥–ª—ë–Ω.\\n</td>\n",
       "      <td>[–°–∫–æ—Ç–ª–µ–Ω–¥-–Ø—Ä–¥, –≤–ø–µ—Ä–≤—ã–µ, –≤–æ–∑–≥–ª–∞–≤–∏–ª–∞, –∂–µ–Ω—â–∏–Ω–∞, –°–∫–æ—Ç–ª–µ–Ω–¥-–Ø—Ä–¥, –ü–æ–ª–∏—Ü–∏—é, –õ–æ–Ω–¥–æ–Ω–∞, –ü–æ–ª–∏—Ü–∏—é, –õ–æ–Ω–¥–æ–Ω–∞, –≤–ø–µ—Ä–≤—ã–µ, –∑–∞, 188, –ª–µ—Ç, –≤–æ–∑–≥–ª–∞–≤–∏–ª–∞, –∂–µ–Ω—â–∏–Ω–∞, ., –ù–æ–≤—ã–º, –≥–ª–∞–≤–æ–π, –∫—Ä—É–ø–Ω–µ–π—à–µ–≥–æ, —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è, –ø–æ–ª–∏—Ü–∏–∏, –°–æ–µ–¥–∏–Ω—ë–Ω–Ω–æ–≥–æ, –ö–æ—Ä–æ–ª–µ–≤—Å—Ç–≤–∞, —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è, –ø–æ–ª–∏—Ü–∏–∏, –°–æ–µ–¥–∏–Ω—ë–Ω–Ω–æ–≥–æ, –ö–æ—Ä–æ–ª–µ–≤—Å—Ç–≤–∞, –ø–æ–ª–∏—Ü–∏–∏, –°–æ–µ–¥–∏–Ω—ë–Ω–Ω–æ–≥–æ, –ö–æ—Ä–æ–ª–µ–≤—Å—Ç–≤–∞, –°–æ–µ–¥–∏–Ω—ë–Ω–Ω–æ–≥–æ, –ö–æ—Ä–æ–ª–µ–≤—Å—Ç–≤–∞, —Å—Ç–∞–ª–∞, –ö—Ä–µ—Å—Å–∏–¥–∞, –î–∏–∫, (, Cressida, Dick, ),, –±—ã–≤—à–∏–π, —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å, –Ω–∞—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π, –∞–Ω—Ç–∏—Ç–µ—Ä—Ä–æ—Ä–∏—Å—Ç–∏—á–µ—Å–∫–æ–π, —Å–ª—É–∂–±—ã, –í–µ–ª–∏–∫–æ–±—Ä–∏—Ç–∞–Ω–∏–∏, –Ω–∞—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π, –∞–Ω—Ç–∏—Ç–µ—Ä—Ä–æ—Ä–∏—Å—Ç–∏—á–µ—Å–∫–æ–π, —Å–ª—É–∂–±—ã, –í–µ–ª–∏–∫–æ–±—Ä–∏—Ç–∞–Ω–∏–∏, –í–µ–ª–∏–∫–æ–±—Ä–∏—Ç–∞–Ω–∏–∏, ., –°–æ–æ–±—â–∞–µ—Ç—Å—è,, —á—Ç–æ, 56-–ª–µ—Ç–Ω—è—è, –î–∏–∫, –ø—Ä–∏–º–µ—Ç, —ç—Ç–æ—Ç, –ø–æ—Å—Ç, —É, –∑–∞–Ω–∏–º–∞–≤—à–µ–≥–æ, –µ–≥–æ, —Å, 2011, –≥–æ–¥–∞, —Å—ç—Ä–∞, –ë–µ—Ä–Ω–∞—Ä–¥–∞, –•–æ–≥–∞–Ω–∞-–•–∞—É, (, Bernard, Hogan-Howe, )., –î–æ, –Ω–∞—Å—Ç–æ—è—â–µ–≥–æ, –≤—Ä–µ–º–µ–Ω–∏, –æ–Ω–∞, –∑–∞–Ω–∏–º–∞–ª–∞, –ø–æ—Å—Ç, –≤, –º–∏–Ω–∏—Å—Ç–µ—Ä—Å—Ç–≤–µ, –∏–Ω–æ—Å—Ç—Ä–∞–Ω–Ω—ã—Ö, –¥–µ–ª, ,, –æ–¥–Ω–∞–∫–æ, —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ, –µ—ë, —Ä–∞–±–æ—Ç—ã, —Ç–∞–º, –Ω–µ, —Ä–∞—Å–∫—Ä—ã–≤–∞–µ—Ç—Å—è., –î–∏–∫, –æ—Ç–¥–∞–ª–∞, —Å–ª—É–∂–±–µ, –≤, –°–∫–æ—Ç–ª–µ–Ω–¥-–Ø—Ä–¥–µ, –±–æ–ª–µ–µ, 30, –ª–µ—Ç, ,, –Ω–æ, –≤, ...]</td>\n",
       "      <td>[B-ORGANIZATION, O, B-EVENT, I-EVENT, B-ORGANIZATION, B-ORGANIZATION, I-ORGANIZATION, B-ORGANIZATION, B-CITY, O, O, B-DATE, I-DATE, B-EVENT, I-EVENT, O, O, B-PROFESSION, I-PROFESSION, I-PROFESSION, I-PROFESSION, I-PROFESSION, I-PROFESSION, B-ORGANIZATION, I-ORGANIZATION, I-ORGANIZATION, I-ORGANIZATION, B-ORGANIZATION, I-ORGANIZATION, I-ORGANIZATION, B-COUNTRY, I-COUNTRY, O, B-PERSON, I-PERSON, O, B-PERSON, I-PERSON, O, O, B-PROFESSION, I-PROFESSION, I-PROFESSION, I-PROFESSION, I-PROFESSION, B-ORGANIZATION, I-ORGANIZATION, I-ORGANIZATION, I-ORGANIZATION, B-COUNTRY, O, O, O, B-AGE, B-PERSON, O, O, O, O, O, O, B-DATE, I-DATE, I-DATE, B-PROFESSION, B-PERSON, I-PERSON, O, B-PERSON, I-PERSON, O, O, O, O, O, O, O, O, B-ORGANIZATION, I-ORGANIZATION, I-ORGANIZATION, O, O, O, O, O, O, O, O, B-PERSON, O, O, O, B-ORGANIZATION, B-DATE, I-DATE, I-DATE, O, O, B-DATE, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>–°–µ–ª–µ–Ω–µ –ì–æ–º–µ—Å –ø–µ—Ä–µ—Å–∞–¥–∏–ª–∏ –ø–æ—á–∫—É –ª—É—á—à–µ–π –ø–æ–¥—Ä—É–≥–∏\\n–°–µ–ª–µ–Ω–∞ –ì–æ–º–µ—Å\\n–ê–º–µ—Ä–∏–∫–∞–Ω—Å–∫–∞—è –ø–µ–≤–∏—Ü–∞ –∏ –∞–∫—Ç—Ä–∏—Å–∞ –°–µ–ª–µ–Ω–∞ –ì–æ–º–µ—Å –ø—Ä–∏–∑–Ω–∞–ª–∞—Å—å –Ω–∞ —Å–≤–æ–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ –≤ Instagram, —á—Ç–æ –Ω–µ–¥–∞–≤–Ω–æ –ø–µ—Ä–µ–Ω–µ—Å–ª–∞ –æ–ø–µ—Ä–∞—Ü–∏—é –ø–æ –ø–µ—Ä–µ—Å–∞–¥–∫–µ –ø–æ—á–∫–∏.\\n\\n25-–ª–µ—Ç–Ω—è—è –¥–µ–≤—É—à–∫–∞ –≤—ã–ª–æ–∂–∏–ª–∞ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—é –≤ –±–æ–ª—å–Ω–∏—á–Ω–æ–π –ø–∞–ª–∞—Ç–µ —Å –ª—É—á—à–µ–π –ø–æ–¥—Ä—É–≥–æ–π –§—Ä–∞–Ω—Å–∏–µ–π –†–∞–π—Å–æ–π, –∫–æ—Ç–æ—Ä–∞—è —Å—Ç–∞–ª–∞ –µ—ë –¥–æ–Ω–æ—Ä–æ–º:\\n–ó–Ω–∞—é, –º–Ω–æ–≥–∏–µ –º–æ–∏ –ø–æ–∫–ª–æ–Ω–Ω–∏–∫–∏ –∑–∞–º–µ—Ç–∏–ª–∏, —á—Ç–æ —á–∞—Å—Ç—å –ª–µ—Ç–∞ –æ–±–æ –º–Ω–µ –Ω–∏—á–µ–≥–æ –Ω–µ –±—ã–ª–æ —Å–ª—ã—à–Ω–æ, –∏ –∑–∞–¥–∞–≤–∞–ª–∏—Å—å –≤–æ–ø—Ä–æ—Å–æ–º, –ø–æ—á–µ–º—É —è –Ω–µ –ø—Ä–æ–¥–≤–∏–≥–∞—é —Å–≤–æ–∏ –ø–µ—Å–Ω–∏, –∫–æ—Ç–æ—Ä—ã–º–∏ –æ—á–µ–Ω—å –≥–æ—Ä–∂—É—Å—å. –í –æ–±—â–µ–º, —Å—Ç–∞–ª–æ –∏–∑–≤–µ—Å—Ç–Ω–æ, —á—Ç–æ –∏–∑-–∑–∞ –≤–æ–ª—á–∞–Ω–∫–∏ –º–Ω–µ –Ω—É–∂–Ω–æ –±—ã–ª–æ —Å–¥–µ–ª–∞—Ç—å —Ç—Ä–∞–Ω—Å–ø–ª–∞–Ω—Ç–∞—Ü–∏—é –ø–æ—á–∫–∏. –≠—Ç–æ –±—ã–ª–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –¥–ª—è –º–æ–µ–≥–æ –∑–¥–æ—Ä–æ–≤—å—è. –°–µ–π—á–∞—Å —è —Ö–æ—á—É –ø—É–±–ª–∏—á–Ω–æ –ø–æ–±–ª–∞–≥–æ–¥–∞—Ä–∏—Ç—å —Å–≤–æ—é —Å–µ–º—å—é –∏ –Ω–µ–≤–µ—Ä–æ—è—Ç–Ω—É—é –∫–æ–º–∞–Ω–¥—É –≤—Ä–∞—á–µ–π –∑–∞ –≤—Å–µ —Ç–æ, —á—Ç–æ –æ–Ω–∏ –¥–ª—è –º–µ–Ω—è —Å–¥–µ–ª–∞–ª–∏ –¥–æ –∏ –ø–æ—Å–ª–µ –æ–ø–µ—Ä–∞—Ü–∏–∏. –ò, –Ω–∞–∫–æ–Ω–µ—Ü, –Ω–µ—Ç —Å–ª–æ–≤, —á—Ç–æ–±—ã –æ–ø–∏—Å–∞—Ç—å, –∫–∞–∫ —è –±–ª–∞–≥–æ–¥–∞—Ä–Ω–∞ –º–æ–µ–π –ø—Ä–µ–∫—Ä–∞—Å–Ω–æ–π –ø–æ–¥—Ä—É–≥–µ –§—Ä–∞–Ω—Å–∏–∏ –†–∞–π—Å–µ. –û–Ω–∞ —Å–¥–µ–ª–∞–ª–∞ –º–Ω–µ —É–¥–∏–≤–∏—Ç–µ–ª—å–Ω—ã–π –ø–æ–¥–∞—Ä–æ–∫, –ø–æ–∂–µ—Ä—Ç–≤–æ–≤–∞–≤ —Å–≤–æ—é –ø–æ—á–∫—É. –Ø –Ω–µ–≤–µ—Ä–æ—è—Ç–Ω–æ –±–ª–∞–≥–æ–¥–∞—Ä–Ω–∞. –Ø —Ç–∞–∫ —Å–∏–ª—å–Ω–æ –ª—é–±–ª—é —Ç–µ–±—è.\\n\\n–¢–∞–∫–∂–µ –æ–Ω–∞ –ø–æ–∫–∞–∑–∞–ª–∞ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—é —à—Ä–∞–º–∞ –ø–æ—Å–ª–µ –æ–ø–µ—Ä–∞—Ü–∏–∏.\\n\\n10 –∏—é–Ω—è 2011 –≥–æ–¥–∞ –°–µ–ª–µ–Ω–∞ –±—ã–ª–∞ —ç–∫—Å—Ç—Ä–µ–Ω–Ω–æ –≥–æ—Å–ø–∏—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ —Å —Ç–æ—à–Ω–æ—Ç–æ–π –∏ —Å–∏–ª—å–Ω—ã–º–∏ –≥–æ–ª–æ–≤–Ω—ã–º–∏ –±–æ–ª—è–º–∏ –ø–æ—Å–ª–µ —É—á–∞—Å—Ç–∏—è –≤ —à–æ—É ''The Tonight Show''.\\n–ü–µ—Ä–≤–æ–Ω–∞—á–∞–ª—å–Ω–æ —Å—á–∏—Ç–∞–ª–æ—Å—å, —á—Ç–æ –ø—Ä–∏—á–∏–Ω–æ–π –Ω–µ–¥—É–≥–∞ –ì–æ–º–µ—Å —Å—Ç–∞–ª–∏ —Ñ–∏–∑–∏—á–µ—Å–∫–æ–µ –∏—Å—Ç–æ—â–µ–Ω–∏–µ –∏ –ø–∏—â–µ–≤–æ–µ –æ—Ç—Ä–∞–≤–ª–µ–Ω–∏–µ.\\n\\n27 –¥–µ–∫–∞–±—Ä—è 2013 –≥–æ–¥–∞ —Ä—è–¥ –°–ú–ò —Å–æ–æ–±—â–∏–ª, —á—Ç–æ –ì–æ–º–µ—Å —É–∂–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –ª–µ—Ç —Å—Ç—Ä–∞–¥–∞–µ—Ç —Å–∏—Å—Ç–µ–º–Ω–æ–π –∫—Ä–∞—Å–Ω–æ–π –≤–æ–ª—á–∞–Ω–∫–æ–π.\\n\\n7 –æ–∫—Ç—è–±—Ä—è 2015 –≥–æ–¥–∞ –ì–æ–º–µ—Å –ø–æ–¥—Ç–≤–µ—Ä–¥–∏–ª–∞ —Å–≤–æ–π –¥–∏–∞–≥–Ω–æ–∑ –∏ —Å–æ–æ–±—â–∏–ª–∞, —á—Ç–æ –æ–Ω–∞ –ø—Ä–æ—à–ª–∞ –¥–≤–∞ –∫—É—Ä—Å–∞ —Ö–∏–º–∏–æ—Ç–µ—Ä–∞–ø–∏–∏, –∫–æ—Ç–æ—Ä—ã–µ –¥–æ–≤–µ–ª–∏ –µ—ë –¥–æ –ø—Ä–µ–¥–∏–Ω—Å—É–ª—å—Ç–Ω–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è –∏ –Ω–µ —Å—Ä–∞–∑—É –¥–∞–ª–∏ —ç—Ñ—Ñ–µ–∫—Ç.\\n\\n–í –∫–æ–Ω—Ü–µ –∞–≤–≥—É—Å—Ç–∞ 2016 –≥–æ–¥–∞ –ì–æ–º–µ—Å –±—ã–ª–∞ –≤—ã–Ω—É–∂–¥–µ–Ω–∞ –ø—Ä–µ—Ä–≤–∞—Ç—å —Å–≤–æ–π –∫–æ–Ω—Ü–µ—Ä—Ç–Ω—ã–π —Ç—É—Ä –ø–æ –º–∏—Ä—É Revival –∏–∑-–∑–∞ –æ–±–æ—Å—Ç—Ä–µ–Ω–∏—è –≤–æ–ª—á–∞–Ω–∫–∏.\\n–í —Ä–∞–∑–≥–∞—Ä–µ —Ç—É—Ä–Ω–µ –º–æ–ª–æ–¥–∞—è –ø–æ–ø-–∑–≤–µ–∑–¥–∞ —Å—Ç–æ–ª–∫–Ω—É–ª–∞—Å—å —Å –ø–æ–±–æ—á–Ω—ã–º–∏ —ç—Ñ—Ñ–µ–∫—Ç–∞–º–∏ —ç—Ç–æ–π –±–æ–ª–µ–∑–Ω–∏ ‚Äî –ø–∞–Ω–∏—á–µ—Å–∫–∏–º–∏ –∞—Ç–∞–∫–∞–º–∏ –∏ –¥–µ–ø—Ä–µ—Å—Å–∏–µ–π.\\n\\n–û–±—ä—è–≤–∏–≤ –æ–± —É—Ö—É–¥—à–µ–Ω–∏–∏ —Å–≤–æ–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è –∏ –æ—Ç–º–µ–Ω–µ –∫–æ–Ω—Ü–µ—Ä—Ç–æ–≤, –°–µ–ª–µ–Ω–∞ –ø—Ä–æ–ø–∞–ª–∞ –∏–∑ –ø–æ–ª—è –≤–∏–¥–∏–º–æ—Å—Ç–∏ –°–ú–ò –∏ –ø–æ–∫–ª–æ–Ω–Ω–∏–∫–æ–≤.\\n\\n–í—ã—è—Å–Ω–∏–ª–æ—Å—å, —á—Ç–æ –ø–µ–≤–∏—Ü–∞ –ø—Ä–æ—Ö–æ–¥–∏—Ç –ª–µ—á–µ–Ω–∏–µ –≤ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–º —Ö—Ä–∏—Å—Ç–∏–∞–Ω—Å–∫–æ–º —Ä–µ—Ö–∞–±–µ (–Ω–∞—Ä–∫–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–π –∫–ª–∏–Ω–∏–∫–µ), –∫–æ—Ç–æ—Ä—ã–π –∑–∞—Ç–µ—Ä—è–Ω –≤ –≥–ª—É—Ö–æ–º –ª–µ—Å—É.\\n–°—á–∏—Ç–∞–µ—Ç—Å—è, —á—Ç–æ –Ω–∞ –ø—Ä–∏—Ä–æ–¥–µ, –≤–¥–∞–ª–∏ –æ—Ç —Ü–∏–≤–∏–ª–∏–∑–∞—Ü–∏–∏, –ø—Ä–æ—Ü–µ—Å—Å –µ—ë –≤—ã–∑–¥–æ—Ä–æ–≤–ª–µ–Ω–∏—è –ø–æ–π–¥—ë—Ç –±—ã—Å—Ç—Ä–µ–µ.\\n\\n¬´–≠—Ç–æ –Ω–µ –∫–∞–∫–æ–π-—Ç–æ —Ç–∞–º –æ–≥—Ä–æ–º–Ω—ã–π —Ä–µ–∞–±–∏–ª–∏—Ç–∞—Ü–∏–æ–Ω–Ω—ã–π —Ü–µ–Ω—Ç—Ä –¥–ª—è –∑–Ω–∞–º–µ–Ω–∏—Ç–æ—Å—Ç–µ–π, ‚Äî —Å–æ–æ–±—â–∏–ª–æ —Ç–∞–±–ª–æ–∏–¥–∞–º –¥–æ–≤–µ—Ä–µ–Ω–Ω–æ–µ –ª–∏—Ü–æ –ø–µ–≤–∏—Ü—ã. ‚Äî –†–µ—Ö–∞–± –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —É–µ–¥–∏–Ω—ë–Ω–Ω–æ–º –º–µ—Å—Ç–µ –∏ —Ä–∞—Å—Å—á–∏—Ç–∞–Ω –∏—Å–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ –Ω–∞ –∂–µ–Ω—â–∏–Ω¬ª.\\n\\n–í –æ—Å–Ω–æ–≤–µ —Ç–µ—Ä–∞–ø–∏–∏, –∫–æ—Ç–æ—Ä—É—é –ø—Ä–∞–∫—Ç–∏–∫–æ–≤–∞–ª–∏ –≤ —Ä–µ—Ö–∞–±–µ, –ª–µ–∂–∞–ª–∞ —Ä–µ–ª–∏–≥–∏—è. ¬´–í–æ–∑–º–æ–∂–Ω–æ, —ç—Ç–æ –ø—Ä–∏–≤–ª–µ–∫–ª–æ –°–µ–ª–µ–Ω—É –ì–æ–º–µ—Å, –≤–µ–¥—å –æ–Ω–∞ –∏–∑ —Ä–µ–ª–∏–≥–∏–æ–∑–Ω–æ–π —Ö—Ä–∏—Å—Ç–∏–∞–Ω—Å–∫–æ–π —Å–µ–º—å–∏¬ª, ‚Äî —Å–æ–æ–±—â–∏—Ç –∏–Ω—Å–∞–π–¥–µ—Ä.\\n\\n–û–¥–Ω–∞–∫–æ, —Ç–∞–∫–∞—è —Ç–µ—Ä–∞–ø–∏—è –Ω–µ –º–æ–≥–ª–∞ –ø–æ–±–µ–¥–∏—Ç—å –±–æ–ª–µ–∑–Ω—å.\\n</td>\n",
       "      <td>[–°–µ–ª–µ–Ω–µ, –ì–æ–º–µ—Å, –ø–µ—Ä–µ—Å–∞–¥–∏–ª–∏, –ø–æ—á–∫—É, –ª—É—á—à–µ–π, –ø–æ–¥—Ä—É–≥–∏, –°–µ–ª–µ–Ω–∞, –ì–æ–º–µ—Å, –ê–º–µ—Ä–∏–∫–∞–Ω—Å–∫–∞—è, –ø–µ–≤–∏—Ü–∞, –∏, –∞–∫—Ç—Ä–∏—Å–∞, –°–µ–ª–µ–Ω–∞, –ì–æ–º–µ—Å, –ø—Ä–∏–∑–Ω–∞–ª–∞—Å—å, –Ω–∞, —Å–≤–æ–µ–π, —Å—Ç—Ä–∞–Ω–∏—Ü–µ, –≤, Instagram, ,, —á—Ç–æ, –Ω–µ–¥–∞–≤–Ω–æ, –ø–µ—Ä–µ–Ω–µ—Å–ª–∞, –æ–ø–µ—Ä–∞—Ü–∏—é, –ø–æ, –ø–µ—Ä–µ—Å–∞–¥–∫–µ, –ø–æ—á–∫–∏, ., 25-–ª–µ—Ç–Ω—è—è, –¥–µ–≤—É—à–∫–∞, –≤—ã–ª–æ–∂–∏–ª–∞, —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—é, –≤, –±–æ–ª—å–Ω–∏—á–Ω–æ–π, –ø–∞–ª–∞—Ç–µ, —Å, –ª—É—á—à–µ–π, –ø–æ–¥—Ä—É–≥–æ–π, –§—Ä–∞–Ω—Å–∏–µ–π, –†–∞–π—Å–æ–π, ,, –∫–æ—Ç–æ—Ä–∞—è, —Å—Ç–∞–ª–∞, –µ—ë, –¥–æ–Ω–æ—Ä–æ–º:, –ó–Ω–∞—é,, –º–Ω–æ–≥–∏–µ, –º–æ–∏, –ø–æ–∫–ª–æ–Ω–Ω–∏–∫–∏, –∑–∞–º–µ—Ç–∏–ª–∏,, —á—Ç–æ, —á–∞—Å—Ç—å, –ª–µ—Ç–∞, –æ–±–æ, –º–Ω–µ, –Ω–∏—á–µ–≥–æ, –Ω–µ, –±—ã–ª–æ, —Å–ª—ã—à–Ω–æ,, –∏, –∑–∞–¥–∞–≤–∞–ª–∏—Å—å, –≤–æ–ø—Ä–æ—Å–æ–º,, –ø–æ—á–µ–º—É, —è, –Ω–µ, –ø—Ä–æ–¥–≤–∏–≥–∞—é, —Å–≤–æ–∏, –ø–µ—Å–Ω–∏,, –∫–æ—Ç–æ—Ä—ã–º–∏, –æ—á–µ–Ω—å, –≥–æ—Ä–∂—É—Å—å., –í, –æ–±—â–µ–º,, —Å—Ç–∞–ª–æ, –∏–∑–≤–µ—Å—Ç–Ω–æ,, —á—Ç–æ, –∏–∑-–∑–∞, –≤–æ–ª—á–∞–Ω–∫–∏, –º–Ω–µ, –Ω—É–∂–Ω–æ, –±—ã–ª–æ, —Å–¥–µ–ª–∞—Ç—å, —Ç—Ä–∞–Ω—Å–ø–ª–∞–Ω—Ç–∞—Ü–∏—é, –ø–æ—á–∫–∏., –≠—Ç–æ, –±—ã–ª–æ, –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ, –¥–ª—è, –º–æ–µ–≥–æ, –∑–¥–æ—Ä–æ–≤—å—è., –°–µ–π—á–∞—Å, —è, —Ö–æ—á—É, –ø—É–±–ª–∏—á–Ω–æ, –ø–æ–±–ª–∞–≥–æ–¥–∞—Ä–∏—Ç—å, —Å–≤–æ—é, —Å–µ–º—å—é, –∏, –Ω–µ–≤–µ—Ä–æ—è—Ç–Ω—É—é, ...]</td>\n",
       "      <td>[B-PERSON, I-PERSON, B-EVENT, I-EVENT, O, O, B-PERSON, I-PERSON, B-NATIONALITY, B-PROFESSION, O, B-PROFESSION, B-PERSON, I-PERSON, O, O, O, O, O, B-PRODUCT, O, O, O, O, B-EVENT, I-EVENT, I-EVENT, I-EVENT, O, B-AGE, O, O, O, O, O, O, O, O, O, B-PERSON, I-PERSON, O, O, O, O, O, O, O, O, O, O, O, B-DATE, I-DATE, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-DISEASE, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>–ë–∞–π–¥–µ–Ω –±–µ—Å–µ–¥–æ–≤–∞–ª —Å –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç–æ–º –≠–∫–≤–∞–¥–æ—Ä–∞ –æ –°–Ω–æ—É–¥–µ–Ω–µ\\n\\n –î–∂–æ –ë–∞–π–¥–µ–Ω –≤ –æ–∫—Ä—É–∂–µ–Ω–∏–∏ –≤–æ–µ–Ω–Ω–æ—Å–ª—É–∂–∞—â–∏—Ö –°–®–ê –†–∞—Ñ–∞—ç–ª—å –ö–æ—Ä—Ä–µ–∞ –≠–¥–≤–∞—Ä–¥ –°–Ω–æ—É–¥–µ–Ω \\n\\n–í–∏—Ü–µ-–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç –°–®–ê –î–∂–æ –ë–∞–π–¥–µ–Ω –ø–æ–±–µ—Å–µ–¥–æ–≤–∞–ª —Å –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç–æ–º –≠–∫–≤–∞–¥–æ—Ä–∞ –†–∞—Ñ–∞—ç–ª–µ–º –ö–æ—Ä—Ä–µ–∞ –ø–æ –ø–æ–≤–æ–¥—É –≠–¥–≤–∞—Ä–¥–∞ –°–Ω–æ—É–¥–µ–Ω–∞.\\n–ë–∞–π–¥–µ–Ω –ø—Ä–æ—Å–∏–ª –æ—Ç–∫–∞–∑–∞—Ç—å –°–Ω–æ—É–¥–µ–Ω—É –≤ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–∏ —É–±–µ–∂–∏—â–∞, –∫–æ—Ç–æ—Ä–æ–µ –°–Ω–æ—É–¥–µ–Ω –ø—Ä–µ–¥–ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ, —Ö–æ—á–µ—Ç –ø–æ–ª—É—á–∏—Ç—å.\\n–ö–æ—Ä—Ä–µ–∞ –≤ –æ—Ç–≤–µ—Ç –∑–∞—è–≤–∏–ª, —á—Ç–æ —Å—É–¥—å–±–∞ –°–Ω–æ—É–¥–µ–Ω–∞ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —Ä–æ—Å—Å–∏–π—Å–∫–∏—Ö —Ä—É–∫–∞—Ö.\\n\\n–û —Ä–∞–∑–≥–æ–≤–æ—Ä–µ —Å –ë–∞–π–¥–µ–Ω–æ–º —Ä–∞—Å—Å–∫–∞–∑–∞–ª —Å–∞–º –ö–æ—Ä—Ä–µ–∞ –≤–æ –≤—Ä–µ–º—è –µ–∂–µ–Ω–µ–¥–µ–ª—å–Ω–æ–≥–æ –æ–±—Ä–∞—â–µ–Ω–∏—è –∫ —ç–∫–≤–∞–¥–æ—Ä—Ü–∞–º.\\n–ü–æ –µ–≥–æ —Å–ª–æ–≤–∞–º, –±–µ—Å–µ–¥–∞ —Å–æ—Å—Ç–æ—è–ª–∞—Å—å –≤ –ø—è—Ç–Ω–∏—Ü—É.\\n\\n–ë–µ–ª—ã–π –¥–æ–º –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç —Ñ–∞–∫—Ç —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ –æ –°–Ω–æ—É–¥–µ–Ω–µ, –æ–¥–Ω–∞–∫–æ –Ω–∏—á–µ–≥–æ –Ω–µ —Å–æ–æ–±—â–∞–µ—Ç –æ –¥–µ—Ç–∞–ª—è—Ö –∏–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö —ç—Ç–æ–≥–æ –æ–±—â–µ–Ω–∏—è.\\n\\n–í–ª–∞—Å—Ç–∏ –≠–∫–≤–∞–¥–æ—Ä–∞ –∑–∞—è–≤–∏–ª–∏, —á—Ç–æ –Ω–µ –º–æ–≥—É—Ç —Ä–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å –≤–æ–ø—Ä–æ—Å –æ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–∏ —É–±–µ–∂–∏—â–∞ –°–Ω–æ—É–¥–µ–Ω—É –¥–æ —Ç–µ—Ö –ø–æ—Ä, –ø–æ–∫–∞ –æ–Ω –Ω–µ –æ–∫–∞–∂–µ—Ç—Å—è –Ω–∞ —Ç–µ—Ä—Ä–∏—Ç–æ—Ä–∏–∏ —Å—Ç—Ä–∞–Ω—ã.\\n\\n–ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è, —á—Ç–æ –≠–¥–≤–∞—Ä–¥ –°–Ω–æ—É–¥–µ–Ω, —Ä–∞–∑–≥–ª–∞—Å–∏–≤—à–∏–π —Å–µ–∫—Ä–µ—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∞–º–µ—Ä–∏–∫–∞–Ω—Å–∫–∏—Ö –ø—Ä–æ–≥—Ä–∞–º–º–∞—Ö –ø–æ –±–æ—Ä—å–±–µ —Å —Ç–µ—Ä—Ä–æ—Ä–∏–∑–º–æ–º, –ø–æ-–ø—Ä–µ–∂–Ω–µ–º—É –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —Ç—Ä–∞–Ω–∑–∏—Ç–Ω–æ–π –∑–æ–Ω–µ –º–æ—Å–∫–æ–≤—Å–∫–æ–≥–æ –∞—ç—Ä–æ–ø–æ—Ä—Ç–∞ –®–µ—Ä–µ–º–µ—Ç—å–µ–≤–æ, –∫—É–¥–∞ –æ–Ω –ø—Ä–∏–ª–µ—Ç–µ–ª –∏–∑ –ì–æ–Ω–∫–æ–Ω–≥–∞ —Å –Ω–∞–º–µ—Ä–µ–Ω–∏–µ–º –¥–æ–±—Ä–∞—Ç—å—Å—è –¥–æ –≠–∫–≤–∞–¥–æ—Ä–∞ —á–µ—Ä–µ–∑ –ö—É–±—É.\\n–ï–≥–æ –∞–º–µ—Ä–∏–∫–∞–Ω—Å–∫–∏–π –ø–∞—Å–ø–æ—Ä—Ç –∞–Ω–Ω—É–ª–∏—Ä–æ–≤–∞–Ω, –∏ –°–®–ê –¥–æ–±–∏–≤–∞—é—Ç—Å—è –≤—ã–¥–∞—á–∏ –°–Ω–æ—É–¥–µ–Ω–∞.\\n\\n–†–∞–Ω–µ–µ –≠–∫–≤–∞–¥–æ—Ä –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏–ª —É–±–µ–∂–∏—â–µ –æ—Å–Ω–æ–≤–∞—Ç–µ–ª—é WikiLeaks –î–∂—É–ª–∏–∞–Ω—É –ê—Å—Å–∞–Ω–∂—É, –∫–æ—Ç–æ—Ä—ã–π –æ—Å—Ç–∞—ë—Ç—Å—è –≤ –ø–æ—Å–æ–ª—å—Å—Ç–≤–µ –≠–∫–≤–∞–¥–æ—Ä–∞ –≤ –õ–æ–Ω–¥–æ–Ω–µ.\\n\\n–ü—Ä–µ–∑–∏–¥–µ–Ω—Ç –ö–æ—Ä—Ä–µ–∞ –∑–∞—è–≤–ª—è–ª, —á—Ç–æ –°–®–ê –¥–æ–ª–∂–Ω—ã –Ω–µ –ª–æ–≤–∏—Ç—å –°–Ω–æ—É–¥–µ–Ω–∞, –∞ –æ–±—ä—è—Å–Ω–∏—Ç—å—Å—è –ø–æ –ø–æ–≤–æ–¥—É —Å–µ–∫—Ä–µ—Ç–Ω—ã—Ö –ø—Ä–æ–≥—Ä–∞–º–º, –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞—é—â–∏—Ö —Å–±–æ—Ä –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ç–µ–ª–µ—Ñ–æ–Ω–Ω—ã—Ö –∑–≤–æ–Ω–∫–∞—Ö –∏ —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –ø–µ—Ä–µ–ø–∏—Å–∫–µ –∞–º–µ—Ä–∏–∫–∞–Ω—Ü–µ–≤.\\n–ö—Ä–æ–º–µ —Ç–æ–≥–æ, –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç –≠–∫–≤–∞–¥–æ—Ä–∞ —Å–æ–æ–±—â–∏–ª, —á—Ç–æ —Å—É–¥—å–±–∞ –°–Ω–æ—É–¥–µ–Ω–∞ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —Ä–æ—Å—Å–∏–π—Å–∫–∏—Ö —Ä—É–∫–∞—Ö.\\n\\n–¢–µ–º –≤—Ä–µ–º–µ–Ω–µ–º –∞–º–µ—Ä–∏–∫–∞–Ω—Å–∫–∏–µ –°–ú–ò –Ω–∞—á–∞–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—É—é –≤–æ–π–Ω—É, –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω—É—é –Ω–∞ —Ç–æ, —á—Ç–æ–±—ã –Ω–µ –¥–æ–ø—É—Å—Ç–∏—Ç—å –ø–æ–ª—É—á–µ–Ω–∏–µ –°–Ω–æ—É–¥–µ–Ω–æ–º —É–±–µ–∂–∏—â–∞ –≤ –≠–∫–≤–∞–¥–æ—Ä–µ.\\n–ù–∞–ø—Ä–∏–º–µ—Ä, –ø–æ —Å–æ–æ–±—â–µ–Ω–∏—é –∞–≥–µ–Ω—Ç—Å—Ç–≤–∞ Associated Press, –∂–∏—Ç–µ–ª–∏ –≠–∫–≤–∞–¥–æ—Ä–∞, –∫–æ—Ç–æ—Ä—ã–µ —Ä–∞–∑–≤–æ–¥—è—Ç —Ä–æ–∑—ã –∏ –¥–µ–ª—å—Ñ–∏–Ω–∏–∏, –∂–∞–ª—É—é—Ç—Å—è –Ω–∞ —Ç–æ, —á—Ç–æ –∏–∑-–∑–∞ –°–Ω–æ—É–¥–µ–Ω–∞ –∞–º–µ—Ä–∏–∫–∞–Ω—Å–∫–æ–µ –ø—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–æ –æ—Ç–∫–∞–∑–∞–ª–æ—Å—å —Å–Ω–∏–∑–∏—Ç—å —Ç–∞—Ä–∏—Ñ—ã –Ω–∞ –∏–º–ø–æ—Ä—Ç —Ä–æ–∑ –∏–∑ –∏—Ö —Å—Ç—Ä–∞–Ω—ã.\\n–•–æ–∑—è–∏–Ω –∫—Ä—É–ø–Ω–æ–π –ø–ª–∞–Ω—Ç–∞—Ü–∏–∏ –î–∂–∏–Ω–æ –î–µ—Å–∫–∞–ª—å—Å–∏:\\n–ú—ã –ø—Ä–æ—Å—Ç–æ —à–æ–∫–∏—Ä–æ–≤–∞–Ω—ã —Å–ª—É—á–∏–≤—à–∏–º—Å—è. –ü—Ä–∏–¥—ë—Ç—Å—è –º–µ–Ω—è—Ç—å –≤—Å–µ –ø–ª–∞–Ω—ã –Ω–∞ –±–ª–∏–∂–∞–π—à–∏–π –≥–æ–¥.  –ü–æ—á–µ–º—É –º—ã –¥–æ–ª–∂–Ω—ã –∑–∞–≤–∏—Å–µ—Ç—å –æ—Ç –∫–∞–∫–æ–≥–æ-—Ç–æ 29 –ª–µ—Ç–Ω–µ–≥–æ —Ö–∞–∫–µ—Ä–∞, –∫–æ—Ç–æ—Ä–æ–≥–æ –º—ã –¥–∞–∂–µ –Ω–µ –∑–Ω–∞–µ–º.\\n–°–ú–ò –æ—Ç–º–µ—á–∞—é—Ç, —á—Ç–æ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –±–µ–∂–µ–Ω—Ü–∞ ¬´—Ö–∞–∫–µ—Ä—É¬ª –Ω–∞–Ω–µ—Å—ë—Ç —Å–µ—Ä—å—ë–∑–Ω—ã–π —É—â–µ—Ä–± –ø–æ –±–ª–∞–≥–æ—Å–æ—Å—Ç–æ—è–Ω–∏—é 50 —Ç—ã—Å—è—á —á–µ–ª–æ–≤–µ–∫, –∑–∞–Ω–∏–º–∞—é—â–∏—Ö—Å—è –≤—ã—Ä–∞—â–∏–≤–∞–Ω–∏–µ–º —Ü–≤–µ—Ç–æ–≤, –∞ —ç—Ç–∞ –æ—Ç—Ä–∞—Å–ª—å —ç–∫–æ–Ω–æ–º–∏–∫–∏ ‚Äî —á–µ—Ç–≤—ë—Ä—Ç–∞—è –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏ –≤ —Å—Ç—Ä–∞–Ω–µ –ø–æ—Å–ª–µ –Ω–µ—Ñ—Ç–∏, –º–æ—Ä–µ–ø—Ä–æ–¥—É–∫—Ç–æ–≤ –∏ –±–∞–Ω–∞–Ω–æ–≤.\\n</td>\n",
       "      <td>[–ë–∞–π–¥–µ–Ω, –±–µ—Å–µ–¥–æ–≤–∞–ª, —Å, –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç–æ–º, –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç–æ–º, –≠–∫–≤–∞–¥–æ—Ä–∞, –≠–∫–≤–∞–¥–æ—Ä–∞, –æ, –°–Ω–æ—É–¥–µ–Ω–µ, –î–∂–æ, –ë–∞–π–¥–µ–Ω, –≤, –æ–∫—Ä—É–∂–µ–Ω–∏–∏, –≤–æ–µ–Ω–Ω–æ—Å–ª—É–∂–∞—â–∏—Ö, –°–®–ê, –≤–æ–µ–Ω–Ω–æ—Å–ª—É–∂–∞—â–∏—Ö, –°–®–ê, –†–∞—Ñ–∞—ç–ª—å, –ö–æ—Ä—Ä–µ–∞, –≠–¥–≤–∞—Ä–¥, –°–Ω–æ—É–¥–µ–Ω, –í–∏—Ü–µ-–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç, –í–∏—Ü–µ-–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç, –°–®–ê, –°–®–ê, –î–∂–æ, –ë–∞–π–¥–µ–Ω, –ø–æ–±–µ—Å–µ–¥–æ–≤–∞–ª, —Å, –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç–æ–º, –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç–æ–º, –≠–∫–≤–∞–¥–æ—Ä–∞, –≠–∫–≤–∞–¥–æ—Ä–∞, –†–∞—Ñ–∞—ç–ª–µ–º, –ö–æ—Ä—Ä–µ–∞, –ø–æ, –ø–æ–≤–æ–¥—É, –≠–¥–≤–∞—Ä–¥–∞, –°–Ω–æ—É–¥–µ–Ω–∞, ., –ë–∞–π–¥–µ–Ω, –ø—Ä–æ—Å–∏–ª, –æ—Ç–∫–∞–∑–∞—Ç—å, –°–Ω–æ—É–¥–µ–Ω—É, –≤, –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–∏, —É–±–µ–∂–∏—â–∞,, –∫–æ—Ç–æ—Ä–æ–µ, –°–Ω–æ—É–¥–µ–Ω, –ø—Ä–µ–¥–ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ,, —Ö–æ—á–µ—Ç, –ø–æ–ª—É—á–∏—Ç—å., –ö–æ—Ä—Ä–µ–∞, –≤, –æ—Ç–≤–µ—Ç, –∑–∞—è–≤–∏–ª,, —á—Ç–æ, —Å—É–¥—å–±–∞, –°–Ω–æ—É–¥–µ–Ω–∞, –Ω–∞—Ö–æ–¥–∏—Ç—Å—è, –≤, —Ä–æ—Å—Å–∏–π—Å–∫–∏—Ö, —Ä—É–∫–∞—Ö., –û, —Ä–∞–∑–≥–æ–≤–æ—Ä–µ, —Å, –ë–∞–π–¥–µ–Ω–æ–º, —Ä–∞—Å—Å–∫–∞–∑–∞–ª, —Å–∞–º, –ö–æ—Ä—Ä–µ–∞, –≤–æ, –≤—Ä–µ–º—è, –µ–∂–µ–Ω–µ–¥–µ–ª—å–Ω–æ–≥–æ, –æ–±—Ä–∞—â–µ–Ω–∏—è, –∫, —ç–∫–≤–∞–¥–æ—Ä—Ü–∞–º, ., –ü–æ, –µ–≥–æ, —Å–ª–æ–≤–∞–º,, –±–µ—Å–µ–¥–∞, —Å–æ—Å—Ç–æ—è–ª–∞—Å—å, –≤, –ø—è—Ç–Ω–∏—Ü—É, ., –ë–µ–ª—ã–π, –¥–æ–º, –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç, —Ñ–∞–∫—Ç, —Ä–∞–∑–≥–æ–≤–æ—Ä–∞, –æ, –°–Ω–æ—É–¥–µ–Ω–µ, ,, –æ–¥–Ω–∞–∫–æ, –Ω–∏—á–µ–≥–æ, –Ω–µ, —Å–æ–æ–±—â–∞–µ—Ç, –æ, –¥–µ—Ç–∞–ª—è—Ö, –∏–ª–∏, ...]</td>\n",
       "      <td>[B-PERSON, B-EVENT, O, B-PROFESSION, B-PROFESSION, I-PROFESSION, B-COUNTRY, O, B-PERSON, B-PERSON, I-PERSON, O, O, B-PROFESSION, I-PROFESSION, B-PROFESSION, B-COUNTRY, B-PERSON, I-PERSON, B-PERSON, I-PERSON, B-PROFESSION, B-PROFESSION, I-PROFESSION, B-COUNTRY, B-PERSON, I-PERSON, B-EVENT, O, B-PROFESSION, B-PROFESSION, I-PROFESSION, B-COUNTRY, B-PERSON, I-PERSON, O, O, B-PERSON, I-PERSON, O, B-PERSON, O, O, B-PERSON, O, O, O, O, B-PERSON, O, O, O, B-PERSON, O, O, O, O, O, B-PERSON, O, O, B-COUNTRY, O, O, B-EVENT, O, B-PERSON, O, O, B-PERSON, O, O, B-DATE, O, O, B-NATIONALITY, O, O, O, O, B-EVENT, O, O, B-DATE, O, B-ORGANIZATION, I-ORGANIZATION, O, O, B-EVENT, O, B-PERSON, O, O, O, O, O, O, O, O, ...]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T16:12:45.926808Z",
     "start_time": "2024-04-10T16:12:45.920460Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–í–æ –≤—Ä–µ–º—è –≤–∑—Ä—ã–≤–∞ –∞–≤—Ç–æ–º–æ–±–∏–ª—è –≤ –ö–∏–µ–≤–µ –ø–æ—Å—Ç—Ä–∞–¥–∞–ª–∞ –º–æ–¥–µ–ª—å Dior\n",
      "–ú–∞–≥–∞–∑–∏–Ω Christian Dior\n",
      "–í –∞–≤—Ç–æ–º–æ–±–∏–ª–µ, –∫–æ—Ç–æ—Ä—ã–π –≤–∑–æ—Ä–≤–∞–ª—Å—è –≤—á–µ—Ä–∞, 8 —Å–µ–Ω—Ç—è–±—Ä—è 2017 –≥–æ–¥–∞, –≤ —Ä–∞–π–æ–Ω–µ –ë–µ—Å—Å–∞—Ä–∞–±—Å–∫–æ–π –ø–ª–æ—â–∞–¥–∏ –≤ –ö–∏–µ–≤–µ –Ω–∞—Ö–æ–¥–∏–ª–∞—Å—å –º–æ–¥–µ–ª—å Christian Dior –ù–∞—Ç–∞–ª—å—è –ö–æ—à–µ–ª—å, –µ–π –æ—Ç–æ—Ä–≤–∞–ª–æ –Ω–æ–≥—É, —Ç–∞–∫–∂–µ –æ–Ω–∞ –ø–æ–ª—É—á–∏–ª–∞ —Ç—Ä–∞–≤–º—ã –≥–ª–∞–∑, —Å–æ–æ–±—â–∞—é—Ç –°–ú–ò.\n",
      "\n",
      "–†–∞–Ω–µ–µ –ø–æ–¥—Ä—É–≥–∞ –¥–µ–≤—É—à–∫–∏ –û–∫—Å–∞–Ω–∞ –õ–∞–∑–µ–±–Ω–∏–∫ —Å–æ–æ–±—â–∏–ª–∞ –°–ú–ò, —á—Ç–æ –≤ –º–æ–º–µ–Ω—Ç –≤–∑—Ä—ã–≤–∞ –≤ –º–∞—à–∏–Ω–µ –Ω–∞—Ö–æ–¥–∏–ª–∞—Å—å ¬´–≤—Å–µ–º–∏—Ä–Ω–æ –∏–∑–≤–µ—Å—Ç–Ω–∞—è –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è —è–≤–ª—è–µ—Ç—Å—è –ª–∏—Ü–æ–º –º–∞—Ä–∫–∏ Dior¬ª.\n",
      "\n",
      "–í –Ω–∞—Å—Ç–æ—è—â–µ–µ –≤—Ä–µ–º—è –∑–∞ –µ—ë –∂–∏–∑–Ω—å –±–æ—Ä—é—Ç—Å—è –≤—Ä–∞—á–∏ 17-–π –±–æ–ª—å–Ω–∏—Ü—ã —É–∫—Ä–∞–∏–Ω—Å–∫–æ–π —Å—Ç–æ–ª–∏—Ü—ã.\n",
      "–ó–∞–≤–µ–¥—É—é—â–∏–π –æ—Ç–¥–µ–ª–µ–Ω–∏–µ–º –ø–æ–ª–∏—Ç—Ä–∞–≤–º –∫–∏–µ–≤—Å–∫–æ–π –±–æ–ª—å–Ω–∏—Ü—ã ‚Ññ 17 –î–º–∏—Ç—Ä–∏–π –ú—è—Å–Ω–∏–∫–æ–≤ –∑–∞—è–≤–∏–ª, —á—Ç–æ –∂–µ–Ω—â–∏–Ω—É –æ–ø–µ—Ä–∏—Ä—É—é—Ç —Ç—Ä–∏ –±—Ä–∏–≥–∞–¥—ã —Ö–∏—Ä—É—Ä–≥–æ–≤.\n",
      "\n",
      "¬´–£ –ø–∞—Ü–∏–µ–Ω—Ç–∫–∏ –µ—Å—Ç—å —Ç–µ—Ä–º–∏—á–µ—Å–∫–∞—è —Ç—Ä–∞–≤–º–∞, –æ–∂–æ–≥–∏, –ø–æ—Ä–∞–∂–µ–Ω–∏—è –æ—Ä–≥–∞–Ω–æ–≤, —Ç—Ä–∞–≤–º–∞ –∫–æ—Å—Ç–µ–π –∏ —Ç—Ä–∞–≤–º–∞ –º—è–≥–∫–∏—Ö —Ç–∫–∞–Ω–µ–π¬ª, ‚Äî —Å–∫–∞–∑–∞–ª –≤—Ä–∞—á.\n",
      "\n",
      "–ú–æ–¥–µ–ª—å –Ω–∞—Ö–æ–¥–∏–ª–∞—Å—å –≤ –º–∞—à–∏–Ω–µ –≤–º–µ—Å—Ç–µ —Å —à–µ—Å—Ç–∏–ª–µ—Ç–Ω–∏–º –º–∞–ª—å—á–∏–∫–æ–º –ø–æ –∏–º–µ–Ω–∏ –ê–Ω—Ç–æ–Ω. –†–µ–±—ë–Ω–∫–∞ –¥–æ—Å—Ç–∞–≤–∏–ª–∏ –≤ –æ–∂–æ–≥–æ–≤—ã–π —Ü–µ–Ω—Ç—Ä. –û –µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ –Ω–∏—á–µ–≥–æ –Ω–µ —Å–æ–æ–±—â–∞–µ—Ç—Å—è.\n",
      "\n",
      "–ò–∑-–∑–∞ –≤–∑—Ä—ã–≤–∞ –Ω–∞ –º–µ—Å—Ç–µ –ø—Ä–æ–∏—Å—à–µ—Å—Ç–≤–∏—è –ø–æ–≥–∏–± –Ω–∞—Ö–æ–¥–∏–≤—à–∏–π—Å—è –≤ –º–∞—à–∏–Ω–µ –≥—Ä–∞–∂–¥–∞–Ω–∏–Ω –ì—Ä—É–∑–∏–∏ –±–æ–µ—Ü —á–µ—á–µ–Ω—Å–∫–æ–≥–æ –±–∞—Ç–∞–ª—å–æ–Ω–∞ –∏–º–µ–Ω–∏ —à–µ–π—Ö–∞ –ú–∞–Ω—Å—É—Ä–∞ —á–µ—á–µ–Ω–µ—Ü –¢–∏–º—É—Ä –ú–∞—Ö–∞—É—Ä–∏.\n",
      "\n",
      "–ò–Ω—Ü–∏–¥–µ–Ω—Ç –ø—Ä–æ–∏–∑–æ—à–µ–ª –≤ –ø—è—Ç–Ω–∏—Ü—É –æ–∫–æ–ª–æ 18:00 –º–µ–∂–¥—É —É–ª. –ë–∞—Å—Å–µ–π–Ω–æ–π –∏ –ë–æ–ª—å—à–æ–π –í–∞—Å–∏–ª—å–∫–æ–≤—Å–∫–æ–π. –í–∑–æ—Ä–≤–∞–≤—à–∏–π—Å—è –∞–≤—Ç–æ–º–æ–±–∏–ª—å ¬´–¢–æ–π–æ—Ç–∞ –ö–∞–º—Ä–∏¬ª –ø–æ–ª–Ω–æ—Å—Ç—å—é —É–Ω–∏—á—Ç–æ–∂–µ–Ω.\n",
      "\n",
      "–î–∏—Ä–µ–∫—Ç–æ—Ä –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç–∞ –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏ –ú–í–î –£–∫—Ä–∞–∏–Ω—ã –ê—Ä—Ç—ë–º –®–µ–≤—á–µ–Ω–∫–æ —Å–æ–æ–±—â–∞–ª –°–ú–ò:\n",
      "–°–µ–≥–æ–¥–Ω—è –ø—Ä–æ–∏–∑–æ—à–µ–ª –≤–∑—Ä—ã–≤ –∞–≤—Ç–æ–º–æ–±–∏–ª—è, –≤ –∫–æ—Ç–æ—Ä–æ–º –Ω–∞—Ö–æ–¥–∏–ª–∏—Å—å —Ç—Ä–∏ —á–µ–ª–æ–≤–µ–∫–∞. –≠—Ç–æ —á–µ–ª–æ–≤–µ–∫, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–≥–∏–±, –∂–µ–Ω—â–∏–Ω–∞, –∫–æ—Ç–æ—Ä–∞—è –ø–æ–ª—É—á–∏–ª–∞ —Å–µ—Ä—å–µ–∑–Ω—ã–µ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è –∏ —Å–µ–π—á–∞—Å –∑–∞ –µ–µ –∂–∏–∑–Ω—å –±–æ—Ä—é—Ç—Å—è –º–µ–¥–∏–∫–∏, –∏ —Ä–µ–±–µ–Ω–æ–∫, –≤—ã–∂–∏–≤—à–∏–π –∏ –∂–∏–∑–Ω–∏ –∫–æ—Ç–æ—Ä–æ–≥–æ –Ω–∏—á–µ–≥–æ –Ω–µ —É–≥—Ä–æ–∂–∞–µ—Ç.\n",
      "\n",
      "–ü–æ —Å–ª–æ–≤–∞–º –®–µ–≤—á–µ–Ω–∫–æ, –≤ 2017 –≥–æ–¥—É –ú–∞—Ö–∞—É—Ä–∏ ‚Äî ¬´–ª–∏—Ü–æ, –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∏–∑–≤–µ—Å—Ç–Ω–æ–µ –≤ –∫—Ä–∏–º–∏–Ω–∞–ª—å–Ω—ã—Ö –∫—Ä—É–≥–∞—Ö, –∫–æ—Ç–æ—Ä–æ–µ –∏–º–µ–ª–æ —É—Å—Ç–æ–π—á–∏–≤—ã–µ —Å–≤—è–∑–∏ —Å —Ä–∞–∑–Ω–æ–≥–æ —Ä–æ–¥–∞ —á–µ—á–µ–Ω—Å–∫–∏–º–∏ –∫—Ä—É–≥–∞–º–∏¬ª, –±—ã–ª –∑–∞–¥–µ—Ä–∂–∞–Ω –∑–∞ –Ω–µ–∑–∞–∫–æ–Ω–Ω–æ–µ —Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ä—É–∂–∏—è. –ü–æ–∑–∂–µ –æ–Ω –∑–∞–∫–ª—é—á–∏–ª —Å–¥–µ–ª–∫—É —Å–æ —Å–ª–µ–¥—Å—Ç–≤–∏–µ–º –∏ –ø–æ–ª—É—á–∏–ª —É—Å–ª–æ–≤–Ω—ã–π —Å—Ä–æ–∫.\n",
      "\n",
      "–í–æ–∑–±—É–∂–¥–µ–Ω–æ —É–≥–æ–ª–æ–≤–Ω–æ–µ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–æ –ø–æ —Å—Ç. 115 —á. 2 ¬´–£–º—ã—à–ª–µ–Ω–Ω–æ–µ —É–±–∏–π—Å—Ç–≤–æ, —Å–æ–≤–µ—Ä—à–µ–Ω–Ω–æ–µ –æ–±—â–µ—Å—Ç–≤–µ–Ω–Ω–æ –æ–ø–∞—Å–Ω—ã–º —Å–ø–æ—Å–æ–±–æ–º¬ª. –°–æ–≥–ª–∞—Å–Ω–æ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–º –¥–∞–Ω–Ω—ã–º, –≤ –∞–≤—Ç–æ–º–æ–±–∏–ª–µ —Å—Ä–∞–±–æ—Ç–∞–ª–æ –≤–∑—Ä—ã–≤–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ.\n",
      "\n",
      "–ü–æ–ª–∏—Ü–∏—è –∏ –ù–∞—Ü–≥–≤–∞—Ä–¥–∏—è —É—Å–∏–ª–∏–ª–∏ –ø–∞—Ç—Ä—É–ª–∏—Ä–æ–≤–∞–Ω–∏–µ —Ü–µ–Ω—Ç—Ä–∞ –ö–∏–µ–≤–∞ –∏ –º–µ—Ç—Ä–æ –ø–æ—Å–ª–µ –≤–∑—Ä—ã–≤–∞ –Ω–∞ –ë–µ—Å—Å–∞—Ä–∞–±–∫–µ.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"–í–æ –≤—Ä–µ–º—è –≤–∑—Ä—ã–≤–∞ –∞–≤—Ç–æ–º–æ–±–∏–ª—è –≤ –ö–∏–µ–≤–µ –ø–æ—Å—Ç—Ä–∞–¥–∞–ª–∞ –º–æ–¥–µ–ª—å Dior\\n–ú–∞–≥–∞–∑–∏–Ω Christian Dior\\n–í –∞–≤—Ç–æ–º–æ–±–∏–ª–µ, –∫–æ—Ç–æ—Ä—ã–π –≤–∑–æ—Ä–≤–∞–ª—Å—è –≤—á–µ—Ä–∞, 8 —Å–µ–Ω—Ç—è–±—Ä—è 2017 –≥–æ–¥–∞, –≤ —Ä–∞–π–æ–Ω–µ –ë–µ—Å—Å–∞—Ä–∞–±—Å–∫–æ–π –ø–ª–æ—â–∞–¥–∏ –≤ –ö–∏–µ–≤–µ –Ω–∞—Ö–æ–¥–∏–ª–∞—Å—å –º–æ–¥–µ–ª—å Christian Dior –ù–∞—Ç–∞–ª—å—è –ö–æ—à–µ–ª—å, –µ–π –æ—Ç–æ—Ä–≤–∞–ª–æ –Ω–æ–≥—É, —Ç–∞–∫–∂–µ –æ–Ω–∞ –ø–æ–ª—É—á–∏–ª–∞ —Ç—Ä–∞–≤–º—ã –≥–ª–∞–∑, —Å–æ–æ–±—â–∞—é—Ç –°–ú–ò.\\n\\n–†–∞–Ω–µ–µ –ø–æ–¥—Ä—É–≥–∞ –¥–µ–≤—É—à–∫–∏ –û–∫—Å–∞–Ω–∞ –õ–∞–∑–µ–±–Ω–∏–∫ —Å–æ–æ–±—â–∏–ª–∞ –°–ú–ò, —á—Ç–æ –≤ –º–æ–º–µ–Ω—Ç –≤–∑—Ä—ã–≤–∞ –≤ –º–∞—à–∏–Ω–µ –Ω–∞—Ö–æ–¥–∏–ª–∞—Å—å ¬´–≤—Å–µ–º–∏—Ä–Ω–æ –∏–∑–≤–µ—Å—Ç–Ω–∞—è –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è —è–≤–ª—è–µ—Ç—Å—è –ª–∏—Ü–æ–º –º–∞—Ä–∫–∏ Dior¬ª.\\n\\n–í –Ω–∞—Å—Ç–æ—è—â–µ–µ –≤—Ä–µ–º—è –∑–∞ –µ—ë –∂–∏–∑–Ω—å –±–æ—Ä—é—Ç—Å—è –≤—Ä–∞—á–∏ 17-–π –±–æ–ª—å–Ω–∏—Ü—ã —É–∫—Ä–∞–∏–Ω—Å–∫–æ–π —Å—Ç–æ–ª–∏—Ü—ã.\\n–ó–∞–≤–µ–¥—É—é—â–∏–π –æ—Ç–¥–µ–ª–µ–Ω–∏–µ–º –ø–æ–ª–∏—Ç—Ä–∞–≤–º –∫–∏–µ–≤—Å–∫–æ–π –±–æ–ª—å–Ω–∏—Ü—ã ‚Ññ 17 –î–º–∏—Ç—Ä–∏–π –ú—è—Å–Ω–∏–∫–æ–≤ –∑–∞—è–≤–∏–ª, —á—Ç–æ –∂–µ–Ω—â–∏–Ω—É –æ–ø–µ—Ä–∏—Ä—É—é—Ç —Ç—Ä–∏ –±—Ä–∏–≥–∞–¥—ã —Ö–∏—Ä—É—Ä–≥–æ–≤.\\n\\n¬´–£ –ø–∞—Ü–∏–µ–Ω—Ç–∫–∏ –µ—Å—Ç—å —Ç–µ—Ä–º–∏—á–µ—Å–∫–∞—è —Ç—Ä–∞–≤–º–∞, –æ–∂–æ–≥–∏, –ø–æ—Ä–∞–∂–µ–Ω–∏—è –æ—Ä–≥–∞–Ω–æ–≤, —Ç—Ä–∞–≤–º–∞ –∫–æ—Å—Ç–µ–π –∏ —Ç—Ä–∞–≤–º–∞ –º—è–≥–∫–∏—Ö —Ç–∫–∞–Ω–µ–π¬ª, ‚Äî —Å–∫–∞–∑–∞–ª –≤—Ä–∞—á.\\n\\n–ú–æ–¥–µ–ª—å –Ω–∞—Ö–æ–¥–∏–ª–∞—Å—å –≤ –º–∞—à–∏–Ω–µ –≤–º–µ—Å—Ç–µ —Å —à–µ—Å—Ç–∏–ª–µ—Ç–Ω–∏–º –º–∞–ª—å—á–∏–∫–æ–º –ø–æ –∏–º–µ–Ω–∏ –ê–Ω—Ç–æ–Ω. –†–µ–±—ë–Ω–∫–∞ –¥–æ—Å—Ç–∞–≤–∏–ª–∏ –≤ –æ–∂–æ–≥–æ–≤—ã–π —Ü–µ–Ω—Ç—Ä. –û –µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ –Ω–∏—á–µ–≥–æ –Ω–µ —Å–æ–æ–±—â–∞–µ—Ç—Å—è.\\n\\n–ò–∑-–∑–∞ –≤–∑—Ä—ã–≤–∞ –Ω–∞ –º–µ—Å—Ç–µ –ø—Ä–æ–∏—Å—à–µ—Å—Ç–≤–∏—è –ø–æ–≥–∏–± –Ω–∞—Ö–æ–¥–∏–≤—à–∏–π—Å—è –≤ –º–∞—à–∏–Ω–µ –≥—Ä–∞–∂–¥–∞–Ω–∏–Ω –ì—Ä—É–∑–∏–∏ –±–æ–µ—Ü —á–µ—á–µ–Ω—Å–∫–æ–≥–æ –±–∞—Ç–∞–ª—å–æ–Ω–∞ –∏–º–µ–Ω–∏ —à–µ–π—Ö–∞ –ú–∞–Ω—Å—É—Ä–∞ —á–µ—á–µ–Ω–µ—Ü –¢–∏–º—É—Ä –ú–∞—Ö–∞—É—Ä–∏.\\n\\n–ò–Ω—Ü–∏–¥–µ–Ω—Ç –ø—Ä–æ–∏–∑–æ—à–µ–ª –≤ –ø—è—Ç–Ω–∏—Ü—É –æ–∫–æ–ª–æ 18:00 –º–µ–∂–¥—É —É–ª. –ë–∞—Å—Å–µ–π–Ω–æ–π –∏ –ë–æ–ª—å—à–æ–π –í–∞—Å–∏–ª—å–∫–æ–≤—Å–∫–æ–π. –í–∑–æ—Ä–≤–∞–≤—à–∏–π—Å—è –∞–≤—Ç–æ–º–æ–±–∏–ª—å ¬´–¢–æ–π–æ—Ç–∞ –ö–∞–º—Ä–∏¬ª –ø–æ–ª–Ω–æ—Å—Ç—å—é —É–Ω–∏—á—Ç–æ–∂–µ–Ω.\\n\\n–î–∏—Ä–µ–∫—Ç–æ—Ä –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç–∞ –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏ –ú–í–î –£–∫—Ä–∞–∏–Ω—ã –ê—Ä—Ç—ë–º –®–µ–≤—á–µ–Ω–∫–æ —Å–æ–æ–±—â–∞–ª –°–ú–ò:\\n–°–µ–≥–æ–¥–Ω—è –ø—Ä–æ–∏–∑–æ—à–µ–ª –≤–∑—Ä—ã–≤ –∞–≤—Ç–æ–º–æ–±–∏–ª—è, –≤ –∫–æ—Ç–æ—Ä–æ–º –Ω–∞—Ö–æ–¥–∏–ª–∏—Å—å —Ç—Ä–∏ —á–µ–ª–æ–≤–µ–∫–∞. –≠—Ç–æ —á–µ–ª–æ–≤–µ–∫, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–≥–∏–±, –∂–µ–Ω—â–∏–Ω–∞, –∫–æ—Ç–æ—Ä–∞—è –ø–æ–ª—É—á–∏–ª–∞ —Å–µ—Ä—å–µ–∑–Ω—ã–µ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è –∏ —Å–µ–π—á–∞—Å –∑–∞ –µ–µ –∂–∏–∑–Ω—å –±–æ—Ä—é—Ç—Å—è –º–µ–¥–∏–∫–∏, –∏ —Ä–µ–±–µ–Ω–æ–∫, –≤—ã–∂–∏–≤—à–∏–π –∏ –∂–∏–∑–Ω–∏ –∫–æ—Ç–æ—Ä–æ–≥–æ –Ω–∏—á–µ–≥–æ –Ω–µ —É–≥—Ä–æ–∂–∞–µ—Ç.\\n\\n–ü–æ —Å–ª–æ–≤–∞–º –®–µ–≤—á–µ–Ω–∫–æ, –≤ 2017 –≥–æ–¥—É –ú–∞—Ö–∞—É—Ä–∏ ‚Äî ¬´–ª–∏—Ü–æ, –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∏–∑–≤–µ—Å—Ç–Ω–æ–µ –≤ –∫—Ä–∏–º–∏–Ω–∞–ª—å–Ω—ã—Ö –∫—Ä—É–≥–∞—Ö, –∫–æ—Ç–æ—Ä–æ–µ –∏–º–µ–ª–æ —É—Å—Ç–æ–π—á–∏–≤—ã–µ —Å–≤—è–∑–∏ —Å —Ä–∞–∑–Ω–æ–≥–æ —Ä–æ–¥–∞ —á–µ—á–µ–Ω—Å–∫–∏–º–∏ –∫—Ä—É–≥–∞–º–∏¬ª, –±—ã–ª –∑–∞–¥–µ—Ä–∂–∞–Ω –∑–∞ –Ω–µ–∑–∞–∫–æ–Ω–Ω–æ–µ —Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ä—É–∂–∏—è. –ü–æ–∑–∂–µ –æ–Ω –∑–∞–∫–ª—é—á–∏–ª —Å–¥–µ–ª–∫—É —Å–æ —Å–ª–µ–¥—Å—Ç–≤–∏–µ–º –∏ –ø–æ–ª—É—á–∏–ª —É—Å–ª–æ–≤–Ω—ã–π —Å—Ä–æ–∫.\\n\\n–í–æ–∑–±—É–∂–¥–µ–Ω–æ —É–≥–æ–ª–æ–≤–Ω–æ–µ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–æ –ø–æ —Å—Ç. 115 —á. 2 ¬´–£–º—ã—à–ª–µ–Ω–Ω–æ–µ —É–±–∏–π—Å—Ç–≤–æ, —Å–æ–≤–µ—Ä—à–µ–Ω–Ω–æ–µ –æ–±—â–µ—Å—Ç–≤–µ–Ω–Ω–æ –æ–ø–∞—Å–Ω—ã–º —Å–ø–æ—Å–æ–±–æ–º¬ª. –°–æ–≥–ª–∞—Å–Ω–æ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–º –¥–∞–Ω–Ω—ã–º, –≤ –∞–≤—Ç–æ–º–æ–±–∏–ª–µ —Å—Ä–∞–±–æ—Ç–∞–ª–æ –≤–∑—Ä—ã–≤–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ.\\n\\n–ü–æ–ª–∏—Ü–∏—è –∏ –ù–∞—Ü–≥–≤–∞—Ä–¥–∏—è —É—Å–∏–ª–∏–ª–∏ –ø–∞—Ç—Ä—É–ª–∏—Ä–æ–≤–∞–Ω–∏–µ —Ü–µ–Ω—Ç—Ä–∞ –ö–∏–µ–≤–∞ –∏ –º–µ—Ç—Ä–æ –ø–æ—Å–ª–µ –≤–∑—Ä—ã–≤–∞ –Ω–∞ –ë–µ—Å—Å–∞—Ä–∞–±–∫–µ.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n9qywopnIrJH"
   },
   "source": [
    "## Preprocessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YVx71GdAIrJH"
   },
   "source": [
    "Before we can feed those texts to our model, we need to preprocess them. This is done by a ü§ó Transformers `Tokenizer` which will (as the name indicates) tokenize the inputs (including converting the tokens to their corresponding IDs in the pretrained vocabulary) and put it in a format the model expects, as well as generate the other inputs that model requires.\n",
    "\n",
    "To do all of this, we instantiate our tokenizer with the `AutoTokenizer.from_pretrained` method, which will ensure:\n",
    "\n",
    "- we get a tokenizer that corresponds to the model architecture we want to use,\n",
    "- we download the vocabulary used when pretraining this specific checkpoint.\n",
    "\n",
    "That vocabulary will be cached, so it's not downloaded again the next time we run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T04:46:19.860660Z",
     "start_time": "2024-04-11T04:46:17.257235Z"
    },
    "id": "eXNLu_-nIrJI"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T04:47:15.331420Z",
     "start_time": "2024-04-11T04:47:15.092698Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tokenizer.hf/tokenizer_config.json',\n",
       " 'tokenizer.hf/special_tokens_map.json',\n",
       " 'tokenizer.hf/vocab.txt',\n",
       " 'tokenizer.hf/added_tokens.json',\n",
       " 'tokenizer.hf/tokenizer.json')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(\"tokenizer.hf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vl6IidfdIrJK"
   },
   "source": [
    "The following assertion ensures that our tokenizer is a fast tokenizers (backed by Rust) from the ü§ó Tokenizers library. Those fast tokenizers are available for almost all models, and we will need some of the special features they have for our preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T16:12:47.378499Z",
     "start_time": "2024-04-10T16:12:47.375530Z"
    },
    "id": "-n0_1lnuYoUo"
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "assert isinstance(tokenizer, transformers.PreTrainedTokenizerFast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5nZHUROIYoUo"
   },
   "source": [
    "You can check which type of models have a fast tokenizer available and which don't on the [big table of models](https://huggingface.co/transformers/index.html#bigtable)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rowT4iCLIrJK"
   },
   "source": [
    "You can directly call this tokenizer on one sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T16:12:47.391599Z",
     "start_time": "2024-04-10T16:12:47.380279Z"
    },
    "id": "a5hBlsrHIrJL",
    "outputId": "acdaa98a-a8cd-4a20-89b8-cc26437bbe90"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 67124, 70471, 121, 26802, 13218, 30046, 118080, 12894, 177, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"Hello, this is one sentence!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i28NrDEPYoUt"
   },
   "source": [
    "Depending on the model you selected, you will see different keys in the dictionary returned by the cell above. They don't matter much for what we're doing here (just know they are required by the model we will instantiate later), you can learn more about them in [this tutorial](https://huggingface.co/transformers/preprocessing.html) if you're interested.\n",
    "\n",
    "If, as is the case here, your inputs have already been split into words, you should pass the list of words to your tokenzier with the argument `is_split_into_words=True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T16:12:47.406194Z",
     "start_time": "2024-04-10T16:12:47.393776Z"
    },
    "id": "pteRZjrYYoUt",
    "outputId": "0eb65824-32c6-47e6-faab-298f97ae1749"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 67124, 70471, 121, 26802, 13218, 30046, 118080, 12894, 16994, 69821, 443, 42038, 119660, 454, 126, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer([\"Hello\", \",\", \"this\", \"is\", \"one\", \"sentence\", \"split\", \"into\", \"words\", \".\"], is_split_into_words=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gati9HKdYoUt"
   },
   "source": [
    "Note that transformers are often pretrained with subword tokenizers, meaning that even if your inputs have been split into words already, each of those words could be split again by the tokenizer. Let's look at an example of that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T16:12:47.420708Z",
     "start_time": "2024-04-10T16:12:47.409378Z"
    },
    "id": "O3HfxAqUYoUt",
    "outputId": "5404d8cc-5203-4b13-c9d7-0cb393201451"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Facebook', '–Ω–∞—à–µ–ª', '–Ω–æ–≤–æ–≥–æ', '—Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–≥–æ', '–¥–∏—Ä–µ–∫—Ç–æ—Ä–∞', '–§–∏–Ω–∞–Ω—Å–æ–≤—ã–º', '–¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–º', '—Å–æ—Ü–∏–∞–ª—å–Ω–æ–π', '—Å–µ—Ç–∏', 'Facebook', '–Ω–∞–∑–Ω–∞—á–µ–Ω', '39-–ª–µ—Ç–Ω–∏–π', '–î—ç–≤–∏–¥', '–≠–±–µ—Ä—Å–º–∞–Ω', '(', 'David', 'Ebersman', '),', '—Å–æ–æ–±—â–∞–µ—Ç', 'The', 'Wall', 'Street', 'Journal', '.', '–ù–∞', '—Ä–∞–±–æ—Ç—É', '–≤', 'Facebook', '–æ–Ω', '–≤—ã–π–¥–µ—Ç', '–≤', '—Å–µ–Ω—Ç—è–±—Ä–µ', '.', '–†–∞–Ω–µ–µ', '–≠–±–µ—Ä—Å–º–∞–Ω', '–±—ã–ª', '—Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–º', '–¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–º', '–±–∏–æ—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–π', '–∫–æ–º–ø–∞–Ω–∏–∏', 'Genentech', '.', '–≠–±–µ—Ä—Å–º–∞–Ω', '–ø–æ–¥—á–µ—Ä–∫–Ω—É–ª,', '—á—Ç–æ', '–≤–∏–¥–∏—Ç', '–º–Ω–æ–≥–æ', '–æ–±—â–µ–≥–æ', '–º–µ–∂–¥—É', 'Facebook', '–∏', 'Genentech', '.', '–í', '—á–∞—Å—Ç–Ω–æ—Å—Ç–∏,', '—ç—Ç–æ', '–¥–≤–µ', '–±—ã—Å—Ç—Ä–æ—Ä–∞—Å—Ç—É—â–∏–µ', '–∫–æ–º–ø–∞–Ω–∏–∏', '—Å', '—Å–∏–ª—å–Ω–æ–π', '–∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–æ–π', '–∫—É–ª—å—Ç—É—Ä–æ–π.', '–¢–∞–∫–∂–µ', '–æ–Ω', '–∑–∞—è–≤–∏–ª,', '—á—Ç–æ', 'Facebook', '–æ–∂–∏–¥–∞–µ—Ç', '70-–ø—Ä–æ—Ü–µ–Ω—Ç–Ω–æ–µ', '—É–≤–µ–ª–∏—á–µ–Ω–∏–µ', '–≤—ã—Ä—É—á–∫–∏', '–≤', '2009', '–≥–æ–¥—É', '.', '–í', '–∫–æ–º–ø–∞–Ω–∏–∏', 'Genentech', '–î—ç–≤–∏–¥', '–≠–±–µ—Ä—Å–º–∞–Ω', '–ø—Ä–æ—Ä–∞–±–æ—Ç–∞–ª', '15', '–ª–µ—Ç', '.', '–ï–µ', '—Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–º', '–¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–º', '–æ–Ω', '—Å—Ç–∞–ª', '–≤', '2006', '–≥–æ–¥—É', '.', '–ù–∞', '—ç—Ç–æ–π', '–¥–æ–ª–∂–Ω–æ—Å—Ç–∏', '–≠–±–µ—Ä—Å–º–∞–Ω', '–ø—Ä–æ—Ä–∞–±–æ—Ç–∞–ª', '–¥–æ', '–∞–ø—Ä–µ–ª—è', '2009', '–≥–æ–¥–∞', ',', '–∫–æ–≥–¥–∞', 'Roche', 'Holding', '–∫—É–ø–∏–ª', 'Genentech', '.', '–ü–æ', '–¥–∞–Ω–Ω—ã–º', 'The', 'Wall', 'Street', 'Journal', ',', '–Ω–∞', '–¥–æ–ª–∂–Ω–æ—Å—Ç—å', '—Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–≥–æ', '–¥–∏—Ä–µ–∫—Ç–æ—Ä–∞', '—Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–≥–æ', '–¥–∏—Ä–µ–∫—Ç–æ—Ä–∞', 'Facebook', 'Facebook', '–ø—Ä–µ—Ç–µ–Ω–¥–æ–≤–∞–ª–∏', '11', '–∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤.', '–ö–∞–∂–¥—ã–π', '–∏–∑', '–Ω–∏—Ö', '–ø—Ä–æ—à–µ–ª', '—Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ', '—Å', '–æ—Å–Ω–æ–≤–∞—Ç–µ–ª–µ–º', 'Facebook', '–ú–∞—Ä–∫–æ–º', '–¶—É–∫–µ—Ä–±–µ—Ä–≥–æ–º', '(', 'Mark', 'Zuckerberg', ')', '–∏', '–¥—Ä—É–≥–∏–º–∏', '—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è–º–∏', '–∫–æ–º–ø–∞–Ω–∏–∏', '.', '–†–∞–Ω–µ–µ', '—Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–º', '–¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–º', '—Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–º', '–¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–º', 'Facebook', 'Facebook', '–±—ã–ª', '–ì–∏–¥–µ–æ–Ω', '–Æ', '(', 'Gideon', 'Yu', ').', '–û–Ω', '–ø–æ–∫–∏–Ω—É–ª', '–∫–æ–º–ø–∞–Ω–∏—é', '—Ç—Ä–∏', '–º–µ—Å—è—Ü–∞', '–Ω–∞–∑–∞–¥', '.', '–í–º–µ—Å—Ç–æ', '–Ω–µ–≥–æ', '—Å–æ—Ü–∏–∞–ª—å–Ω–∞—è', '—Å–µ—Ç—å', '—Ä–µ—à–∏–ª–∞', '–Ω–∞–Ω—è—Ç—å', '—Ç–æ–ø-–º–µ–Ω–µ–¥–∂–µ—Ä–∞', '—Å', '–æ–ø—ã—Ç–æ–º', '—Ä–∞–±–æ—Ç—ã', '–≤', '–ø—É–±–ª–∏—á–Ω–æ–π', '–∫–æ–º–ø–∞–Ω–∏–∏.', 'Facebook', '—è–≤–ª—è–µ—Ç—Å—è', '–∫—Ä—É–ø–Ω–µ–π—à–µ–π', '–∑–∞–ø–∞–¥–Ω–æ–π', '—Å–æ—Ü–∏–∞–ª—å–Ω–æ–π', '—Å–µ—Ç—å—é.', '–ó–∞', '–ø—è—Ç—å', '–ª–µ—Ç', '—Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è', '—ç—Ç–æ–≥–æ', '–ø—Ä–æ–µ–∫—Ç–∞', '–µ–≥–æ', '–∞—É–¥–∏—Ç–æ—Ä–∏—è', '–ø—Ä–µ–≤—ã—Å–∏–ª–∞', '200', '–º–∏–ª–ª–∏–æ–Ω–æ–≤', '—á–µ–ª–æ–≤–µ–∫.']\n"
     ]
    }
   ],
   "source": [
    "example = train_dataset[4]\n",
    "print(example[\"tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T16:12:47.433313Z",
     "start_time": "2024-04-10T16:12:47.424289Z"
    },
    "id": "MPiR1SNxYoUt",
    "outputId": "3249e0f4-957a-4013-e1ed-9f67146c0c2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'facebook', '–Ω–∞—à–µ–ª', '–Ω–æ–≤–æ–≥–æ', '—Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–≥–æ', '–¥–∏—Ä–µ–∫—Ç–æ—Ä–∞', '—Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–º', '–¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–º', '—Å–æ—Ü–∏–∞–ª—å–Ω–æ', '##–∏', '—Å–µ—Ç–∏', 'facebook', '–Ω–∞–∑–Ω–∞—á–µ–Ω', '39', '-', '–ª–µ—Ç', '##–Ω–∏–∏', '–¥—ç', '##–≤–∏–¥', '—ç', '##–±–µ—Ä', '##—Å–º–∞–Ω', '(', 'dav', '##id', 'e', '##ber', '##sm', '##an', ')', ',', '—Å–æ–æ–±—â–∞–µ—Ç', 'the', 'w', '##all', 'str', '##ee', '##t', 'j', '##ournal', '.', '–Ω–∞', '—Ä–∞–±–æ—Ç—É', '–≤', 'facebook', '–æ–Ω', '–≤—ã–∏', '##–¥–µ—Ç', '–≤', '—Å–µ–Ω—Ç—è–±—Ä–µ', '.', '—Ä–∞–Ω–µ–µ', '—ç', '##–±–µ—Ä', '##—Å–º–∞–Ω', '–±—ã–ª', '—Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–º', '–¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–º', '–±–∏–æ—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏', '##—á–µ—Å–∫–æ', '##–∏', '–∫–æ–º–ø–∞–Ω–∏–∏', 'gen', '##ente', '##ch', '.', '—ç', '##–±–µ—Ä', '##—Å–º–∞–Ω', '–ø–æ–¥—á–µ—Ä–∫–Ω—É–ª', ',', '—á—Ç–æ', '–≤–∏–¥–∏—Ç', '–º–Ω–æ–≥–æ', '–æ–±—â–µ–≥–æ', '–º–µ–∂–¥—É', 'facebook', '–∏', 'gen', '##ente', '##ch', '.', '–≤', '—á–∞—Å—Ç–Ω–æ—Å—Ç–∏', ',', '—ç—Ç–æ', '–¥–≤–µ', '–±—ã—Å—Ç—Ä–æ—Ä–∞—Å—Ç—É', '##—â–∏–µ', '–∫–æ–º–ø–∞–Ω–∏–∏', '—Å', '—Å–∏–ª—å–Ω–æ', '##–∏', '–∫–æ—Ä–ø–æ—Ä–∞', '##—Ç–∏–≤–Ω–æ', '##–∏', '–∫—É–ª—å—Ç—É—Ä–æ', '##–∏', '.', '—Ç–∞–∫–∂–µ', '–æ–Ω', '–∑–∞—è–≤–∏–ª', ',', '—á—Ç–æ', 'facebook', '–æ–∂–∏–¥–∞–µ—Ç', '70', '-', '–ø—Ä–æ—Ü–µ–Ω—Ç', '##–Ω–æ–µ', '—É–≤–µ–ª–∏—á–µ–Ω–∏–µ', '–≤—ã—Ä—É—á–∫–∏', '–≤', '2009', '–≥–æ–¥—É', '.', '–≤', '–∫–æ–º–ø–∞–Ω–∏–∏', 'gen', '##ente', '##ch', '–¥—ç', '##–≤–∏–¥', '—ç', '##–±–µ—Ä', '##—Å–º–∞–Ω', '–ø—Ä–æ—Ä–∞–±–æ—Ç–∞–ª', '15', '–ª–µ—Ç', '.', '–µ–µ', '—Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–º', '–¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–º', '–æ–Ω', '—Å—Ç–∞–ª', '–≤', '2006', '–≥–æ–¥—É', '.', '–Ω–∞', '—ç—Ç–æ', '##–∏', '–¥–æ–ª–∂–Ω–æ—Å—Ç–∏', '—ç', '##–±–µ—Ä', '##—Å–º–∞–Ω', '–ø—Ä–æ—Ä–∞–±–æ—Ç–∞–ª', '–¥–æ', '–∞–ø—Ä–µ–ª—è', '2009', '–≥–æ–¥–∞', ',', '–∫–æ–≥–¥–∞', 'ro', '##che', 'h', '##old', '##ing', '–∫—É–ø–∏–ª', 'gen', '##ente', '##ch', '.', '–ø–æ', '–¥–∞–Ω–Ω—ã–º', 'the', 'w', '##all', 'str', '##ee', '##t', 'j', '##ournal', ',', '–Ω–∞', '–¥–æ–ª–∂–Ω–æ—Å—Ç—å', '—Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–≥–æ', '–¥–∏—Ä–µ–∫—Ç–æ—Ä–∞', '—Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–≥–æ', '–¥–∏—Ä–µ–∫—Ç–æ—Ä–∞', 'facebook', 'facebook', '–ø—Ä–µ—Ç–µ–Ω–¥–æ–≤–∞–ª–∏', '11', '–∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤', '.', '–∫–∞–∂–¥—ã', '##–∏', '–∏–∑', '–Ω–∏—Ö', '–ø—Ä–æ—à–µ–ª', '—Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ', '—Å', '–æ—Å–Ω–æ–≤–∞—Ç–µ–ª–µ–º', 'facebook', '–º–∞—Ä–∫', '##–æ–º', '—Ü—É', '##–∫–µ—Ä', '##–±–µ—Ä–≥–æ–º', '(', 'mark', 'zu', '##ck', '##er', '##berg', ')', '–∏', '–¥—Ä—É–≥–∏–º–∏', '—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è–º–∏', '–∫–æ–º–ø–∞–Ω–∏–∏', '.', '—Ä–∞–Ω–µ–µ', '—Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–º', '–¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–º', '—Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–º', '–¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–º', 'facebook', 'facebook', '–±—ã–ª', '–≥–∏–¥', '##–µ', '##–æ–Ω', '—é', '(', 'g', '##ideo', '##n', 'y', '##u', ')', '.', '–æ–Ω', '–ø–æ–∫–∏–Ω—É–ª', '–∫–æ–º–ø–∞–Ω–∏—é', '—Ç—Ä–∏', '–º–µ—Å—è—Ü–∞', '–Ω–∞–∑–∞–¥', '.', '–≤–º–µ—Å—Ç–æ', '–Ω–µ–≥–æ', '—Å–æ—Ü–∏–∞–ª—å–Ω–∞—è', '—Å–µ—Ç—å', '—Ä–µ—à–∏–ª–∞', '–Ω–∞–Ω—è—Ç—å', '—Ç–æ–ø', '-', '–º–µ–Ω–µ–¥–∂–µ—Ä–∞', '—Å', '–æ–ø—ã—Ç–æ–º', '—Ä–∞–±–æ—Ç—ã', '–≤', '–ø—É–±–ª–∏—á–Ω–æ', '##–∏', '–∫–æ–º–ø–∞–Ω–∏–∏', '.', 'facebook', '—è–≤–ª—è–µ—Ç—Å—è', '–∫—Ä—É–ø', '##–Ω–µ', '##–∏', '##—à–µ', '##–∏', '–∑–∞–ø–∞–¥–Ω–æ', '##–∏', '—Å–æ—Ü–∏–∞–ª—å–Ω–æ', '##–∏', '—Å–µ—Ç—å—é', '.', '–∑–∞', '–ø—è—Ç—å', '–ª–µ—Ç', '—Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è', '—ç—Ç–æ–≥–æ', '–ø—Ä–æ–µ–∫—Ç–∞', '–µ–≥–æ', '–∞—É–¥–∏—Ç–æ—Ä–∏—è', '–ø—Ä–µ–≤—ã—Å–∏–ª–∞', '200', '–º–∏–ª–ª–∏–æ–Ω–æ–≤', '—á–µ–ª–æ–≤–µ–∫', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "tokenized_input = tokenizer(example[\"tokens\"], is_split_into_words=True)\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VPuTUJPhYoUt"
   },
   "source": [
    "Here the words \"Zwingmann\" and \"sheepmeat\" have been split in three subtokens.\n",
    "\n",
    "This means that we need to do some processing on our labels as the input ids returned by the tokenizer are longer than the lists of labels our dataset contain, first because some special tokens might be added (we can a `[CLS]` and a `[SEP]` above) and then because of those possible splits of words in multiple tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T16:12:47.451732Z",
     "start_time": "2024-04-10T16:12:47.445797Z"
    },
    "id": "P21pkSmiYoUt",
    "outputId": "aca85ec0-3119-4967-dda8-91e24e4a9fd8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199, 283)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(example[f\"{task}_tags\"]), len(tokenized_input[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cdWxuHvoYoUu"
   },
   "source": [
    "Thankfully, the tokenizer returns outputs that have a `word_ids` method which can help us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T16:12:47.458267Z",
     "start_time": "2024-04-10T16:12:47.454502Z"
    },
    "id": "3FWUGBqQYoUu",
    "outputId": "7dbf269e-87d0-46c7-cd29-9244d43f08a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 0, 1, 2, 3, 4, 5, 6, 7, 7, 8, 9, 10, 11, 11, 11, 11, 12, 12, 13, 13, 13, 14, 15, 15, 16, 16, 16, 16, 17, 17, 18, 19, 20, 20, 21, 21, 21, 22, 22, 23, 24, 25, 26, 27, 28, 29, 29, 30, 31, 32, 33, 34, 34, 34, 35, 36, 37, 38, 38, 38, 39, 40, 40, 40, 41, 42, 42, 42, 43, 43, 44, 45, 46, 47, 48, 49, 50, 51, 51, 51, 52, 53, 54, 54, 55, 56, 57, 57, 58, 59, 60, 60, 61, 61, 61, 62, 62, 62, 63, 64, 65, 65, 66, 67, 68, 69, 69, 69, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 78, 78, 79, 79, 80, 80, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 95, 96, 97, 97, 97, 98, 99, 100, 101, 102, 103, 104, 105, 105, 106, 106, 106, 107, 108, 108, 108, 109, 110, 111, 112, 113, 113, 114, 114, 114, 115, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 127, 128, 128, 129, 130, 131, 132, 133, 134, 135, 136, 136, 137, 137, 137, 138, 139, 140, 140, 140, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 155, 155, 156, 157, 158, 158, 158, 159, 159, 160, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 174, 174, 175, 176, 177, 178, 179, 179, 180, 180, 181, 182, 183, 183, 183, 183, 183, 184, 184, 185, 185, 186, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 198, None]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_input.word_ids())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hX6jEEBzYoUu"
   },
   "source": [
    "As we can see, it returns a list with the same number of elements as our processed input ids, mapping special tokens to `None` and all other tokens to their respective word. This way, we can align the labels with the processed input ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T16:12:47.468397Z",
     "start_time": "2024-04-10T16:12:47.459722Z"
    },
    "id": "XY0QUrK5YoUu",
    "outputId": "bddcceab-a963-4483-c48a-cd5394a46cb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283 283\n",
      "[CLS] -100\n",
      "facebook B-ORGANIZATION\n",
      "–Ω–∞—à–µ–ª O\n",
      "–Ω–æ–≤–æ–≥–æ O\n",
      "—Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–≥–æ B-PROFESSION\n",
      "–¥–∏—Ä–µ–∫—Ç–æ—Ä–∞ I-PROFESSION\n",
      "—Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–º B-PROFESSION\n",
      "–¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–º I-PROFESSION\n",
      "—Å–æ—Ü–∏–∞–ª—å–Ω–æ O\n",
      "##–∏ O\n",
      "—Å–µ—Ç–∏ O\n",
      "facebook B-ORGANIZATION\n",
      "–Ω–∞–∑–Ω–∞—á–µ–Ω B-EVENT\n",
      "39 B-AGE\n",
      "- B-AGE\n",
      "–ª–µ—Ç B-AGE\n",
      "##–Ω–∏–∏ B-AGE\n",
      "–¥—ç B-PERSON\n",
      "##–≤–∏–¥ B-PERSON\n",
      "—ç I-PERSON\n",
      "##–±–µ—Ä I-PERSON\n",
      "##—Å–º–∞–Ω I-PERSON\n",
      "( O\n",
      "dav B-PERSON\n",
      "##id B-PERSON\n",
      "e I-PERSON\n",
      "##ber I-PERSON\n",
      "##sm I-PERSON\n",
      "##an I-PERSON\n",
      ") O\n",
      ", O\n",
      "—Å–æ–æ–±—â–∞–µ—Ç O\n",
      "the B-ORGANIZATION\n",
      "w I-ORGANIZATION\n",
      "##all I-ORGANIZATION\n",
      "str I-ORGANIZATION\n",
      "##ee I-ORGANIZATION\n",
      "##t I-ORGANIZATION\n",
      "j I-ORGANIZATION\n",
      "##ournal I-ORGANIZATION\n",
      ". O\n",
      "–Ω–∞ O\n",
      "—Ä–∞–±–æ—Ç—É O\n",
      "–≤ O\n",
      "facebook B-ORGANIZATION\n",
      "–æ–Ω O\n",
      "–≤—ã–∏ O\n",
      "##–¥–µ—Ç O\n",
      "–≤ B-DATE\n",
      "—Å–µ–Ω—Ç—è–±—Ä–µ I-DATE\n",
      ". O\n",
      "—Ä–∞–Ω–µ–µ O\n",
      "—ç B-PERSON\n",
      "##–±–µ—Ä B-PERSON\n",
      "##—Å–º–∞–Ω B-PERSON\n",
      "–±—ã–ª O\n",
      "—Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–º B-PROFESSION\n",
      "–¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–º I-PROFESSION\n",
      "–±–∏–æ—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏ O\n",
      "##—á–µ—Å–∫–æ O\n",
      "##–∏ O\n",
      "–∫–æ–º–ø–∞–Ω–∏–∏ O\n",
      "gen B-ORGANIZATION\n",
      "##ente B-ORGANIZATION\n",
      "##ch B-ORGANIZATION\n",
      ". O\n",
      "—ç B-PERSON\n",
      "##–±–µ—Ä B-PERSON\n",
      "##—Å–º–∞–Ω B-PERSON\n",
      "–ø–æ–¥—á–µ—Ä–∫–Ω—É–ª O\n",
      ", O\n",
      "—á—Ç–æ O\n",
      "–≤–∏–¥–∏—Ç O\n",
      "–º–Ω–æ–≥–æ O\n",
      "–æ–±—â–µ–≥–æ O\n",
      "–º–µ–∂–¥—É O\n",
      "facebook B-ORGANIZATION\n",
      "–∏ O\n",
      "gen B-ORGANIZATION\n",
      "##ente B-ORGANIZATION\n",
      "##ch B-ORGANIZATION\n",
      ". O\n",
      "–≤ O\n",
      "—á–∞—Å—Ç–Ω–æ—Å—Ç–∏ O\n",
      ", O\n",
      "—ç—Ç–æ O\n",
      "–¥–≤–µ B-NUMBER\n",
      "–±—ã—Å—Ç—Ä–æ—Ä–∞—Å—Ç—É O\n",
      "##—â–∏–µ O\n",
      "–∫–æ–º–ø–∞–Ω–∏–∏ O\n",
      "—Å O\n",
      "—Å–∏–ª—å–Ω–æ O\n",
      "##–∏ O\n",
      "–∫–æ—Ä–ø–æ—Ä–∞ O\n",
      "##—Ç–∏–≤–Ω–æ O\n",
      "##–∏ O\n",
      "–∫—É–ª—å—Ç—É—Ä–æ O\n",
      "##–∏ O\n",
      ". O\n",
      "—Ç–∞–∫–∂–µ O\n",
      "–æ–Ω O\n",
      "–∑–∞—è–≤–∏–ª O\n",
      ", O\n",
      "—á—Ç–æ O\n",
      "facebook B-ORGANIZATION\n",
      "–æ–∂–∏–¥–∞–µ—Ç O\n",
      "70 B-PERCENT\n",
      "- B-PERCENT\n",
      "–ø—Ä–æ—Ü–µ–Ω—Ç B-PERCENT\n",
      "##–Ω–æ–µ B-PERCENT\n",
      "—É–≤–µ–ª–∏—á–µ–Ω–∏–µ O\n",
      "–≤—ã—Ä—É—á–∫–∏ O\n",
      "–≤ B-DATE\n",
      "2009 I-DATE\n",
      "–≥–æ–¥—É I-DATE\n",
      ". O\n",
      "–≤ O\n",
      "–∫–æ–º–ø–∞–Ω–∏–∏ O\n",
      "gen B-ORGANIZATION\n",
      "##ente B-ORGANIZATION\n",
      "##ch B-ORGANIZATION\n",
      "–¥—ç B-PERSON\n",
      "##–≤–∏–¥ B-PERSON\n",
      "—ç I-PERSON\n",
      "##–±–µ—Ä I-PERSON\n",
      "##—Å–º–∞–Ω I-PERSON\n",
      "–ø—Ä–æ—Ä–∞–±–æ—Ç–∞–ª O\n",
      "15 B-DATE\n",
      "–ª–µ—Ç I-DATE\n",
      ". O\n",
      "–µ–µ O\n",
      "—Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–º B-PROFESSION\n",
      "–¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–º I-PROFESSION\n",
      "–æ–Ω O\n",
      "—Å—Ç–∞–ª O\n",
      "–≤ B-DATE\n",
      "2006 I-DATE\n",
      "–≥–æ–¥—É I-DATE\n",
      ". O\n",
      "–Ω–∞ O\n",
      "—ç—Ç–æ O\n",
      "##–∏ O\n",
      "–¥–æ–ª–∂–Ω–æ—Å—Ç–∏ O\n",
      "—ç B-PERSON\n",
      "##–±–µ—Ä B-PERSON\n",
      "##—Å–º–∞–Ω B-PERSON\n",
      "–ø—Ä–æ—Ä–∞–±–æ—Ç–∞–ª O\n",
      "–¥–æ B-DATE\n",
      "–∞–ø—Ä–µ–ª—è I-DATE\n",
      "2009 I-DATE\n",
      "–≥–æ–¥–∞ I-DATE\n",
      ", O\n",
      "–∫–æ–≥–¥–∞ O\n",
      "ro B-ORGANIZATION\n",
      "##che B-ORGANIZATION\n",
      "h I-ORGANIZATION\n",
      "##old I-ORGANIZATION\n",
      "##ing I-ORGANIZATION\n",
      "–∫—É–ø–∏–ª B-EVENT\n",
      "gen B-ORGANIZATION\n",
      "##ente B-ORGANIZATION\n",
      "##ch B-ORGANIZATION\n",
      ". O\n",
      "–ø–æ O\n",
      "–¥–∞–Ω–Ω—ã–º O\n",
      "the B-ORGANIZATION\n",
      "w I-ORGANIZATION\n",
      "##all I-ORGANIZATION\n",
      "str I-ORGANIZATION\n",
      "##ee I-ORGANIZATION\n",
      "##t I-ORGANIZATION\n",
      "j I-ORGANIZATION\n",
      "##ournal I-ORGANIZATION\n",
      ", O\n",
      "–Ω–∞ O\n",
      "–¥–æ–ª–∂–Ω–æ—Å—Ç—å O\n",
      "—Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–≥–æ B-PROFESSION\n",
      "–¥–∏—Ä–µ–∫—Ç–æ—Ä–∞ I-PROFESSION\n",
      "—Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–≥–æ B-PROFESSION\n",
      "–¥–∏—Ä–µ–∫—Ç–æ—Ä–∞ I-PROFESSION\n",
      "facebook I-PROFESSION\n",
      "facebook B-ORGANIZATION\n",
      "–ø—Ä–µ—Ç–µ–Ω–¥–æ–≤–∞–ª–∏ O\n",
      "11 B-NUMBER\n",
      "–∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ O\n",
      ". O\n",
      "–∫–∞–∂–¥—ã O\n",
      "##–∏ O\n",
      "–∏–∑ O\n",
      "–Ω–∏—Ö O\n",
      "–ø—Ä–æ—à–µ–ª O\n",
      "—Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ O\n",
      "—Å O\n",
      "–æ—Å–Ω–æ–≤–∞—Ç–µ–ª–µ–º O\n",
      "facebook B-ORGANIZATION\n",
      "–º–∞—Ä–∫ B-PERSON\n",
      "##–æ–º B-PERSON\n",
      "—Ü—É I-PERSON\n",
      "##–∫–µ—Ä I-PERSON\n",
      "##–±–µ—Ä–≥–æ–º I-PERSON\n",
      "( O\n",
      "mark B-PERSON\n",
      "zu I-PERSON\n",
      "##ck I-PERSON\n",
      "##er I-PERSON\n",
      "##berg I-PERSON\n",
      ") O\n",
      "–∏ O\n",
      "–¥—Ä—É–≥–∏–º–∏ O\n",
      "—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è–º–∏ B-PROFESSION\n",
      "–∫–æ–º–ø–∞–Ω–∏–∏ I-PROFESSION\n",
      ". O\n",
      "—Ä–∞–Ω–µ–µ O\n",
      "—Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–º B-PROFESSION\n",
      "–¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–º I-PROFESSION\n",
      "—Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–º B-PROFESSION\n",
      "–¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–º I-PROFESSION\n",
      "facebook I-PROFESSION\n",
      "facebook B-ORGANIZATION\n",
      "–±—ã–ª O\n",
      "–≥–∏–¥ B-PERSON\n",
      "##–µ B-PERSON\n",
      "##–æ–Ω B-PERSON\n",
      "—é I-PERSON\n",
      "( O\n",
      "g B-PERSON\n",
      "##ideo B-PERSON\n",
      "##n B-PERSON\n",
      "y I-PERSON\n",
      "##u I-PERSON\n",
      ") O\n",
      ". O\n",
      "–æ–Ω O\n",
      "–ø–æ–∫–∏–Ω—É–ª B-EVENT\n",
      "–∫–æ–º–ø–∞–Ω–∏—é I-EVENT\n",
      "—Ç—Ä–∏ B-DATE\n",
      "–º–µ—Å—è—Ü–∞ I-DATE\n",
      "–Ω–∞–∑–∞–¥ I-DATE\n",
      ". O\n",
      "–≤–º–µ—Å—Ç–æ O\n",
      "–Ω–µ–≥–æ O\n",
      "—Å–æ—Ü–∏–∞–ª—å–Ω–∞—è O\n",
      "—Å–µ—Ç—å O\n",
      "—Ä–µ—à–∏–ª–∞ O\n",
      "–Ω–∞–Ω—è—Ç—å O\n",
      "—Ç–æ–ø B-PROFESSION\n",
      "- B-PROFESSION\n",
      "–º–µ–Ω–µ–¥–∂–µ—Ä–∞ B-PROFESSION\n",
      "—Å O\n",
      "–æ–ø—ã—Ç–æ–º O\n",
      "—Ä–∞–±–æ—Ç—ã O\n",
      "–≤ O\n",
      "–ø—É–±–ª–∏—á–Ω–æ O\n",
      "##–∏ O\n",
      "–∫–æ–º–ø–∞–Ω–∏–∏ O\n",
      ". O\n",
      "facebook B-ORGANIZATION\n",
      "—è–≤–ª—è–µ—Ç—Å—è O\n",
      "–∫—Ä—É–ø O\n",
      "##–Ω–µ O\n",
      "##–∏ O\n",
      "##—à–µ O\n",
      "##–∏ O\n",
      "–∑–∞–ø–∞–¥–Ω–æ B-LOCATION\n",
      "##–∏ B-LOCATION\n",
      "—Å–æ—Ü–∏–∞–ª—å–Ω–æ O\n",
      "##–∏ O\n",
      "—Å–µ—Ç—å—é O\n",
      ". O\n",
      "–∑–∞ B-DATE\n",
      "–ø—è—Ç—å I-DATE\n",
      "–ª–µ—Ç I-DATE\n",
      "—Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è O\n",
      "—ç—Ç–æ–≥–æ O\n",
      "–ø—Ä–æ–µ–∫—Ç–∞ O\n",
      "–µ–≥–æ O\n",
      "–∞—É–¥–∏—Ç–æ—Ä–∏—è O\n",
      "–ø—Ä–µ–≤—ã—Å–∏–ª–∞ O\n",
      "200 B-NUMBER\n",
      "–º–∏–ª–ª–∏–æ–Ω–æ–≤ I-NUMBER\n",
      "—á–µ–ª–æ–≤–µ–∫ O\n",
      ". O\n",
      "[SEP] -100\n"
     ]
    }
   ],
   "source": [
    "word_ids = tokenized_input.word_ids()\n",
    "aligned_labels = [-100 if i is None else example[f\"{task}_tags\"][i] for i in word_ids]\n",
    "print(len(aligned_labels), len(tokenized_input[\"input_ids\"]))\n",
    "for i in range(len(aligned_labels)):\n",
    "    print(*tokenizer.convert_ids_to_tokens([tokenized_input[\"input_ids\"][i]]), aligned_labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nejP5Y5DYoUu"
   },
   "source": [
    "Here we set the labels of all special tokens to -100 (the index that is ignored by PyTorch) and the labels of all other tokens to the label of the word they come from. Another strategy is to set the label only on the first token obtained from a given word, and give a label of -100 to the other subtokens from the same word. We propose the two strategies here, just change the value of the following flag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T16:12:47.473322Z",
     "start_time": "2024-04-10T16:12:47.469932Z"
    },
    "id": "DSfs0DqCYoUu"
   },
   "outputs": [],
   "source": [
    "label_all_tokens = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2C0hcmp9IrJQ"
   },
   "source": [
    "We're now ready to write the function that will preprocess our samples. We feed them to the `tokenizer` with the argument `truncation=True` (to truncate texts that are bigger than the maximum size allowed by the model) and `is_split_into_words=True` (as seen above). Then we align the labels with the token ids using the strategy we picked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T16:12:47.481341Z",
     "start_time": "2024-04-10T16:12:47.474745Z"
    }
   },
   "outputs": [],
   "source": [
    "label2id = {\n",
    "    'O': 0,\n",
    "    'B-AGE': 1,\n",
    "    'I-AGE': 2,\n",
    "    'B-AWARD': 3,\n",
    "    'I-AWARD': 4,\n",
    "    'B-CITY': 5,\n",
    "    'I-CITY': 6,\n",
    "    'B-COUNTRY': 7,\n",
    "    'I-COUNTRY': 8,\n",
    "    'B-CRIME': 9,\n",
    "    'I-CRIME': 10,\n",
    "    'B-DATE': 11,\n",
    "    'I-DATE': 12,\n",
    "    'B-DISEASE': 13,\n",
    "    'I-DISEASE': 14,\n",
    "    'B-DISTRICT': 15,\n",
    "    'I-DISTRICT': 16,\n",
    "    'B-EVENT': 17,\n",
    "    'I-EVENT': 18,\n",
    "    'B-FACILITY': 19,\n",
    "    'I-FACILITY': 20,\n",
    "    'B-FAMILY': 21,\n",
    "    'I-FAMILY': 22,\n",
    "    'B-IDEOLOGY': 23,\n",
    "    'I-IDEOLOGY': 24,\n",
    "    'B-LANGUAGE': 25,\n",
    "    'I-LANGUAGE': 26,\n",
    "    'B-LAW': 27,\n",
    "    'I-LAW': 28,\n",
    "    'B-LOCATION': 29,\n",
    "    'I-LOCATION': 30,\n",
    "    'B-MONEY': 31,\n",
    "    'I-MONEY': 32,\n",
    "    'B-NATIONALITY': 33,\n",
    "    'I-NATIONALITY': 34,\n",
    "    'B-NUMBER': 35,\n",
    "    'I-NUMBER': 36,\n",
    "    'B-ORDINAL': 37,\n",
    "    'I-ORDINAL': 38,\n",
    "    'B-ORGANIZATION': 39,\n",
    "    'I-ORGANIZATION': 40,\n",
    "    'B-PENALTY': 41,\n",
    "    'I-PENALTY': 42,\n",
    "    'B-PERCENT': 43,\n",
    "    'I-PERCENT': 44,\n",
    "    'B-PERSON': 45,\n",
    "    'I-PERSON': 46,\n",
    "    'B-PRODUCT': 47,\n",
    "    'I-PRODUCT': 48,\n",
    "    'B-PROFESSION': 49,\n",
    "    'I-PROFESSION': 50,\n",
    "    'B-RELIGION': 51,\n",
    "    'I-RELIGION': 52,\n",
    "    'B-STATE_OR_PROVINCE': 53,\n",
    "    'I-STATE_OR_PROVINCE': 54,\n",
    "    'B-TIME': 55,\n",
    "    'I-TIME': 56,\n",
    "    'B-WORK_OF_ART': 57,\n",
    "    'I-WORK_OF_ART': 58,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T16:12:47.490886Z",
     "start_time": "2024-04-10T16:12:47.483280Z"
    },
    "id": "vc0BSBLIIrJQ"
   },
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    \n",
    "    transformed = {\"id\": [], \"text\": [], \"tokens\": [], \"ner_tags\": []}\n",
    "    \n",
    "    for idx, text, entities in zip(examples[\"id\"], examples[\"text\"], examples[\"entities\"]):\n",
    "        tokens, ner_tags = transform(text, transform_entities(entities))\n",
    "        transformed[\"id\"].append(idx)\n",
    "        transformed[\"text\"].append(text)\n",
    "        transformed[\"tokens\"].append(tokens)\n",
    "        transformed[\"ner_tags\"].append(ner_tags)\n",
    "    \n",
    "    tokenized_inputs = tokenizer(transformed[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(transformed[f\"{task}_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
    "            # ignored in the loss function.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            # We set the label for the first token of each word.\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label2id[label[word_idx]])\n",
    "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
    "            # the label_all_tokens flag.\n",
    "            else:\n",
    "                label_ids.append(label2id[label[word_idx]] if label_all_tokens else -100)\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0lm8ozrJIrJR"
   },
   "source": [
    "This function works with one or several examples. In the case of several examples, the tokenizer will return a list of lists for each key:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "voWiw8C7IrJV"
   },
   "source": [
    "Even better, the results are automatically cached by the ü§ó Datasets library to avoid spending time on this step the next time you run your notebook. The ü§ó Datasets library is normally smart enough to detect when the function you pass to map has changed (and thus requires to not use the cache data). For instance, it will properly detect if you change the task in the first cell and rerun the notebook. ü§ó Datasets warns you when it uses cached files, you can pass `load_from_cache_file=False` in the call to `map` to not use the cached files and force the preprocessing to be applied again.\n",
    "\n",
    "Note that we passed `batched=True` to encode the texts by batches together. This is to leverage the full benefit of the fast tokenizer we loaded earlier, which will use multi-threading to treat the texts in a batch concurrently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "545PP3o8IrJV"
   },
   "source": [
    "## Fine-tuning the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FBiW8UpKIrJW"
   },
   "source": [
    "Now that our data is ready, we can download the pretrained model and fine-tune it. Since all our tasks are about token classification, we use the `AutoModelForTokenClassification` class. Like with the tokenizer, the `from_pretrained` method will download and cache the model for us. The only thing we have to specify is the number of labels for our problem (which we can get from the features, as seen before):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CczA5lJlIrJX"
   },
   "source": [
    "The warning is telling us we are throwing away some weights (the `vocab_transform` and `vocab_layer_norm` layers) and randomly initializing some other (the `pre_classifier` and `classifier` layers). This is absolutely normal in this case, because we are removing the head used to pretrain the model on a masked language modeling objective and replacing it with a new head for which we don't have pretrained weights, so the library warns us we should fine-tune this model before using it for inference, which is exactly what we are going to do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_N8urzhyIrJY"
   },
   "source": [
    "To instantiate a `Trainer`, we will need to define three more things. The most important is the [`TrainingArguments`](https://huggingface.co/transformers/main_classes/trainer.html#transformers.TrainingArguments), which is a class that contains all the attributes to customize the training. It requires one folder name, which will be used to save the checkpoints of the model, and all other arguments are optional:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T16:12:52.730095Z",
     "start_time": "2024-04-10T16:12:52.584317Z"
    },
    "id": "Bliy8zgjIrJY"
   },
   "outputs": [],
   "source": [
    "model_name = model_checkpoint.split(\"/\")[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "km3pGVdTIrJc"
   },
   "source": [
    "Here we set the evaluation to be done at the end of each epoch, tweak the learning rate, use the `batch_size` defined at the top of the notebook and customize the number of epochs for training, as well as the weight decay.\n",
    "\n",
    "The last argument to setup everything so we can push the model to the [Hub](https://huggingface.co/models) regularly during training. Remove it if you didn't follow the installation steps at the top of the notebook. If you want to save your model locally in a name that is different than the name of the repository it will be pushed, or if you want to push your model under an organization and not your name space, use the `hub_model_id` argument to set the repo name (it needs to be the full name, including your namespace: for instance `\"sgugger/bert-finetuned-ner\"` or `\"huggingface/bert-finetuned-ner\"`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W3GyIIRKYoUv"
   },
   "source": [
    "Then we will need a data collator that will batch our processed examples together while applying padding to make them all the same size (each pad will be padded to the length of its longest example). There is a data collator for this task in the Transformers library, that not only pads the inputs, but also the labels:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rXuFTAzDIrJe"
   },
   "source": [
    "Note that we drop the precision/recall/f1 computed for each category and only focus on the overall precision/recall/f1/accuracy.\n",
    "\n",
    "Then we just need to pass all of this along with our datasets to the `Trainer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import AutoTokenizer\n",
    "import json\n",
    "import warnings\n",
    "import torch\n",
    "import sys \n",
    "\n",
    "class MyConversionScript():\n",
    "\n",
    "    _ARCHITECTURE_TYPE_DICT = {}\n",
    "    _ARCHITECTURE_TYPE_DICT = {**{\"LSG\" + k: v for k, v in _ARCHITECTURE_TYPE_DICT.items()}, **_ARCHITECTURE_TYPE_DICT}\n",
    "    _BASE_ARCHITECTURE_TYPE = None\n",
    "    _DEFAULT_ARCHITECTURE_TYPE = None\n",
    "    _CONFIG_MODULE = None\n",
    "\n",
    "    _DEFAULT_CONFIG_POSITIONAL_OFFSET = 0\n",
    "    _DEFAULT_POSITIONAL_OFFSET = 0\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        initial_model, \n",
    "        model_name, \n",
    "        max_sequence_length, \n",
    "        architecture, \n",
    "        random_global_init, \n",
    "        global_positional_stride, \n",
    "        keep_first_global_token, \n",
    "        resize_lsg, \n",
    "        model_kwargs, \n",
    "        use_token_ids,\n",
    "        use_auth_token,\n",
    "        config,\n",
    "        save_model,\n",
    "        seed\n",
    "        ):\n",
    "        \n",
    "        self.initial_model = initial_model\n",
    "        self.model_name = model_name\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.architecture = architecture\n",
    "        self.random_global_init = random_global_init\n",
    "        self.global_positional_stride = global_positional_stride\n",
    "        self.keep_first_global_token = keep_first_global_token\n",
    "        self.resize_lsg = resize_lsg\n",
    "        self.model_kwargs = model_kwargs\n",
    "        self.use_token_ids = use_token_ids\n",
    "        self.use_auth_token = use_auth_token\n",
    "        self.config = config\n",
    "        self.save_model = save_model\n",
    "\n",
    "        self.new_config = None\n",
    "\n",
    "    def save(self, model, tokenizer):\n",
    "\n",
    "        model.save_pretrained(self.model_name)\n",
    "        tokenizer.save_pretrained(self.model_name)\n",
    "\n",
    "    def process(self):\n",
    "        \n",
    "        (lsg_architecture, lsg_model), initial_architecture = self.get_architecture()\n",
    "        is_base_architecture, is_lsg, keep_first_global = self.get_additional_params(lsg_architecture, initial_architecture)\n",
    "        model, tokenizer = self.get_model(lsg_architecture, lsg_model)\n",
    "        is_training = model.training\n",
    "        model, tokenizer = self.update_config(model, tokenizer)\n",
    "\n",
    "        # Get the module prefix to update\n",
    "        module_prefix = self.get_module(model, is_base_architecture)\n",
    "\n",
    "        # Update global embedding\n",
    "        if not (is_lsg and self.resize_lsg):\n",
    "            bos_id = tokenizer.bos_token_id if tokenizer.bos_token_id is not None else tokenizer.cls_token_id\n",
    "            bos_id = bos_id if bos_id is not None else model.config.bos_token_id\n",
    "            mask_id = tokenizer.mask_token_id\n",
    "            if self.random_global_init:\n",
    "                self.update_global_randomly(module_prefix, bos_id, self.global_positional_stride, keep_first_global)\n",
    "            else:\n",
    "                self.update_global(module_prefix, bos_id, mask_id, self.global_positional_stride, keep_first_global)\n",
    "\n",
    "        # Update positional\n",
    "        self.update_positions(module_prefix, self.max_sequence_length)\n",
    "\n",
    "        # For Pegasus\n",
    "        self.update_positions_with_model(model, self.max_sequence_length)\n",
    "\n",
    "        if self.save_model:\n",
    "            self.save(model, tokenizer)\n",
    "        \n",
    "        return model.train() if is_training else model.eval(), tokenizer\n",
    "\n",
    "    def get_architecture(self):\n",
    "        if self.architecture is not None:\n",
    "            return self.validate_architecture(self.architecture)\n",
    "\n",
    "        architectures = self.config.architectures\n",
    "        if architectures is not None:\n",
    "            architecture = architectures if isinstance(architectures, str) else architectures[0]\n",
    "            return self.validate_architecture(architecture)\n",
    "\n",
    "        return self.validate_architecture(self._DEFAULT_ARCHITECTURE_TYPE)\n",
    "\n",
    "    def validate_architecture(self, architecture):\n",
    "        _architecture = self._ARCHITECTURE_TYPE_DICT.get(architecture, None)\n",
    "\n",
    "        s = \"\\n * \" + \"\\n * \".join([k for k in self._ARCHITECTURE_TYPE_DICT.keys()])\n",
    "        assert _architecture is not None, f\"Provided/config architecture is wrong, make sure it is in: {s}\"\n",
    "        return _architecture, architecture\n",
    "\n",
    "    def get_model(self, lsg_architecture, lsg_model):\n",
    "        self.new_config = self._CONFIG_MODULE.from_pretrained(\n",
    "            self.initial_model, \n",
    "            architectures=lsg_architecture, \n",
    "            trust_remote_code=True, \n",
    "            use_auth_token=self.use_auth_token,\n",
    "            **json.loads(self.model_kwargs.replace(\"'\", \"\\\"\"))\n",
    "            )\n",
    "        self.new_config.label2id = label2id\n",
    "        self.new_config.id2label = id2label\n",
    "        self.new_config._num_labels = len(label2id)\n",
    "        model = lsg_model.from_pretrained(self.initial_model, use_auth_token=self.use_auth_token, config=self.new_config, trust_remote_code=True, ignore_mismatched_sizes=True)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(self.initial_model, use_auth_token=self.use_auth_token, trust_remote_code=True, truncation=True, padding='max_length', max_length=4096)\n",
    "        return model, tokenizer\n",
    "\n",
    "    def update_config(self, model, tokenizer):\n",
    "\n",
    "        # Update tokenizer and config\n",
    "        tokenizer.model_max_length = self.max_sequence_length\n",
    "        tokenizer.init_kwargs['model_max_length'] = self.max_sequence_length\n",
    "\n",
    "        max_pos = self.max_sequence_length\n",
    "        model.config.max_position_embeddings = max_pos + self._DEFAULT_CONFIG_POSITIONAL_OFFSET\n",
    "        model.config._name_or_path = self.model_name\n",
    "        return model, tokenizer\n",
    "\n",
    "    def get_additional_params(self, _architecture, initial_architecture):\n",
    "\n",
    "        # Hack because of architecture\n",
    "        is_base_architecture = True if _architecture in [self._BASE_ARCHITECTURE_TYPE, \"LSG\" + self._BASE_ARCHITECTURE_TYPE] else False\n",
    "\n",
    "        # Check if it is LSG architecture\n",
    "        if vars(self.config).get(\"base_model_prefix\", None) == \"lsg\" or \"LSG\" in initial_architecture:\n",
    "            is_lsg_architecture = True\n",
    "        else: \n",
    "            is_lsg_architecture = False\n",
    "\n",
    "        if is_lsg_architecture and not self.resize_lsg:\n",
    "            warnings.warn(\"LSG architecture detected, to resize positional embedding only, add --resize_lsg (won't affect global embedding)\")\n",
    "        if is_lsg_architecture and not self.keep_first_global_token and not self.resize_lsg:\n",
    "            warnings.warn(\"LSG architecture detected, to keep the same first global token, add --keep_first_global_token\")\n",
    "\n",
    "        keep_first = False\n",
    "        if self.keep_first_global_token:\n",
    "            if is_lsg_architecture:\n",
    "                keep_first = True\n",
    "            else:\n",
    "                warnings.warn(\"--keep_first_global_token won't be used if the initial model isn't a LSG model\")\n",
    "        return is_base_architecture, is_lsg_architecture, keep_first\n",
    "\n",
    "    def get_module(self, model, is_base_architecture):\n",
    "        if is_base_architecture:\n",
    "            return\n",
    "        return\n",
    "\n",
    "    def update_global_randomly(self, module_prefix, bos_id, stride, keep_first_global):\n",
    "        pass\n",
    "\n",
    "    def update_global(self, module_prefix, bos_id, mask_id, stride, keep_first_global):\n",
    "        pass\n",
    "\n",
    "    def update_positions(self, module_prefix, max_pos):\n",
    "        pass\n",
    "    \n",
    "    def update_positions_with_model(self, model, max_pos):\n",
    "        pass\n",
    "    \n",
    "    def update_buffer(self, module, value):\n",
    "        pass\n",
    "    \n",
    "    def order_positions(self, positions, stride):\n",
    "        n, d = positions.size()\n",
    "        if n % 512 != 0:\n",
    "            if n > 512:\n",
    "                positions = positions[:512*(n//512)]\n",
    "            else:\n",
    "                mean = positions.mean(dim=0, keepdim=True).expand(512 - n, -1)\n",
    "                std = positions.std(dim=0, keepdim=True).expand(512 - n, -1)\n",
    "                positions = torch.cat([positions, torch.normal(mean, std)], dim=0)\n",
    "            n, d = positions.size()\n",
    "\n",
    "        factor = n // 512\n",
    "        positions = positions.reshape(-1, factor, d)[:, 0]\n",
    "        positions = positions.reshape(-1, stride//factor, d).transpose(0, 1).reshape(-1, d)\n",
    "        return positions\n",
    "\n",
    "    def run_test(self):\n",
    "        pass\n",
    "    \n",
    "    def run_models(self, lsg_path, max_length, hidden_size, text, auto_map, gradient_checkpointing=False, is_encoder_decoder=False):\n",
    "\n",
    "        from transformers import AutoTokenizer, AutoConfig, AutoModel, pipeline\n",
    "        from transformers import AutoModelForSequenceClassification, AutoModelForTokenClassification, AutoModelForQuestionAnswering\n",
    "        from transformers import AutoModelForMaskedLM, AutoModelForCausalLM\n",
    "\n",
    "        tokenizer = AutoTokenizer.from_pretrained(lsg_path)\n",
    "        \n",
    "        long_text = text * 200\n",
    "        dtype = torch.bfloat16\n",
    "\n",
    "        for name in auto_map.keys():\n",
    "\n",
    "            if name == \"AutoConfig\":\n",
    "                continue\n",
    "\n",
    "            model = getattr(sys.modules[\"transformers\"], name)\n",
    "            print(\"\\n\\n\" + \"=\"*5 + \" \" + name + \" \" + \"=\"*5 + \"\\n\")\n",
    "            model = model.from_pretrained(lsg_path, trust_remote_code=True, is_decoder=\"Causal\" in name, torch_dtype=dtype).train()\n",
    "            \n",
    "            if gradient_checkpointing:\n",
    "                model.gradient_checkpointing_enable()\n",
    "\n",
    "            if \"QuestionAnswering\" in name:\n",
    "                tokens = tokenizer(\"context\", long_text, return_tensors=\"pt\", truncation=True)\n",
    "                inputs_embeds = torch.randn(1, max_length, hidden_size, dtype=dtype)\n",
    "            elif \"MultipleChoice\" in name:\n",
    "                num_choices = 4\n",
    "                tokens = tokenizer([long_text]*num_choices, return_tensors=\"pt\", truncation=True)\n",
    "                tokens = {k: v.reshape(1, num_choices, -1) for k, v in tokens.items()}\n",
    "                inputs_embeds = torch.randn(1, num_choices, max_length//4, hidden_size, dtype=dtype)\n",
    "            else:\n",
    "                tokens = tokenizer(long_text, return_tensors=\"pt\", truncation=True)\n",
    "                inputs_embeds = torch.randn(1, max_length, hidden_size, dtype=dtype)\n",
    "\n",
    "            if model.config.model_type != \"pegasus\":\n",
    "                model(**tokens)\n",
    "                \n",
    "            if not is_encoder_decoder:\n",
    "                model(inputs_embeds=inputs_embeds)\n",
    "            elif \"decoder_input_ids\" in model.forward.__code__.co_varnames:\n",
    "                decoder_input_ids = tokens.input_ids[:, :256]\n",
    "                if \"SequenceClassification\" not in name:\n",
    "                    model(**tokens, decoder_input_ids=decoder_input_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lsg_converter.bert.modeling_lsg_bert import *\n",
    "try:\n",
    "    from lsg_converter.conversion_utils import ConversionScript\n",
    "except:\n",
    "    from conversion_utils import ConversionScript\n",
    "\n",
    "class MyBertConversionScript(MyConversionScript):\n",
    "\n",
    "    _ARCHITECTURE_TYPE_DICT = {\n",
    "        \"BertModel\": (\"LSGBertModel\", LSGBertModel),\n",
    "        \"BertForMaskedLM\": (\"LSGBertForMaskedLM\", LSGBertForMaskedLM),\n",
    "        \"BertForPreTraining\": (\"LSGBertForPreTraining\", LSGBertForPreTraining),\n",
    "        \"BertLMHeadModel\": (\"LSGBertLMHeadModel\", LSGBertLMHeadModel),\n",
    "        \"BertForMultipleChoice\": (\"LSGBertForMultipleChoice\", LSGBertForMultipleChoice),\n",
    "        \"BertForQuestionAnswering\": (\"LSGBertForQuestionAnswering\", LSGBertForQuestionAnswering),\n",
    "        \"BertForSequenceClassification\": (\"LSGBertForSequenceClassification\", LSGBertForSequenceClassification),\n",
    "        \"BertForTokenClassification\": (\"LSGBertForTokenClassification\", LSGBertForTokenClassification)\n",
    "    }\n",
    "    _ARCHITECTURE_TYPE_DICT = {**{\"LSG\" + k: v for k, v in _ARCHITECTURE_TYPE_DICT.items()}, **_ARCHITECTURE_TYPE_DICT}\n",
    "\n",
    "    _BASE_ARCHITECTURE_TYPE = \"BertModel\"\n",
    "    _DEFAULT_ARCHITECTURE_TYPE = \"BertForPreTraining\"\n",
    "    _CONFIG_MODULE = LSGBertConfig\n",
    "\n",
    "    _DEFAULT_CONFIG_POSITIONAL_OFFSET = 0\n",
    "    _DEFAULT_POSITIONAL_OFFSET = 0\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def get_module(self, model, is_base_architecture):\n",
    "        if is_base_architecture:\n",
    "            return model\n",
    "        return model.bert\n",
    "\n",
    "    def update_global_randomly(self, module_prefix, bos_id, stride, keep_first_global):\n",
    "\n",
    "        import torch\n",
    "        from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "\n",
    "        u = module_prefix.embeddings.word_embeddings.weight.clone()\n",
    "\n",
    "        cov = torch.cov(u.T)\n",
    "        m = MultivariateNormal(u.mean(dim=0), cov)\n",
    "        w = m.sample((512,))\n",
    "        w[0] = u[bos_id]\n",
    "\n",
    "        positions = module_prefix.embeddings.position_embeddings.weight.clone()\n",
    "        positions = self.order_positions(positions, stride)\n",
    "\n",
    "        if self.use_token_ids:\n",
    "            token_ids = module_prefix.embeddings.token_type_embeddings.weight.clone()\n",
    "            positions += token_ids[0].unsqueeze(0)\n",
    "            w[0] = u[bos_id] + token_ids[0]\n",
    "\n",
    "        if keep_first_global:\n",
    "            module_prefix.embeddings.global_embeddings.weight.data[1:] = (w + positions)[1:]\n",
    "        else:\n",
    "            module_prefix.embeddings.global_embeddings.weight.data = w + positions\n",
    "\n",
    "    def update_global(self, module_prefix, bos_id, mask_id, stride, keep_first_global):\n",
    "\n",
    "        u = module_prefix.embeddings.word_embeddings.weight.clone()\n",
    "        positions = module_prefix.embeddings.position_embeddings.weight.clone()\n",
    "        positions = self.order_positions(positions, stride)\n",
    "\n",
    "        positions[0] += u[bos_id]\n",
    "        positions[1:] += u[mask_id].unsqueeze(0)\n",
    "\n",
    "        if self.use_token_ids:\n",
    "            token_ids = module_prefix.embeddings.token_type_embeddings.weight.clone()\n",
    "            positions += token_ids[0].unsqueeze(0)\n",
    "\n",
    "        if keep_first_global:\n",
    "            module_prefix.embeddings.global_embeddings.weight.data[1:] = positions[1:]\n",
    "        else:\n",
    "            module_prefix.embeddings.global_embeddings.weight.data = positions\n",
    "        \n",
    "    def update_positions(self, module_prefix, max_pos):\n",
    "\n",
    "        position_embeddings_weights = module_prefix.embeddings.position_embeddings.weight.clone()\n",
    "        current_max_position = position_embeddings_weights.size()[0]\n",
    "\n",
    "        new_position_embeddings_weights = torch.cat([\n",
    "            position_embeddings_weights for _ in range(max_pos//current_max_position + 1)\n",
    "            ], dim=0)[:max_pos + self._DEFAULT_POSITIONAL_OFFSET]\n",
    "\n",
    "        module_prefix.embeddings.position_embeddings = nn.Embedding(\n",
    "            *new_position_embeddings_weights.size(), \n",
    "            _weight=new_position_embeddings_weights,\n",
    "            dtype=new_position_embeddings_weights.dtype\n",
    "            )\n",
    "        self.update_buffer(module_prefix.embeddings, max_pos + self._DEFAULT_POSITIONAL_OFFSET)\n",
    "        \n",
    "    def update_buffer(self, module, value):\n",
    "        \n",
    "        # Update buffer dogshit\n",
    "        module.register_buffer(\n",
    "            \"position_ids\", torch.arange(value).expand((1, -1)), persistent=False\n",
    "        )\n",
    "        module.register_buffer(\n",
    "            \"token_type_ids\", torch.zeros(module.position_ids.size(), dtype=torch.long), persistent=False\n",
    "        )\n",
    "        \n",
    "    def run_test(self):\n",
    "        \n",
    "        from transformers import AutoConfig, AutoTokenizer\n",
    "\n",
    "        initial_path = self.initial_model\n",
    "        lsg_path = self.model_name\n",
    "\n",
    "        config = AutoConfig.from_pretrained(lsg_path, trust_remote_code=True)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(lsg_path)\n",
    "        text = f\"Paris is the {tokenizer.mask_token} of France.\"\n",
    "\n",
    "        max_length = config.max_position_embeddings - 20\n",
    "        hidden_size = config.hidden_size\n",
    "\n",
    "        self.run_models(lsg_path, max_length, hidden_size, text, AUTO_MAP)\n",
    "        self.run_pipeline(lsg_path, initial_path, tokenizer, text)\n",
    "\n",
    "    def run_pipeline(self, lsg_path, initial_path, tokenizer, text):\n",
    "\n",
    "        from transformers import AutoModelForMaskedLM, pipeline\n",
    "\n",
    "        model = AutoModelForMaskedLM.from_pretrained(lsg_path, trust_remote_code=True)\n",
    "        pipe = pipeline(\"fill-mask\", model=model, tokenizer=tokenizer)\n",
    "        pipe_lsg = pipe(text)\n",
    "\n",
    "        model = AutoModelForMaskedLM.from_pretrained(initial_path, trust_remote_code=True)\n",
    "        pipe = pipeline(\"fill-mask\", model=model, tokenizer=tokenizer)\n",
    "        pipe_initial = pipe(text)\n",
    "  \n",
    "        print(\"\\n\\n\" + \"=\"*5 + \" LSG PIPELINE \" + \"=\"*5 + \"\\n\")\n",
    "        print(text)\n",
    "        print(pipe_lsg[0])\n",
    "        print(\"\\n\\n\" + \"=\"*5 + \" INITIAL PIPELINE \" + \"=\"*5 + \"\\n\")\n",
    "        print(text)\n",
    "        print(pipe_initial[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig\n",
    "from transformers.models.auto.modeling_auto import *\n",
    "import json\n",
    "\n",
    "from lsg_converter.albert.convert_albert_checkpoint import *\n",
    "from lsg_converter.bart.convert_bart_checkpoint import *\n",
    "from lsg_converter.barthez.convert_barthez_checkpoint import *\n",
    "from lsg_converter.bert.convert_bert_checkpoint import *\n",
    "from lsg_converter.camembert.convert_camembert_checkpoint import *\n",
    "from lsg_converter.distilbert.convert_distilbert_checkpoint import *\n",
    "from lsg_converter.electra.convert_electra_checkpoint import *\n",
    "from lsg_converter.mbart.convert_mbart_checkpoint import *\n",
    "from lsg_converter.pegasus.convert_pegasus_checkpoint import *\n",
    "from lsg_converter.roberta.convert_roberta_checkpoint import *\n",
    "from lsg_converter.xlm_roberta.convert_xlm_roberta_checkpoint import *\n",
    "\n",
    "_AUTH_MODELS = {\n",
    "    \"albert\": AlbertConversionScript,\n",
    "    \"bart\": BartConversionScript,\n",
    "    \"barthez\": BarthezConversionScript,\n",
    "    \"bert\": MyBertConversionScript,\n",
    "    \"camembert\": CamembertConversionScript,\n",
    "    \"distilbert\": DistilBertConversionScript,\n",
    "    \"electra\": ElectraConversionScript,\n",
    "    \"mbart\": MBartConversionScript,\n",
    "    \"pegasus\": PegasusConversionScript,\n",
    "    \"roberta\": RobertaConversionScript,\n",
    "    \"xlm-roberta\": XLMRobertaConversionScript,\n",
    "}\n",
    "\n",
    "class MYLSGConverter():\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        max_sequence_length=4096, \n",
    "        random_global_init=False, \n",
    "        global_positional_stride=64, \n",
    "        keep_first_global_token=False, \n",
    "        resize_lsg=False, \n",
    "        use_token_ids=True, \n",
    "        seed=123\n",
    "        ):\n",
    "        \"\"\"\n",
    "        max_sequence_length (int): new max sequence length\n",
    "        random_global_init (bool): randomly initialize global tokens\n",
    "        global_positional_stride (int): position stride between global tokens\n",
    "        keep_first_global_token (bool): keep or replace the first global token (<s> + pos 0)\n",
    "        resize_lsg (bool): only resize an existing LSG model\n",
    "        use_token_ids (bool): use token_type_ids to build global tokens\n",
    "        seed (int): seed\n",
    "        \"\"\"\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.random_global_init = random_global_init\n",
    "        self.global_positional_stride = global_positional_stride\n",
    "        self.keep_first_global_token = keep_first_global_token\n",
    "        self.resize_lsg = resize_lsg\n",
    "        self.use_token_ids = use_token_ids\n",
    "        self.seed = seed\n",
    "\n",
    "    def convert_from_pretrained(\n",
    "        self, \n",
    "        model_name_or_path, \n",
    "        architecture=None, \n",
    "        use_auth_token=False,\n",
    "        **model_kwargs\n",
    "        ):\n",
    "        \"\"\"\n",
    "        mode_name_or_path (str): path to the model to convert\n",
    "        architecture (str): specific architecture (optional)\n",
    "        model_kwargs: additional model args\n",
    "        \"\"\"\n",
    "\n",
    "        config = AutoConfig.from_pretrained(model_name_or_path, trust_remote_code=True, use_auth_token=use_auth_token)\n",
    "        config.label2id = label2id\n",
    "        config.id2label = id2label\n",
    "        config._num_labels = len(label2id)\n",
    "        \n",
    "        model_type = config.model_type\n",
    "        model_kwargs = json.dumps(model_kwargs, indent=4)\n",
    "\n",
    "        if model_type in _AUTH_MODELS.keys():\n",
    "            converter = _AUTH_MODELS[model_type](\n",
    "                initial_model=model_name_or_path, \n",
    "                model_name=model_name_or_path, \n",
    "                max_sequence_length=self.max_sequence_length, \n",
    "                architecture=architecture, \n",
    "                random_global_init=self.random_global_init, \n",
    "                global_positional_stride=self.global_positional_stride, \n",
    "                keep_first_global_token=self.keep_first_global_token, \n",
    "                resize_lsg=self.resize_lsg, \n",
    "                model_kwargs=model_kwargs, \n",
    "                use_token_ids=self.use_token_ids,\n",
    "                use_auth_token=use_auth_token,\n",
    "                config=config,\n",
    "                save_model=False,\n",
    "                seed=self.seed\n",
    "            )\n",
    "            \n",
    "            return converter.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T04:47:57.642462Z",
     "start_time": "2024-04-11T04:47:47.647865Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:145: UserWarning: LSG architecture detected, to resize positional embedding only, add --resize_lsg (won't affect global embedding)\n",
      "/data/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:147: UserWarning: LSG architecture detected, to keep the same first global token, add --keep_first_global_token\n",
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n",
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n",
      "Some weights of LSGBertForTokenClassification were not initialized from the model checkpoint at ai-forever/ruBert-base and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([2]) in the checkpoint and torch.Size([59]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([59, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'lsg_converter.bert.modeling_lsg_bert.LSGBertForTokenClassification'>\n"
     ]
    }
   ],
   "source": [
    "converter = MYLSGConverter(max_sequence_length=4096)\n",
    "\n",
    "# Example 1\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "model, tokenizer = converter.convert_from_pretrained(model_checkpoint, architecture=\"BertForTokenClassification\")\n",
    "print(type(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSGBertForTokenClassification(\n",
       "  (bert): LSGBertModel(\n",
       "    (embeddings): LSGBertEmbeddings(\n",
       "      (word_embeddings): Embedding(120138, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(4096, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (global_embeddings): Embedding(512, 768)\n",
       "    )\n",
       "    (encoder): LSGBertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): LSGBertLayer(\n",
       "          (attention): LSGAttention(\n",
       "            (self): LSGSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (attention): LSGAttentionProduct(\n",
       "                (attention): BaseAttentionProduct(\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (full_attention): BaseAttentionProduct(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): LSGBertLayer(\n",
       "          (attention): LSGAttention(\n",
       "            (self): LSGSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (attention): LSGAttentionProduct(\n",
       "                (attention): BaseAttentionProduct(\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (full_attention): BaseAttentionProduct(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): LSGBertLayer(\n",
       "          (attention): LSGAttention(\n",
       "            (self): LSGSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (attention): LSGAttentionProduct(\n",
       "                (attention): BaseAttentionProduct(\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (full_attention): BaseAttentionProduct(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): LSGBertLayer(\n",
       "          (attention): LSGAttention(\n",
       "            (self): LSGSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (attention): LSGAttentionProduct(\n",
       "                (attention): BaseAttentionProduct(\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (full_attention): BaseAttentionProduct(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): LSGBertLayer(\n",
       "          (attention): LSGAttention(\n",
       "            (self): LSGSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (attention): LSGAttentionProduct(\n",
       "                (attention): BaseAttentionProduct(\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (full_attention): BaseAttentionProduct(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): LSGBertLayer(\n",
       "          (attention): LSGAttention(\n",
       "            (self): LSGSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (attention): LSGAttentionProduct(\n",
       "                (attention): BaseAttentionProduct(\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (full_attention): BaseAttentionProduct(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): LSGBertLayer(\n",
       "          (attention): LSGAttention(\n",
       "            (self): LSGSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (attention): LSGAttentionProduct(\n",
       "                (attention): BaseAttentionProduct(\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (full_attention): BaseAttentionProduct(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): LSGBertLayer(\n",
       "          (attention): LSGAttention(\n",
       "            (self): LSGSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (attention): LSGAttentionProduct(\n",
       "                (attention): BaseAttentionProduct(\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (full_attention): BaseAttentionProduct(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): LSGBertLayer(\n",
       "          (attention): LSGAttention(\n",
       "            (self): LSGSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (attention): LSGAttentionProduct(\n",
       "                (attention): BaseAttentionProduct(\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (full_attention): BaseAttentionProduct(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): LSGBertLayer(\n",
       "          (attention): LSGAttention(\n",
       "            (self): LSGSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (attention): LSGAttentionProduct(\n",
       "                (attention): BaseAttentionProduct(\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (full_attention): BaseAttentionProduct(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): LSGBertLayer(\n",
       "          (attention): LSGAttention(\n",
       "            (self): LSGSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (attention): LSGAttentionProduct(\n",
       "                (attention): BaseAttentionProduct(\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (full_attention): BaseAttentionProduct(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): LSGBertLayer(\n",
       "          (attention): LSGAttention(\n",
       "            (self): LSGSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (attention): LSGAttentionProduct(\n",
       "                (attention): BaseAttentionProduct(\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (full_attention): BaseAttentionProduct(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=59, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/nikolay.stepanov/NN/notebooks/test.hf/train/cache-cc69b956e346203f.arrow\n",
      "Loading cached processed dataset at /home/nikolay.stepanov/NN/notebooks/test.hf/test/cache-698f2b76369d0d48.arrow\n",
      "Loading cached processed dataset at /home/nikolay.stepanov/NN/notebooks/test.hf/dev/cache-6edf93fb47ab6769.arrow\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = datasets.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForTokenClassification, AutoConfig, TrainingArguments, Trainer\n",
    "\n",
    "id2label = {y: x for x, y in label2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [p for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [l for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    \n",
    "    m = MultiLabelBinarizer().fit(true_labels)\n",
    "\n",
    "    return {\n",
    "        \"f1\": f1_score(m.transform(true_predictions), m.transform(true_labels), average='macro'),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "\n",
    "args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-{task}\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=50,\n",
    "    weight_decay=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T16:14:14.583344Z",
     "start_time": "2024-04-10T16:14:13.246649Z"
    },
    "id": "imY1oC3SIrJf"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |  707281 KB |  707281 KB |  707281 KB |       0 B  |\n",
      "|       from large pool |  706560 KB |  706560 KB |  706560 KB |       0 B  |\n",
      "|       from small pool |     721 KB |     721 KB |     721 KB |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |  707281 KB |  707281 KB |  707281 KB |       0 B  |\n",
      "|       from large pool |  706560 KB |  706560 KB |  706560 KB |       0 B  |\n",
      "|       from small pool |     721 KB |     721 KB |     721 KB |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |  743424 KB |  743424 KB |  743424 KB |       0 B  |\n",
      "|       from large pool |  741376 KB |  741376 KB |  741376 KB |       0 B  |\n",
      "|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |   36142 KB |   48430 KB |  247034 KB |  210891 KB |\n",
      "|       from large pool |   34816 KB |   46848 KB |  244992 KB |  210176 KB |\n",
      "|       from small pool |    1326 KB |    2042 KB |    2042 KB |     715 KB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |     202    |     202    |     202    |       0    |\n",
      "|       from large pool |      75    |      75    |      75    |       0    |\n",
      "|       from small pool |     127    |     127    |     127    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |     202    |     202    |     202    |       0    |\n",
      "|       from large pool |      75    |      75    |      75    |       0    |\n",
      "|       from small pool |     127    |     127    |     127    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |      21    |      21    |      21    |       0    |\n",
      "|       from large pool |      20    |      20    |      20    |       0    |\n",
      "|       from small pool |       1    |       1    |       1    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |      18    |      18    |      19    |       1    |\n",
      "|       from large pool |      17    |      17    |      18    |       1    |\n",
      "|       from small pool |       1    |       1    |       1    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "print(torch.cuda.memory_summary(device=0, abbreviated=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_CudaDeviceProperties(name='NVIDIA A100-PCIE-40GB', major=8, minor=0, total_memory=40377MB, multi_processor_count=108)\n",
      "_CudaDeviceProperties(name='NVIDIA A100-PCIE-40GB', major=8, minor=0, total_memory=40377MB, multi_processor_count=108)\n",
      "_CudaDeviceProperties(name='NVIDIA A100-PCIE-40GB', major=8, minor=0, total_memory=40377MB, multi_processor_count=108)\n",
      "_CudaDeviceProperties(name='NVIDIA A100-PCIE-40GB', major=8, minor=0, total_memory=40377MB, multi_processor_count=108)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "for i in range(torch.cuda.device_count()):\n",
    "   print(torch.cuda.get_device_properties(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CdzABDVcIrJg"
   },
   "source": [
    "We can now finetune our model by just calling the `train` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-10T16:14:16.462589Z"
    },
    "id": "sxTtB9CIYoUw",
    "jupyter": {
     "is_executing": true
    },
    "outputId": "f3f3d138-c5d7-4275-8533-5eeef7bb4286",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikolay.stepanov/.local/lib/python3.7/site-packages/transformers/optimization.py:415: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "/usr/lib/spark/python/lib/py4j-current-src.zip/py4j/java_gateway.py:2020: DeprecationWarning: invalid escape sequence \\*\n",
      "/usr/lib/spark/python/lib/py4j-current-src.zip/py4j/java_gateway.py:2020: DeprecationWarning: invalid escape sequence \\*\n",
      "/usr/lib/spark/python/lib/py4j-current-src.zip/py4j/java_collections.py:13: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "/usr/lib/spark/python/pyspark/resultiterable.py:23: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  class ResultIterable(collections.Iterable):\n",
      "Trainer is attempting to log a value of \"{0: 'O', 1: 'B-AGE', 2: 'I-AGE', 3: 'B-AWARD', 4: 'I-AWARD', 5: 'B-CITY', 6: 'I-CITY', 7: 'B-COUNTRY', 8: 'I-COUNTRY', 9: 'B-CRIME', 10: 'I-CRIME', 11: 'B-DATE', 12: 'I-DATE', 13: 'B-DISEASE', 14: 'I-DISEASE', 15: 'B-DISTRICT', 16: 'I-DISTRICT', 17: 'B-EVENT', 18: 'I-EVENT', 19: 'B-FACILITY', 20: 'I-FACILITY', 21: 'B-FAMILY', 22: 'I-FAMILY', 23: 'B-IDEOLOGY', 24: 'I-IDEOLOGY', 25: 'B-LANGUAGE', 26: 'I-LANGUAGE', 27: 'B-LAW', 28: 'I-LAW', 29: 'B-LOCATION', 30: 'I-LOCATION', 31: 'B-MONEY', 32: 'I-MONEY', 33: 'B-NATIONALITY', 34: 'I-NATIONALITY', 35: 'B-NUMBER', 36: 'I-NUMBER', 37: 'B-ORDINAL', 38: 'I-ORDINAL', 39: 'B-ORGANIZATION', 40: 'I-ORGANIZATION', 41: 'B-PENALTY', 42: 'I-PENALTY', 43: 'B-PERCENT', 44: 'I-PERCENT', 45: 'B-PERSON', 46: 'I-PERSON', 47: 'B-PRODUCT', 48: 'I-PRODUCT', 49: 'B-PROFESSION', 50: 'I-PROFESSION', 51: 'B-RELIGION', 52: 'I-RELIGION', 53: 'B-STATE_OR_PROVINCE', 54: 'I-STATE_OR_PROVINCE', 55: 'B-TIME', 56: 'I-TIME', 57: 'B-WORK_OF_ART', 58: 'I-WORK_OF_ART'}\" for key \"id2label\" as a parameter. MLflow's log_param() only accepts values no longer than 250 characters so we dropped this attribute. You can use `MLFLOW_FLATTEN_PARAMS` environment variable to flatten the parameters and avoid this message.\n",
      "Trainer is attempting to log a value of \"{'O': 0, 'B-AGE': 1, 'I-AGE': 2, 'B-AWARD': 3, 'I-AWARD': 4, 'B-CITY': 5, 'I-CITY': 6, 'B-COUNTRY': 7, 'I-COUNTRY': 8, 'B-CRIME': 9, 'I-CRIME': 10, 'B-DATE': 11, 'I-DATE': 12, 'B-DISEASE': 13, 'I-DISEASE': 14, 'B-DISTRICT': 15, 'I-DISTRICT': 16, 'B-EVENT': 17, 'I-EVENT': 18, 'B-FACILITY': 19, 'I-FACILITY': 20, 'B-FAMILY': 21, 'I-FAMILY': 22, 'B-IDEOLOGY': 23, 'I-IDEOLOGY': 24, 'B-LANGUAGE': 25, 'I-LANGUAGE': 26, 'B-LAW': 27, 'I-LAW': 28, 'B-LOCATION': 29, 'I-LOCATION': 30, 'B-MONEY': 31, 'I-MONEY': 32, 'B-NATIONALITY': 33, 'I-NATIONALITY': 34, 'B-NUMBER': 35, 'I-NUMBER': 36, 'B-ORDINAL': 37, 'I-ORDINAL': 38, 'B-ORGANIZATION': 39, 'I-ORGANIZATION': 40, 'B-PENALTY': 41, 'I-PENALTY': 42, 'B-PERCENT': 43, 'I-PERCENT': 44, 'B-PERSON': 45, 'I-PERSON': 46, 'B-PRODUCT': 47, 'I-PRODUCT': 48, 'B-PROFESSION': 49, 'I-PROFESSION': 50, 'B-RELIGION': 51, 'I-RELIGION': 52, 'B-STATE_OR_PROVINCE': 53, 'I-STATE_OR_PROVINCE': 54, 'B-TIME': 55, 'I-TIME': 56, 'B-WORK_OF_ART': 57, 'I-WORK_OF_ART': 58}\" for key \"label2id\" as a parameter. MLflow's log_param() only accepts values no longer than 250 characters so we dropped this attribute. You can use `MLFLOW_FLATTEN_PARAMS` environment variable to flatten the parameters and avoid this message.\n",
      "Trainer is attempting to log a value of \"{'AutoModel': 'modeling_lsg_bert.LSGBertModel', 'AutoModelForCausalLM': 'modeling_lsg_bert.LSGBertLMHeadModel', 'AutoModelForMaskedLM': 'modeling_lsg_bert.LSGBertForMaskedLM', 'AutoModelForPreTraining': 'modeling_lsg_bert.LSGBertForPreTraining', 'AutoModelForMultipleChoice': 'modeling_lsg_bert.LSGBertForMultipleChoice', 'AutoModelForQuestionAnswering': 'modeling_lsg_bert.LSGBertForQuestionAnswering', 'AutoModelForSequenceClassification': 'modeling_lsg_bert.LSGBertForSequenceClassification', 'AutoModelForTokenClassification': 'modeling_lsg_bert.LSGBertForTokenClassification'}\" for key \"auto_map\" as a parameter. MLflow's log_param() only accepts values no longer than 250 characters so we dropped this attribute. You can use `MLFLOW_FLATTEN_PARAMS` environment variable to flatten the parameters and avoid this message.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/home/nikolay.stepanov/.local/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2350' max='2350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2350/2350 23:22, Epoch 50/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.452055</td>\n",
       "      <td>0.149778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.914883</td>\n",
       "      <td>0.283168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.690394</td>\n",
       "      <td>0.417824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.555187</td>\n",
       "      <td>0.537424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.477309</td>\n",
       "      <td>0.579699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.427146</td>\n",
       "      <td>0.622090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.397888</td>\n",
       "      <td>0.685415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.378975</td>\n",
       "      <td>0.716707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.367653</td>\n",
       "      <td>0.759636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.367255</td>\n",
       "      <td>0.789237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.605600</td>\n",
       "      <td>0.384461</td>\n",
       "      <td>0.793594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.605600</td>\n",
       "      <td>0.369049</td>\n",
       "      <td>0.812342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.605600</td>\n",
       "      <td>0.371134</td>\n",
       "      <td>0.820356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.605600</td>\n",
       "      <td>0.383269</td>\n",
       "      <td>0.813446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.605600</td>\n",
       "      <td>0.383518</td>\n",
       "      <td>0.817702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.605600</td>\n",
       "      <td>0.392937</td>\n",
       "      <td>0.826177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.605600</td>\n",
       "      <td>0.392639</td>\n",
       "      <td>0.829354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.605600</td>\n",
       "      <td>0.393852</td>\n",
       "      <td>0.834256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.605600</td>\n",
       "      <td>0.396573</td>\n",
       "      <td>0.831515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.605600</td>\n",
       "      <td>0.407212</td>\n",
       "      <td>0.831655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.605600</td>\n",
       "      <td>0.402104</td>\n",
       "      <td>0.825772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.074400</td>\n",
       "      <td>0.415260</td>\n",
       "      <td>0.828506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.074400</td>\n",
       "      <td>0.420009</td>\n",
       "      <td>0.835534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.074400</td>\n",
       "      <td>0.420720</td>\n",
       "      <td>0.830628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.074400</td>\n",
       "      <td>0.432074</td>\n",
       "      <td>0.830749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.074400</td>\n",
       "      <td>0.429449</td>\n",
       "      <td>0.832928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.074400</td>\n",
       "      <td>0.427024</td>\n",
       "      <td>0.839831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.074400</td>\n",
       "      <td>0.438582</td>\n",
       "      <td>0.843455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.074400</td>\n",
       "      <td>0.440052</td>\n",
       "      <td>0.842195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.074400</td>\n",
       "      <td>0.444128</td>\n",
       "      <td>0.831971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.074400</td>\n",
       "      <td>0.440773</td>\n",
       "      <td>0.833016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.029800</td>\n",
       "      <td>0.444867</td>\n",
       "      <td>0.833097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.029800</td>\n",
       "      <td>0.444993</td>\n",
       "      <td>0.843012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.029800</td>\n",
       "      <td>0.449775</td>\n",
       "      <td>0.839597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.029800</td>\n",
       "      <td>0.450337</td>\n",
       "      <td>0.840720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.029800</td>\n",
       "      <td>0.458812</td>\n",
       "      <td>0.845123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.029800</td>\n",
       "      <td>0.460380</td>\n",
       "      <td>0.843946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.029800</td>\n",
       "      <td>0.461855</td>\n",
       "      <td>0.840001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.029800</td>\n",
       "      <td>0.463702</td>\n",
       "      <td>0.848999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.029800</td>\n",
       "      <td>0.461575</td>\n",
       "      <td>0.837582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.029800</td>\n",
       "      <td>0.460290</td>\n",
       "      <td>0.849077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.029800</td>\n",
       "      <td>0.461371</td>\n",
       "      <td>0.847133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.018200</td>\n",
       "      <td>0.464769</td>\n",
       "      <td>0.845655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.018200</td>\n",
       "      <td>0.465843</td>\n",
       "      <td>0.841935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.018200</td>\n",
       "      <td>0.462608</td>\n",
       "      <td>0.845100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.018200</td>\n",
       "      <td>0.464132</td>\n",
       "      <td>0.845371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.018200</td>\n",
       "      <td>0.465718</td>\n",
       "      <td>0.845648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.018200</td>\n",
       "      <td>0.466316</td>\n",
       "      <td>0.845350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.018200</td>\n",
       "      <td>0.466001</td>\n",
       "      <td>0.845076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.018200</td>\n",
       "      <td>0.465534</td>\n",
       "      <td>0.846385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/nikolay.stepanov/.local/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/data/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/nikolay.stepanov/.local/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/data/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/nikolay.stepanov/.local/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/data/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/nikolay.stepanov/.local/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/data/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2350, training_loss=0.15710342143444306, metrics={'train_runtime': 1416.0792, 'train_samples_per_second': 26.34, 'train_steps_per_second': 1.66, 'total_flos': 1.5291973944339396e+16, 'train_loss': 0.15710342143444306, 'epoch': 50.0})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "# train_dataloader = DataLoader(tokenized_datasets[\"train\"], shuffle=True, batch_size=8, collate_fn=data_collator)\n",
    "# eval_dataloader = DataLoader(tokenized_datasets[\"test\"], batch_size=8, collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.optim import AdamW\n",
    "\n",
    "# optimizer = AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import get_scheduler\n",
    "\n",
    "# num_epochs = 3\n",
    "# num_training_steps = num_epochs * len(train_dataloader)\n",
    "# lr_scheduler = get_scheduler(\n",
    "#     name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# print(device)\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm.auto import tqdm\n",
    "\n",
    "# progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "# model.train()\n",
    "# for epoch in range(num_epochs):\n",
    "#     for batch in train_dataloader:\n",
    "#         batch = {k: v.to(device) for k, v in batch.items()}\n",
    "#         outputs = model(**batch)\n",
    "#         loss = outputs.loss\n",
    "#         loss.backward()\n",
    "\n",
    "#         optimizer.step()\n",
    "#         lr_scheduler.step()\n",
    "#         optimizer.zero_grad()\n",
    "#         progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CKASz-2vIrJi"
   },
   "source": [
    "The `evaluate` method allows you to evaluate again on the evaluation dataset or on another dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "UOUcBkX8IrJi",
    "outputId": "de5b9dd6-9dc0-4702-cb43-55e9829fde25"
   },
   "outputs": [],
   "source": [
    "# trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xV_q3s1tYoUw"
   },
   "source": [
    "To get the precision/recall/f1 computed for each category now that we have finished training, we can apply the same function as before on the result of the `predict` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "lLltoXusYoUw",
    "outputId": "208bd802-bdf7-4729-e362-9958eb34704d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'f1': 0.863608568223612}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions, labels, _ = trainer.predict(tokenized_datasets[\"dev\"])\n",
    "predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "# Remove ignored index (special tokens)\n",
    "true_predictions = [\n",
    "   [p for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "true_labels = [\n",
    "    [l for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "\n",
    "m = MultiLabelBinarizer().fit(true_labels)\n",
    "\n",
    "results = {\n",
    "    \"f1\": f1_score(m.transform(true_predictions), m.transform(true_labels), average='macro'),\n",
    "}\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(f'my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:145: UserWarning: LSG architecture detected, to resize positional embedding only, add --resize_lsg (won't affect global embedding)\n",
      "/data/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:147: UserWarning: LSG architecture detected, to keep the same first global token, add --keep_first_global_token\n",
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n",
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'lsg_converter.bert.modeling_lsg_bert.LSGBertForTokenClassification'>\n"
     ]
    }
   ],
   "source": [
    "converter = MYLSGConverter(max_sequence_length=4096)\n",
    "\n",
    "train_model, train_tokenizer = converter.convert_from_pretrained('my_model', architecture=\"BertForTokenClassification\")\n",
    "print(type(train_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "\n",
    "args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-{task}\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=50,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    train_model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=train_tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'text': '–°–µ–º—å—è –û–±–∞–º—ã –ø—Ä–∏–æ–±—Ä–µ–ª–∞ –¥–æ–º –≤ –í–∞—à–∏–Ω–≥—Ç–æ–Ω–µ –∑–∞ 8,1 –º–ª–Ω –¥–æ–ª–ª–∞—Ä–æ–≤\\n\\n–ë–∞—Ä–∞–∫ –û–±–∞–º–∞\\n–ë—ã–≤—à–∏–π –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç –°–®–ê –ë–∞—Ä–∞–∫ –û–±–∞–º–∞ —Å –∂–µ–Ω–æ–π –ú–∏—à–µ–ª—å –ø—Ä–∏–æ–±—Ä–µ–ª–∏ –∂–∏–ª—å—ë –≤ –í–∞—à–∏–Ω–≥—Ç–æ–Ω–µ –Ω–µ–¥–∞–ª–µ–∫–æ –æ—Ç –ë–µ–ª–æ–≥–æ –¥–æ–º–∞.\\n\\n–ü–æ—Å–ª–µ –æ–∫–æ–Ω—á–∞–Ω–∏—è —Å—Ä–æ–∫–∞ —Ä–∞–±–æ—Ç—ã –Ω–∞ –ø–æ—Å—Ç—É –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç–∞ –≤ —è–Ω–≤–∞—Ä–µ —Å—É–ø—Ä—É–≥–∏ –∞—Ä–µ–Ω–¥–æ–≤–∞–ª–∏ –æ—Å–æ–±–Ω—è–∫ –≤ —Å—Ç–∏–ª–µ —ç–ø–æ—Ö–∏ –¢—é–¥–æ—Ä–æ–≤ –≤ –ø—Ä–µ—Å—Ç–∏–∂–Ω–æ–º —Ä–∞–π–æ–Ω–µ —Å—Ç–æ–ª–∏—Ü—ã –°–®–ê ‚Äî –ö–∞–ª–æ—Ä–∞–º–∞, –≥–¥–µ –¥–æ–ª–≥–æ–µ –≤—Ä–µ–º—è —Å–µ–ª–∏–ª–∏—Å—å –¥–∏–ø–ª–æ–º–∞—Ç—ã, –ª–æ–±–±–∏—Å—Ç—ã –∏ –ø–æ–ª–∏—Ç–∏–∫–∏.\\n\\n–ú–ª–∞–¥—à–µ–π –¥–æ—á–µ—Ä–∏ –ë–∞—Ä–∞–∫–∞ –∏ –ú–∏—à–µ–ª—å ‚Äî –°–∞—à–µ –æ—Å—Ç–∞–ª–æ—Å—å –µ—â—ë –¥–≤–∞ –≥–æ–¥–∞ –¥–æ –æ–∫–æ–Ω—á–∞–Ω–∏—è —á–∞—Å—Ç–Ω–æ–π —à–∫–æ–ª—ã –≤ –í–∞—à–∏–Ω–≥—Ç–æ–Ω–µ. –ü–æ—ç—Ç–æ–º—É —Å–µ–º—å—è —Ä–µ—à–∏–ª–∞ –≤—ã–∫—É–ø–∏—Ç—å –¥–æ–º —Å –≤–æ—Å–µ–º—å—é —Å–ø–∞–ª—å–Ω—ã–º–∏ –∫–æ–º–Ω–∞—Ç–∞–º–∏ —Å—Ç–æ–∏–º–æ—Å—Ç—å—é 8,1 –º–∏–ª–ª–∏–æ–Ω–∞ –¥–æ–ª–ª–∞—Ä–æ–≤.\\n\\n–†–∞–Ω–µ–µ –¥–æ–º –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∞–ª –±—ã–≤—à–µ–º—É –ø—Ä–µ—Å—Å-—Å–µ–∫—Ä–µ—Ç–∞—Ä—é —ç–∫—Å-–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç–∞ –°–®–ê –ë–∏–ª–ª–∞ –ö–ª–∏–Ω—Ç–æ–Ω–∞ –î–∂–æ –õ–æ–∫—Ö–∞—Ä—Ç—É (), –∫–æ—Ç–æ—Ä—ã–π –≤ –Ω–∞—Å—Ç–æ—è—â–µ–µ –≤—Ä–µ–º—è –≤–æ–∑–≥–ª–∞–≤–ª—è–µ—Ç –ø—Ä–µ—Å—Å-—Å–ª—É–∂–±—É –ù–∞—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π —Ñ—É—Ç–±–æ–ª—å–Ω–æ–π –ª–∏–≥–∏ –°–®–ê.\\n\\n–°—Ä–µ–¥–∏ —Å–æ—Å–µ–¥–µ–π –û–±–∞–º—ã ‚Äî –≤–∏–¥–Ω—ã–µ –¥–µ—è—Ç–µ–ª–∏ –í–∞—à–∏–Ω–≥—Ç–æ–Ω–∞, –≤–∫–ª—é—á–∞—è –¥–æ—á—å –¥–µ–π—Å—Ç–≤—É—é—â–µ–≥–æ –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç–∞ –ò–≤–∞–Ω–∫—É –¢—Ä–∞–º–ø –∏ –µ—ë –º—É–∂–∞ –î–∂–∞—Ä–µ–¥–∞ –ö—É—à–Ω–µ—Ä–∞ (–æ–±–∞ —è–≤–ª—è—é—Ç—Å—è —Å–æ–≤–µ—Ç–Ω–∏–∫–∞–º–∏ –ë–µ–ª–æ–≥–æ –¥–æ–º–∞), –∫–æ—Ç–æ—Ä—ã–µ –ø–µ—Ä–µ–µ—Ö–∞–ª–∏ –≤ —Ä–∞–π–æ–Ω –ö–∞–ª–æ—Ä–∞–º–∞ –∏–∑ –ù—å—é-–ô–æ—Ä–∫–∞ –≤ –Ω–∞—á–∞–ª–µ 2017 –≥–æ–¥–∞. –ì–æ—Å—Å–µ–∫—Ä–µ—Ç–∞—Ä—å –°–®–ê –†–µ–∫—Å –¢–∏–ª–ª–µ—Ä—Å–æ–Ω —Ç–æ–∂–µ –∂–∏–≤—ë—Ç –≤ –¥–æ–º–µ –Ω–µ–ø–æ–¥–∞–ª–µ–∫—É.\\n\\n¬´–£—á–∏—Ç—ã–≤–∞—è, —á—Ç–æ –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç –∏ –º–∏—Å—Å–∏—Å –û–±–∞–º–∞ –ø–ª–∞–Ω–∏—Ä—É—é—Ç –∂–∏—Ç—å –≤ –í–∞—à–∏–Ω–≥—Ç–æ–Ω–µ –∫–∞–∫ –º–∏–Ω–∏–º—É–º –µ—â—ë –¥–≤–∞ –≥–æ–¥–∞, –¥–ª—è –Ω–∏—Ö –∏–º–µ–ª–æ —Å–º—ã—Å–ª –ø—Ä–∏–æ–±—Ä–µ—Å—Ç–∏ –¥–æ–º –≤ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å, –∞ –Ω–µ –ø—Ä–æ–¥–æ–ª–∂–∞—Ç—å –µ–≥–æ –∞—Ä–µ–Ω–¥–æ–≤–∞—Ç—å¬ª, ‚Äî —Å–æ–æ–±—â–∏–ª –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ–ª—å –û–±–∞–º—ã.\\n\\n–°–µ–º—å—è –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç–∞ –û–±–∞–º—ã —Ç–∞–∫–∂–µ –≤–ª–∞–¥–µ–µ—Ç –¥–æ–º–æ–º –≤ –ß–∏–∫–∞–≥–æ ‚Äî —Ç—Ä–µ—Ç—å–µ–º –ø–æ –≤–µ–ª–∏—á–∏–Ω–µ –≥–æ—Ä–æ–¥–µ –≤ –°–®–ê, –≥–¥–µ –û–±–∞–º–∞ –ø—Ä–∏–æ–±—Ä—ë–ª –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—É—é –ø–æ–ª–∏—Ç–∏—á–µ—Å–∫—É—é –ø–æ–¥–¥–µ—Ä–∂–∫—É –ø–µ—Ä–µ–¥ —Ç–µ–º, –∫–∞–∫ –¥–≤–∞–∂–¥—ã —Å—Ç–∞–ª –≥–ª–∞–≤–æ—é –ë–µ–ª–æ–≥–æ –¥–æ–º–∞.\\n\\n',\n",
       " 'entities': ['T1\\tPERSON 60 71\\t–ë–∞—Ä–∞–∫ –û–±–∞–º–∞',\n",
       "  'T2\\tPERSON 6 11\\t–û–±–∞–º—ã',\n",
       "  'T3\\tFAMILY 274 281\\t–¢—é–¥–æ—Ä–æ–≤',\n",
       "  'T4\\tCITY 28 38\\t–í–∞—à–∏–Ω–≥—Ç–æ–Ω–µ',\n",
       "  'T5\\tMONEY 42 58\\t8,1 –º–ª–Ω –¥–æ–ª–ª–∞—Ä–æ–≤',\n",
       "  'T6\\tPROFESSION 635 649\\t–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç–∞ –°–®–ê',\n",
       "  'T7\\tPROFESSION 615 649\\t–ø—Ä–µ—Å—Å-—Å–µ–∫—Ä–µ—Ç–∞—Ä—é —ç–∫—Å-–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç–∞ –°–®–ê',\n",
       "  'T8\\tPROFESSION 1445 1463\\t–≥–ª–∞–≤–æ—é –ë–µ–ª–æ–≥–æ –¥–æ–º–∞',\n",
       "  'T9\\tCOUNTRY 89 92\\t–°–®–ê',\n",
       "  'T10\\tPERSON 93 104\\t–ë–∞—Ä–∞–∫ –û–±–∞–º–∞',\n",
       "  'T11\\tPERSON 113 119\\t–ú–∏—à–µ–ª—å',\n",
       "  'T12\\tCITY 138 148\\t–í–∞—à–∏–Ω–≥—Ç–æ–Ω–µ',\n",
       "  'T13\\tFACILITY 161 172\\t–ë–µ–ª–æ–≥–æ –¥–æ–º–∞',\n",
       "  'T14\\tPROFESSION 213 223\\t–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç–∞',\n",
       "  'T15\\tDATE 224 232\\t–≤ —è–Ω–≤–∞—Ä–µ',\n",
       "  'T16\\tORGANIZATION 733 765\\t–ù–∞—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π —Ñ—É—Ç–±–æ–ª—å–Ω–æ–π –ª–∏–≥–∏ –°–®–ê',\n",
       "  'T17\\tORGANIZATION 720 765\\t–ø—Ä–µ—Å—Å-—Å–ª—É–∂–±—É –ù–∞—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π —Ñ—É—Ç–±–æ–ª—å–Ω–æ–π –ª–∏–≥–∏ –°–®–ê',\n",
       "  'T18\\tCOUNTRY 310 313\\t–°–®–ê',\n",
       "  'T19\\tDISTRICT 316 324\\t–ö–∞–ª–æ—Ä–∞–º–∞',\n",
       "  'T20\\tPERSON 400 406\\t–ë–∞—Ä–∞–∫–∞',\n",
       "  'T21\\tPERSON 409 415\\t–ú–∏—à–µ–ª—å',\n",
       "  'T22\\tPERSON 418 422\\t–°–∞—à–µ',\n",
       "  'T23\\tDATE 436 444\\t–¥–≤–∞ –≥–æ–¥–∞',\n",
       "  'T24\\tCITY 474 484\\t–í–∞—à–∏–Ω–≥—Ç–æ–Ω–µ',\n",
       "  'T25\\tNUMBER 522 529\\t–≤–æ—Å–µ–º—å—é',\n",
       "  'T26\\tPROFESSION 907 930\\t—Å–æ–≤–µ—Ç–Ω–∏–∫–∞–º–∏ –ë–µ–ª–æ–≥–æ –¥–æ–º–∞',\n",
       "  'T27\\tMONEY 561 582\\t8,1 –º–∏–ª–ª–∏–æ–Ω–∞ –¥–æ–ª–ª–∞—Ä–æ–≤',\n",
       "  'T28\\tDISTRICT 959 967\\t–ö–∞–ª–æ—Ä–∞–º–∞',\n",
       "  'T29\\tPROFESSION 352 361\\t–¥–∏–ø–ª–æ–º–∞—Ç—ã',\n",
       "  'T30\\tPROFESSION 1001 1017\\t–ì–æ—Å—Å–µ–∫—Ä–µ—Ç–∞—Ä—å –°–®–ê',\n",
       "  'T31\\tCOUNTRY 646 649\\t–°–®–ê',\n",
       "  'T32\\tPERSON 650 664\\t–ë–∏–ª–ª–∞ –ö–ª–∏–Ω—Ç–æ–Ω–∞',\n",
       "  'T33\\tPERSON 665 677\\t–î–∂–æ –õ–æ–∫—Ö–∞—Ä—Ç—É',\n",
       "  'T34\\tDATE 1148 1156\\t–¥–≤–∞ –≥–æ–¥–∞',\n",
       "  'T35\\tPROFESSION 1253 1272\\t–ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ–ª—å –û–±–∞–º—ã',\n",
       "  'T36\\tCOUNTRY 762 765\\t–°–®–ê',\n",
       "  'T37\\tPERSON 782 787\\t–û–±–∞–º—ã',\n",
       "  'T38\\tEVENT 12 25\\t–ø—Ä–∏–æ–±—Ä–µ–ª–∞ –¥–æ–º',\n",
       "  'T39\\tCITY 805 815\\t–í–∞—à–∏–Ω–≥—Ç–æ–Ω–∞',\n",
       "  'T40\\tPROFESSION 843 853\\t–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç–∞',\n",
       "  'T41\\tPERSON 854 866\\t–ò–≤–∞–Ω–∫—É –¢—Ä–∞–º–ø',\n",
       "  'T42\\tPERSON 877 892\\t–î–∂–∞—Ä–µ–¥–∞ –ö—É—à–Ω–µ—Ä–∞',\n",
       "  'T43\\tEVENT 120 135\\t–ø—Ä–∏–æ–±—Ä–µ–ª–∏ –∂–∏–ª—å—ë',\n",
       "  'T44\\tORGANIZATION 919 930\\t–ë–µ–ª–æ–≥–æ –¥–æ–º–∞',\n",
       "  'T45\\tPROFESSION 79 92\\t–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç –°–®–ê',\n",
       "  'T46\\tPROFESSION 79 88\\t–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç',\n",
       "  'T47\\tCITY 971 980\\t–ù—å—é-–ô–æ—Ä–∫–∞',\n",
       "  'T48\\tDATE 981 999\\t–≤ –Ω–∞—á–∞–ª–µ 2017 –≥–æ–¥–∞',\n",
       "  'T49\\tPROFESSION 615 630\\t–ø—Ä–µ—Å—Å-—Å–µ–∫—Ä–µ—Ç–∞—Ä—é',\n",
       "  'T50\\tCOUNTRY 1014 1017\\t–°–®–ê',\n",
       "  'T51\\tPERSON 1018 1032\\t–†–µ–∫—Å –¢–∏–ª–ª–µ—Ä—Å–æ–Ω',\n",
       "  'T52\\tPROFESSION 1001 1013\\t–ì–æ—Å—Å–µ–∫—Ä–µ—Ç–∞—Ä—å',\n",
       "  'T53\\tPROFESSION 1079 1088\\t–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç',\n",
       "  'T54\\tCITY 302 313\\t—Å—Ç–æ–ª–∏—Ü—ã –°–®–ê',\n",
       "  'T55\\tPERSON 1091 1103\\t–º–∏—Å—Å–∏—Å –û–±–∞–º–∞',\n",
       "  'T56\\tCITY 1121 1131\\t–í–∞—à–∏–Ω–≥—Ç–æ–Ω–µ',\n",
       "  'T57\\tFAMILY 0 11\\t–°–µ–º—å—è –û–±–∞–º—ã',\n",
       "  'T58\\tPERSON 1098 1103\\t–û–±–∞–º–∞',\n",
       "  'T59\\tPERSON 1267 1272\\t–û–±–∞–º—ã',\n",
       "  'T60\\tPROFESSION 363 371\\t–ª–æ–±–±–∏—Å—Ç—ã',\n",
       "  'T61\\tPROFESSION 1281 1291\\t–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç–∞',\n",
       "  'T62\\tPERSON 1292 1297\\t–û–±–∞–º—ã',\n",
       "  'T63\\tPROFESSION 374 382\\t–ø–æ–ª–∏—Ç–∏–∫–∏',\n",
       "  'T64\\tCITY 1320 1326\\t–ß–∏–∫–∞–≥–æ',\n",
       "  'T65\\tORDINAL 1329 1336\\t—Ç—Ä–µ—Ç—å–µ–º',\n",
       "  'T66\\tCOUNTRY 1358 1361\\t–°–®–ê',\n",
       "  'T67\\tPERSON 1367 1372\\t–û–±–∞–º–∞',\n",
       "  'T68\\tORGANIZATION 1452 1463\\t–ë–µ–ª–æ–≥–æ –¥–æ–º–∞',\n",
       "  'T69\\tFAMILY 1275 1297\\t–°–µ–º—å—è –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç–∞ –û–±–∞–º—ã'],\n",
       " 'relations': ['R1\\tWORKS_AS Arg1:T32 Arg2:T6',\n",
       "  'R2\\tWORKS_AS Arg1:T33 Arg2:T7',\n",
       "  'R3\\tWORKS_AS Arg1:T51 Arg2:T30',\n",
       "  'R4\\tWORKS_AS Arg1:T10 Arg2:T45',\n",
       "  'R5\\tWORKPLACE Arg1:T10 Arg2:T9',\n",
       "  'R6\\tSPOUSE Arg1:T10 Arg2:T11',\n",
       "  'R7\\tLOCATED_IN Arg1:T19 Arg2:T54',\n",
       "  'R8\\tSPOUSE Arg1:T20 Arg2:T21',\n",
       "  'R9\\tPARENT_OF Arg1:T20 Arg2:T22',\n",
       "  'R10\\tPARENT_OF Arg1:T21 Arg2:T22',\n",
       "  'R11\\tSPOUSE Arg1:T41 Arg2:T42',\n",
       "  'R12\\tWORKS_AS Arg1:T42 Arg2:T26',\n",
       "  'R13\\tWORKPLACE Arg1:T42 Arg2:T44',\n",
       "  'R14\\tWORKS_AS Arg1:T41 Arg2:T26',\n",
       "  'R15\\tWORKPLACE Arg1:T41 Arg2:T44',\n",
       "  'R16\\tPLACE_RESIDES_IN Arg1:T53 Arg2:T56',\n",
       "  'R17\\tPLACE_RESIDES_IN Arg1:T55 Arg2:T56',\n",
       "  'R18\\tWORKPLACE Arg1:T67 Arg2:T68',\n",
       "  'R19\\tAGENT Arg1:T57 Arg2:T38',\n",
       "  'R20\\tTAKES_PLACE_IN Arg1:T38 Arg2:T4',\n",
       "  'R21\\tTAKES_PLACE_IN Arg1:T43 Arg2:T12',\n",
       "  'R22\\tAGENT Arg1:T11 Arg2:T43',\n",
       "  'R23\\tAGENT Arg1:T10 Arg2:T43',\n",
       "  'R24\\tLOCATED_IN Arg1:T13 Arg2:T12',\n",
       "  'R25\\tWORKPLACE Arg1:T33 Arg2:T17',\n",
       "  'R26\\tWORKPLACE Arg1:T32 Arg2:T31',\n",
       "  'R27\\tSUBORDINATE_OF Arg1:T33 Arg2:T32',\n",
       "  'R28\\tWORKS_AS Arg1:T62 Arg2:T61',\n",
       "  'R29\\tSPOUSE Arg1:T53 Arg2:T55',\n",
       "  'R30\\tPARENT_OF Arg1:T40 Arg2:T41',\n",
       "  'R31\\tPLACE_RESIDES_IN Arg1:T41 Arg2:T28',\n",
       "  'R32\\tPLACE_RESIDES_IN Arg1:T42 Arg2:T28',\n",
       "  'R33\\tPLACE_RESIDES_IN Arg1:T10 Arg2:T19',\n",
       "  'R34\\tPLACE_RESIDES_IN Arg1:T11 Arg2:T19',\n",
       "  'R35\\tPLACE_RESIDES_IN Arg1:T51 Arg2:T28',\n",
       "  'R36\\tLOCATED_IN Arg1:T28 Arg2:T56',\n",
       "  'R37\\tLOCATED_IN Arg1:T64 Arg2:T66',\n",
       "  'R38\\tALTERNATIVE_NAME Arg1:T2 Arg2:T1',\n",
       "  'R39\\tALTERNATIVE_NAME Arg1:T38 Arg2:T43',\n",
       "  'R40\\tWORKPLACE Arg1:T45 Arg2:T9',\n",
       "  'R41\\tLOCATED_IN Arg1:T54 Arg2:T18',\n",
       "  'R42\\tALTERNATIVE_NAME Arg1:T12 Arg2:T54',\n",
       "  'R43\\tHEADQUARTERED_IN Arg1:T16 Arg2:T36',\n",
       "  'R44\\tWORKPLACE Arg1:T30 Arg2:T50',\n",
       "  'R45\\tSUBORDINATE_OF Arg1:T35 Arg2:T59',\n",
       "  'R46\\tEXPENDITURE Arg1:T57 Arg2:T5',\n",
       "  'R47\\tPART_OF Arg1:T17 Arg2:T16',\n",
       "  'R48\\tWORKPLACE Arg1:T26 Arg2:T44',\n",
       "  'R49\\tSUBORDINATE_OF Arg1:T7 Arg2:T6',\n",
       "  'R50\\tALTERNATIVE_NAME Arg1:T10 Arg2:T20',\n",
       "  'R51\\tALTERNATIVE_NAME Arg1:T20 Arg2:T37',\n",
       "  'R52\\tWORKS_AS Arg1:T37 Arg2:T53',\n",
       "  'R53\\tSPOUSE Arg1:T55 Arg2:T58',\n",
       "  'R54\\tWORKS_AS Arg1:T58 Arg2:T53',\n",
       "  'R55\\tALTERNATIVE_NAME Arg1:T5 Arg2:T27',\n",
       "  'R56\\tMEMBER_OF Arg1:T2 Arg2:T57',\n",
       "  'R57\\tPRICE_OF Arg1:T38 Arg2:T5',\n",
       "  'R58\\tWORKPLACE Arg1:T8 Arg2:T68',\n",
       "  'R59\\tMEMBER_OF Arg1:T62 Arg2:T69',\n",
       "  'R60\\tWORKS_AS Arg1:T67 Arg2:T8'],\n",
       " 'links': ['N1\\tReference T11 Wikidata:Q13133\\t–ú–∏—à–µ–ª—å –û–±–∞–º–∞',\n",
       "  'N2\\tReference T13 Wikidata:Q35525\\t–ë–µ–ª—ã–π –¥–æ–º',\n",
       "  'N3\\tReference T18 Wikidata:Q30\\t–°–®–ê',\n",
       "  'N4\\tReference T22 Wikidata:Q15070048\\t',\n",
       "  'N5\\tReference T32 Wikidata:Q1124\\t–ë–∏–ª–ª –ö–ª–∏–Ω—Ç–æ–Ω',\n",
       "  'N6\\tReference T33 Wikidata:Q6210964\\t',\n",
       "  'N7\\tReference T41 Wikidata:Q239411\\t–ò–≤–∞–Ω–∫–∞ –¢—Ä–∞–º–ø',\n",
       "  'N8\\tReference T42 Wikidata:Q13628723\\t–î–∂–∞—Ä–µ–¥ –ö—É—à–Ω–µ—Ä',\n",
       "  'N9\\tReference T47 Wikidata:Q60\\t–ù—å—é-–ô–æ—Ä–∫',\n",
       "  'N10\\tReference T51 Wikidata:Q331401\\t–¢–∏–ª–ª–µ—Ä—Å–æ–Ω, –†–µ–∫—Å',\n",
       "  'N11\\tReference T55 Wikidata:Q13133\\t–ú–∏—à–µ–ª—å –û–±–∞–º–∞',\n",
       "  'N12\\tReference T56 Wikidata:Q61\\t–í–∞—à–∏–Ω–≥—Ç–æ–Ω',\n",
       "  'N13\\tReference T62 Wikidata:Q76\\t–ë–∞—Ä–∞–∫ –û–±–∞–º–∞',\n",
       "  'N14\\tReference T64 Wikidata:Q1297\\t–ß–∏–∫–∞–≥–æ',\n",
       "  'N15\\tReference T68 Wikidata:Q35525\\t–ë–µ–ª—ã–π –¥–æ–º',\n",
       "  'N16\\tReference T1 Wikidata:Q76\\t–ë–∞—Ä–∞–∫ –û–±–∞–º–∞',\n",
       "  'N17\\tReference T6 Wikidata:Q11696\\t–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç –°–®–ê',\n",
       "  'N18\\tReference T7 Wikidata:NULL\\t',\n",
       "  'N19\\tReference T16 Wikidata:Q1215884\\t–ù–∞—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è —Ñ—É—Ç–±–æ–ª—å–Ω–∞—è –ª–∏–≥–∞',\n",
       "  'N20\\tReference T17 Wikidata:NULL\\t',\n",
       "  'N21\\tReference T26 Wikidata:Q7450652\\t',\n",
       "  'N22\\tReference T35 Wikidata:NULL\\t',\n",
       "  'N23\\tReference T46 Wikidata:Q30461\\t–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç',\n",
       "  'N24\\tReference T19 Wikidata:Q12060942\\t',\n",
       "  'N25\\tReference T49 Wikidata:Q1388151\\t',\n",
       "  'N26\\tReference T52 Wikidata:Q736559\\tc—Ç–∞—Ç—Å-—Å–µ–∫—Ä–µ—Ç–∞—Ä—å',\n",
       "  'N27\\tReference T30 Wikidata:Q14213\\t–≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã–π —Å–µ–∫—Ä–µ—Ç–∞—Ä—å –°–®–ê',\n",
       "  'N28\\tReference T21 Wikidata:Q13133\\t–ú–∏—à–µ–ª—å –û–±–∞–º–∞',\n",
       "  'N29\\tReference T50 Wikidata:Q30\\t–°–®–ê',\n",
       "  'N30\\tReference T36 Wikidata:Q30\\t–°–®–ê',\n",
       "  'N31\\tReference T9 Wikidata:Q30\\t–°–®–ê',\n",
       "  'N32\\tReference T66 Wikidata:Q30\\t–°–®–ê',\n",
       "  'N33\\tReference T31 Wikidata:Q30\\t–°–®–ê',\n",
       "  'N34\\tReference T4 Wikidata:Q61\\t–í–∞—à–∏–Ω–≥—Ç–æ–Ω',\n",
       "  'N35\\tReference T54 Wikidata:Q61\\t–í–∞—à–∏–Ω–≥—Ç–æ–Ω',\n",
       "  'N36\\tReference T39 Wikidata:Q61\\t–í–∞—à–∏–Ω–≥—Ç–æ–Ω',\n",
       "  'N37\\tReference T24 Wikidata:Q61\\t–í–∞—à–∏–Ω–≥—Ç–æ–Ω',\n",
       "  'N38\\tReference T12 Wikidata:Q61\\t–í–∞—à–∏–Ω–≥—Ç–æ–Ω',\n",
       "  'N39\\tReference T37 Wikidata:Q76\\t–ë–∞—Ä–∞–∫ –û–±–∞–º–∞',\n",
       "  'N40\\tReference T20 Wikidata:Q76\\t–ë–∞—Ä–∞–∫ –û–±–∞–º–∞',\n",
       "  'N41\\tReference T58 Wikidata:Q76\\t–ë–∞—Ä–∞–∫ –û–±–∞–º–∞',\n",
       "  'N42\\tReference T10 Wikidata:Q76\\t–ë–∞—Ä–∞–∫ –û–±–∞–º–∞',\n",
       "  'N43\\tReference T67 Wikidata:Q76\\t–ë–∞—Ä–∞–∫ –û–±–∞–º–∞',\n",
       "  'N44\\tReference T59 Wikidata:Q76\\t–ë–∞—Ä–∞–∫ –û–±–∞–º–∞',\n",
       "  'N45\\tReference T44 Wikidata:Q35525\\t–ë–µ–ª—ã–π –¥–æ–º',\n",
       "  'N46\\tReference T2 Wikidata:Q76\\t–ë–∞—Ä–∞–∫ –û–±–∞–º–∞',\n",
       "  'N47\\tReference T45 Wikidata:Q11696\\t–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç –°–®–ê',\n",
       "  'N48\\tReference T14 Wikidata:Q30461\\t–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç',\n",
       "  'N49\\tReference T61 Wikidata:Q30461\\t–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç',\n",
       "  'N50\\tReference T40 Wikidata:Q30461\\t–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç',\n",
       "  'N51\\tReference T53 Wikidata:Q30461\\t–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç',\n",
       "  'N52\\tReference T28 Wikidata:Q12060942\\t'],\n",
       " 'input_ids': [101,\n",
       "  6511,\n",
       "  4984,\n",
       "  839,\n",
       "  4984,\n",
       "  839,\n",
       "  24135,\n",
       "  3158,\n",
       "  113,\n",
       "  61449,\n",
       "  376,\n",
       "  681,\n",
       "  178,\n",
       "  121,\n",
       "  141,\n",
       "  2326,\n",
       "  3123,\n",
       "  83462,\n",
       "  4984,\n",
       "  698,\n",
       "  92128,\n",
       "  42394,\n",
       "  2598,\n",
       "  67899,\n",
       "  2598,\n",
       "  67899,\n",
       "  83462,\n",
       "  4984,\n",
       "  698,\n",
       "  110,\n",
       "  88776,\n",
       "  378,\n",
       "  54189,\n",
       "  2502,\n",
       "  29289,\n",
       "  16610,\n",
       "  113,\n",
       "  61449,\n",
       "  376,\n",
       "  9921,\n",
       "  700,\n",
       "  14462,\n",
       "  1789,\n",
       "  126,\n",
       "  934,\n",
       "  7312,\n",
       "  11928,\n",
       "  2218,\n",
       "  660,\n",
       "  6594,\n",
       "  2662,\n",
       "  113,\n",
       "  6558,\n",
       "  18411,\n",
       "  96770,\n",
       "  378,\n",
       "  36304,\n",
       "  113,\n",
       "  9572,\n",
       "  12471,\n",
       "  3870,\n",
       "  3370,\n",
       "  113,\n",
       "  89243,\n",
       "  690,\n",
       "  378,\n",
       "  1451,\n",
       "  7291,\n",
       "  67899,\n",
       "  67899,\n",
       "  179,\n",
       "  31605,\n",
       "  50993,\n",
       "  121,\n",
       "  1153,\n",
       "  12564,\n",
       "  1012,\n",
       "  120046,\n",
       "  38555,\n",
       "  121,\n",
       "  24841,\n",
       "  1178,\n",
       "  107,\n",
       "  4868,\n",
       "  126,\n",
       "  34041,\n",
       "  378,\n",
       "  8106,\n",
       "  91955,\n",
       "  107,\n",
       "  54189,\n",
       "  2502,\n",
       "  179,\n",
       "  798,\n",
       "  756,\n",
       "  5493,\n",
       "  1025,\n",
       "  1363,\n",
       "  878,\n",
       "  708,\n",
       "  7312,\n",
       "  2300,\n",
       "  110870,\n",
       "  4814,\n",
       "  113,\n",
       "  61449,\n",
       "  376,\n",
       "  126,\n",
       "  2686,\n",
       "  6511,\n",
       "  7042,\n",
       "  45802,\n",
       "  3158,\n",
       "  110,\n",
       "  73276,\n",
       "  11093,\n",
       "  1018,\n",
       "  72004,\n",
       "  378,\n",
       "  17148,\n",
       "  178,\n",
       "  121,\n",
       "  141,\n",
       "  5975,\n",
       "  3123,\n",
       "  126,\n",
       "  2944,\n",
       "  3158,\n",
       "  19878,\n",
       "  27244,\n",
       "  2262,\n",
       "  133,\n",
       "  59474,\n",
       "  2048,\n",
       "  133,\n",
       "  2662,\n",
       "  67899,\n",
       "  2262,\n",
       "  133,\n",
       "  59474,\n",
       "  2048,\n",
       "  133,\n",
       "  2662,\n",
       "  67899,\n",
       "  67899,\n",
       "  20725,\n",
       "  662,\n",
       "  22061,\n",
       "  4414,\n",
       "  101115,\n",
       "  17543,\n",
       "  55243,\n",
       "  389,\n",
       "  160,\n",
       "  158,\n",
       "  121,\n",
       "  862,\n",
       "  378,\n",
       "  113,\n",
       "  3514,\n",
       "  1012,\n",
       "  21255,\n",
       "  2262,\n",
       "  133,\n",
       "  6235,\n",
       "  23231,\n",
       "  378,\n",
       "  12327,\n",
       "  394,\n",
       "  110870,\n",
       "  7440,\n",
       "  67899,\n",
       "  23231,\n",
       "  378,\n",
       "  12327,\n",
       "  394,\n",
       "  110870,\n",
       "  7440,\n",
       "  67899,\n",
       "  67899,\n",
       "  126,\n",
       "  2378,\n",
       "  4753,\n",
       "  376,\n",
       "  378,\n",
       "  4984,\n",
       "  839,\n",
       "  179,\n",
       "  77234,\n",
       "  28081,\n",
       "  61449,\n",
       "  377,\n",
       "  121,\n",
       "  5048,\n",
       "  5785,\n",
       "  784,\n",
       "  34083,\n",
       "  1867,\n",
       "  1432,\n",
       "  2662,\n",
       "  104691,\n",
       "  6181,\n",
       "  11166,\n",
       "  388,\n",
       "  107,\n",
       "  1003,\n",
       "  7678,\n",
       "  16954,\n",
       "  51773,\n",
       "  108133,\n",
       "  5156,\n",
       "  160,\n",
       "  4984,\n",
       "  3933,\n",
       "  112778,\n",
       "  14462,\n",
       "  1789,\n",
       "  14462,\n",
       "  1789,\n",
       "  158,\n",
       "  121,\n",
       "  1115,\n",
       "  39348,\n",
       "  113,\n",
       "  690,\n",
       "  378,\n",
       "  833,\n",
       "  31605,\n",
       "  50993,\n",
       "  734,\n",
       "  22900,\n",
       "  133,\n",
       "  68729,\n",
       "  657,\n",
       "  113,\n",
       "  3109,\n",
       "  5222,\n",
       "  878,\n",
       "  126,\n",
       "  33897,\n",
       "  67899,\n",
       "  33897,\n",
       "  67899,\n",
       "  17766,\n",
       "  381,\n",
       "  1474,\n",
       "  7715,\n",
       "  3006,\n",
       "  1553,\n",
       "  7453,\n",
       "  113,\n",
       "  4308,\n",
       "  13013,\n",
       "  126,\n",
       "  151,\n",
       "  12367,\n",
       "  121,\n",
       "  693,\n",
       "  2598,\n",
       "  107,\n",
       "  10175,\n",
       "  4984,\n",
       "  698,\n",
       "  4984,\n",
       "  698,\n",
       "  13592,\n",
       "  4097,\n",
       "  113,\n",
       "  61449,\n",
       "  376,\n",
       "  785,\n",
       "  6716,\n",
       "  1025,\n",
       "  1363,\n",
       "  878,\n",
       "  121,\n",
       "  849,\n",
       "  1303,\n",
       "  14647,\n",
       "  6658,\n",
       "  15202,\n",
       "  3158,\n",
       "  113,\n",
       "  16223,\n",
       "  121,\n",
       "  106,\n",
       "  672,\n",
       "  9338,\n",
       "  806,\n",
       "  79988,\n",
       "  150,\n",
       "  121,\n",
       "  179,\n",
       "  2422,\n",
       "  4123,\n",
       "  4984,\n",
       "  839,\n",
       "  4984,\n",
       "  839,\n",
       "  126,\n",
       "  6511,\n",
       "  2662,\n",
       "  4984,\n",
       "  839,\n",
       "  2662,\n",
       "  4984,\n",
       "  839,\n",
       "  1080,\n",
       "  17472,\n",
       "  15178,\n",
       "  113,\n",
       "  86155,\n",
       "  653,\n",
       "  179,\n",
       "  10847,\n",
       "  654,\n",
       "  25806,\n",
       "  2974,\n",
       "  113,\n",
       "  67899,\n",
       "  121,\n",
       "  1153,\n",
       "  4984,\n",
       "  698,\n",
       "  20379,\n",
       "  22699,\n",
       "  15598,\n",
       "  5784,\n",
       "  1582,\n",
       "  1201,\n",
       "  121,\n",
       "  785,\n",
       "  7970,\n",
       "  1579,\n",
       "  1578,\n",
       "  375,\n",
       "  403,\n",
       "  14462,\n",
       "  1789,\n",
       "  14462,\n",
       "  1789,\n",
       "  126,\n",
       "  102],\n",
       " 'token_type_ids': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'labels': [-100,\n",
       "  21,\n",
       "  22,\n",
       "  22,\n",
       "  45,\n",
       "  45,\n",
       "  17,\n",
       "  18,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  31,\n",
       "  31,\n",
       "  31,\n",
       "  32,\n",
       "  32,\n",
       "  45,\n",
       "  46,\n",
       "  46,\n",
       "  0,\n",
       "  0,\n",
       "  49,\n",
       "  50,\n",
       "  49,\n",
       "  7,\n",
       "  45,\n",
       "  46,\n",
       "  46,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  45,\n",
       "  45,\n",
       "  17,\n",
       "  18,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  19,\n",
       "  20,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  49,\n",
       "  11,\n",
       "  12,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  21,\n",
       "  21,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  15,\n",
       "  15,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  49,\n",
       "  0,\n",
       "  49,\n",
       "  49,\n",
       "  0,\n",
       "  49,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  45,\n",
       "  0,\n",
       "  45,\n",
       "  45,\n",
       "  0,\n",
       "  45,\n",
       "  45,\n",
       "  0,\n",
       "  0,\n",
       "  11,\n",
       "  12,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  35,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  31,\n",
       "  31,\n",
       "  31,\n",
       "  32,\n",
       "  32,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  49,\n",
       "  49,\n",
       "  49,\n",
       "  50,\n",
       "  50,\n",
       "  50,\n",
       "  50,\n",
       "  49,\n",
       "  49,\n",
       "  49,\n",
       "  0,\n",
       "  0,\n",
       "  49,\n",
       "  50,\n",
       "  7,\n",
       "  45,\n",
       "  45,\n",
       "  46,\n",
       "  46,\n",
       "  45,\n",
       "  46,\n",
       "  46,\n",
       "  46,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  39,\n",
       "  39,\n",
       "  39,\n",
       "  40,\n",
       "  40,\n",
       "  40,\n",
       "  40,\n",
       "  40,\n",
       "  40,\n",
       "  40,\n",
       "  39,\n",
       "  39,\n",
       "  40,\n",
       "  40,\n",
       "  40,\n",
       "  40,\n",
       "  40,\n",
       "  7,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  45,\n",
       "  45,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  49,\n",
       "  45,\n",
       "  45,\n",
       "  46,\n",
       "  46,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  45,\n",
       "  45,\n",
       "  46,\n",
       "  46,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  49,\n",
       "  50,\n",
       "  50,\n",
       "  39,\n",
       "  40,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  15,\n",
       "  15,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  11,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  0,\n",
       "  49,\n",
       "  50,\n",
       "  49,\n",
       "  7,\n",
       "  45,\n",
       "  45,\n",
       "  46,\n",
       "  46,\n",
       "  46,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  49,\n",
       "  0,\n",
       "  45,\n",
       "  46,\n",
       "  46,\n",
       "  45,\n",
       "  45,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  11,\n",
       "  12,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  49,\n",
       "  50,\n",
       "  50,\n",
       "  45,\n",
       "  45,\n",
       "  0,\n",
       "  21,\n",
       "  22,\n",
       "  22,\n",
       "  22,\n",
       "  49,\n",
       "  45,\n",
       "  45,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  37,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  7,\n",
       "  0,\n",
       "  0,\n",
       "  45,\n",
       "  45,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  49,\n",
       "  49,\n",
       "  49,\n",
       "  50,\n",
       "  50,\n",
       "  39,\n",
       "  40,\n",
       "  0,\n",
       "  -100]}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets[\"dev\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"–ü–æ—Ä–æ—à–µ–Ω–∫–æ —Ä–∞–∑—Ä–µ—à–∏–ª –Ω–µ –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –¥–æ–ª–≥ –†–æ—Å—Å–∏–∏\\n\\n–ü—ë—Ç—Ä –ü–æ—Ä–æ—à–µ–Ω–∫–æ\\n–ü—Ä–µ–∑–∏–¥–µ–Ω—Ç –£–∫—Ä–∞–∏–Ω—ã –ü—ë—Ç—Ä –ü–æ—Ä–æ—à–µ–Ω–∫–æ –ø–æ–¥–ø–∏—Å–∞–ª –∑–∞–∫–æ–Ω –æ –≤–≤–µ–¥–µ–Ω–∏–∏ –±–µ—Å—Å—Ä–æ—á–Ω–æ–≥–æ –º–æ—Ä–∞—Ç–æ—Ä–∏—è –Ω–∞ –≤—ã–ø–ª–∞—Ç—É –¥–æ–ª–≥–∞ –†–æ—Å—Å–∏–∏, [http://w1.c1.rada.gov.ua/pls/zweb2/webproc4_1?pf3511=57479 —Å–æ–æ–±—â–∞–µ—Ç—Å—è] –Ω–∞ —Å–∞–π—Ç–µ –í–µ—Ä—Ö–æ–≤–Ω–æ–π –†–∞–¥—ã.\\n\\n–û–¥–æ–±—Ä–µ–Ω–Ω—ã–π –ø–∞—Ä–ª–∞–º–µ–Ω—Ç–æ–º 12 –∞–ø—Ä–µ–ª—è –∏ –ø–æ–¥–ø–∏—Å–∞–Ω–Ω—ã–π –µ—â—ë 29 –∞–ø—Ä–µ–ª—è –∑–∞–∫–æ–Ω –æ—Ç–º–µ–Ω—è–µ—Ç –∫–æ–Ω–µ—á–Ω—É—é –¥–∞—Ç—É –º–æ—Ä–∞—Ç–æ—Ä–∏—è ‚Äî 1 –∏—é–ª—è 2016 –≥–æ–¥–∞, —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–æ–≥–æ –≤ –∑–∞–∫–æ–Ω–µ ¬´–û–± –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—è—Ö –æ—Å—É—â–µ—Å—Ç–≤–ª–µ–Ω–∏—è —Å–¥–µ–ª–æ–∫ —Å –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã–º, –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–æ–º –¥–æ–ª–≥–æ–º –∏ –º–µ—Å—Ç–Ω—ã–º –¥–æ–ª–≥–æ–º¬ª.\\n\\n–†–µ—á—å –∏–¥—ë—Ç –æ –∫—Ä–µ–¥–∏—Ç–µ –≤ –≤–∏–¥–µ –ø–æ–∫—É–ø–∫–∏ –µ–≤—Ä–æ–±–æ–Ω–¥–æ–≤ –Ω–∞ —Å—É–º–º—É 3 –º–ª—Ä–¥ –¥–æ–ª–ª–∞—Ä–æ–≤ –°–®–ê, –∫–æ—Ç–æ—Ä—ã–π –†–æ—Å—Å–∏—è –≤—ã–¥–∞–ª–∞ –£–∫—Ä–∞–∏–Ω–µ –≤–æ –≤—Ä–µ–º—è –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç—Å—Ç–≤–∞ –í–∏–∫—Ç–æ—Ä–∞ –Ø–Ω—É–∫–æ–≤–∏—á–∞ –≤ –¥–µ–∫–∞–±—Ä–µ 2013 –≥–æ–¥–∞, –∏ –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –£–∫—Ä–∞–∏–Ω–æ–π –¥–æ–ª–≥–∞—Ö –º–µ—Å—Ç–Ω—ã—Ö –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏–π –Ω–∞ –æ–±—â—É—é —Å—É–º–º—É –±–æ–ª–µ–µ 500 –º–ª–Ω –¥–æ–ª–ª–∞—Ä–æ–≤ –°–®–ê.\\n\\n–î–æ–ª–≥ –ø–µ—Ä–µ–¥ –†–æ—Å—Å–∏–µ–π –≤ 3 –º–ª—Ä–¥ –∏ 75 –º–ª–Ω –Ω–∞–±–µ–∂–∞–≤—à–∏—Ö –Ω–∞ —Ç–æ—Ç –º–æ–º–µ–Ω—Ç –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤ –¥–æ–ª–∂–µ–Ω –±—ã–ª –±—ã—Ç—å –ø–æ–≥–∞—à–µ–Ω –¥–æ 31 –¥–µ–∫–∞–±—Ä—è 2015 –≥–æ–¥–∞.\\n\\n–ü–æ—Å–ª–µ –±–µ–≥—Å—Ç–≤–∞ –Ø–Ω—É–∫–æ–≤–∏—á–∞ –∏ —Å–º–µ–Ω—ã –≤–ª–∞—Å—Ç–∏ –≤ –£–∫—Ä–∞–∏–Ω–µ –ú–æ—Å–∫–≤–∞ –∏ –ö–∏–µ–≤ –Ω–µ —Å–º–æ–≥–ª–∏ –¥–æ–≥–æ–≤–æ—Ä–∏—Ç—å—Å—è –æ —Ä–µ—Å—Ç—Ä—É–∫—Ç—É—Ä–∏–∑–∞—Ü–∏–∏ –¥–æ–ª–≥–∞.\\n–£–∫—Ä–∞–∏–Ω–∞, —Å—á–∏—Ç–∞—é—â–∞—è —ç—Ç–æ—Ç –∫—Ä–µ–¥–∏—Ç –ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–∏ –æ–±—É—Å–ª–æ–≤–ª–µ–Ω–Ω—ã–º, —Ä–µ—à–∏–ª–∞ –Ω–µ –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –µ–≥–æ –Ω–∞ –ø—Ä–µ–∂–Ω–∏—Ö —É—Å–ª–æ–≤–∏—è—Ö.\\n–î–ª—è —ç—Ç–æ–≥–æ –∫–∞–±–∏–Ω–µ—Ç –º–∏–Ω–∏—Å—Ç—Ä–æ–≤ –≤ –¥–µ–∫–∞–±—Ä–µ 2015 –≥–æ–¥–∞ –≤–≤—ë–ª –º–æ—Ä–∞—Ç–æ—Ä–∏–π –Ω–∞ –µ–≥–æ –≤—ã–ø–ª–∞—Ç—É.\\n\\n–ö—Ä–æ–º–µ —Ç–æ–≥–æ, –£–∫—Ä–∞–∏–Ω–∞ –ø—Ä–æ–≤–µ–ª–∞ —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω—É—é —Ä–∞—Å—á–∏—Å—Ç–∫—É —Å–≤–æ–∏—Ö –∫—Ä–µ–¥–∏—Ç–Ω—ã—Ö –æ–±—è–∑–∞—Ç–µ–ª—å—Å—Ç–≤, —Ä–µ—Å—Ç—Ä—É–∫—Ç—É—Ä–∏–∑–∏—Ä–æ–≤–∞–≤ –∏—Ö –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ —Å–æ –≤—Å–µ–º–∏ —Å—Ç–æ—Ä–æ–Ω–∞–º–∏ –∑–∞ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ–º –†–æ—Å—Å–∏–∏, –∫–æ—Ç–æ—Ä–∞—è –Ω–∞—Å—Ç–∞–∏–≤–∞–ª–∞ –Ω–∞ —ç–∫—Å–∫–ª—é–∑–∏–≤–Ω–æ–º —Å—Ç–∞—Ç—É—Å–µ.\\n\\n–î–æ–ª–≥–æ–≤–æ–π —Å–ø–æ—Ä –º–µ–∂–¥—É –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–∞–º–∏ —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç—Å—è —Å–µ–π—á–∞—Å –≤ –í—ã—Å–æ–∫–æ–º —Å—É–¥–µ –õ–æ–Ω–¥–æ–Ω–∞.\\n\\n–ù–µ—Å–º–æ—Ç—Ä—è –Ω–∞ —ç—Ç–æ 26 —Ñ–µ–≤—Ä–∞–ª—è 2016 –≥–æ–¥–∞ –≤ —Ä–æ—Å—Å–∏–π—Å–∫–æ–º –ú–∏–Ω—Ñ–∏–Ω–µ –∑–∞—è–≤–∏–ª–∏ –æ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –æ–±—Å—É–∂–¥–∞—Ç—å —Å –£–∫—Ä–∞–∏–Ω–æ–π –≤–æ–ø—Ä–æ—Å –æ —Ä–µ—Å—Ç—Ä—É–∫—Ç—É—Ä–∏–∑–∞—Ü–∏–∏ –¥–æ–ª–≥–∞.\\n–¢–µ–º –Ω–µ –º–µ–Ω–µ–µ, –Ω–∞ —Å–µ–≥–æ–¥–Ω—è—à–Ω–∏–π –¥–µ–Ω—å –Ω–µ –∏–∑–≤–µ—Å—Ç–Ω–æ –æ –∫–∞–∫–∏—Ö-–ª–∏–±–æ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ–¥–≤–∏–∂–µ–Ω–∏—è—Ö –≤ —ç—Ç–∏—Ö –ø–µ—Ä–µ–≥–æ–≤–æ—Ä–∞—Ö.\\n\\n\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 3692, 3353, 24972, 672, 35751, 9832, 44422, 5203, 382, 3692, 3353, 2598, 1890, 391, 5203, 382, 3692, 3353, 8447, 2135, 104, 23626, 7302, 75058, 81947, 660, 35188, 11149, 44422, 121, 241, 10843, 162, 197, 197, 217, 412, 126, 196, 412, 126, 70397, 435, 126, 59414, 126, 4979, 197, 24498, 454, 197, 244, 13744, 483, 420, 197, 87447, 107501, 467, 442, 233, 141, 161, 201, 484, 17166, 12131, 242, 8154, 26058, 430, 6438, 240, 660, 798, 42699, 13635, 110870, 13092, 126, 50396, 667, 378, 40729, 1586, 2866, 107, 17179, 667, 378, 1025, 3246, 2866, 2135, 49414, 105174, 20457, 81947, 179, 141, 2757, 2998, 878, 121, 37968, 113, 23959, 151, 721, 53455, 20384, 25959, 110, 20573, 121, 11593, 13680, 12322, 34648, 107, 17273, 34648, 150, 126, 3975, 3071, 104, 119095, 113, 2080, 15407, 75144, 1121, 660, 6171, 168, 2869, 3123, 67899, 121, 862, 378, 6556, 44738, 1890, 376, 703, 1012, 54474, 43784, 649, 2075, 61805, 3840, 113, 6473, 3223, 878, 121, 107, 11593, 6177, 94183, 378, 83827, 6109, 24097, 660, 13747, 6171, 1184, 4818, 2326, 3123, 67899, 126, 9832, 1582, 1247, 376, 378, 113, 168, 2869, 107, 5938, 2326, 18262, 42968, 660, 1778, 2105, 5444, 2081, 905, 1202, 8396, 1096, 708, 3510, 2988, 1763, 878, 126, 934, 45359, 2075, 61805, 3840, 107, 17628, 2245, 113, 1890, 376, 13448, 661, 107, 9019, 672, 6271, 16128, 104, 25675, 11149, 126, 111110, 121, 7943, 1795, 1373, 16148, 31460, 58987, 815, 121, 7042, 672, 35751, 806, 660, 25624, 4252, 126, 849, 1164, 9465, 9965, 113, 6473, 1763, 878, 24511, 6979, 6040, 660, 806, 35188, 126, 3283, 1093, 121, 111110, 10881, 59124, 27346, 21787, 1841, 26725, 16051, 121, 18496, 68568, 972, 3732, 689, 5439, 27007, 681, 9058, 44422, 121, 1623, 46580, 660, 79958, 19513, 126, 16078, 73272, 3854, 1289, 26583, 20621, 794, 86425, 381, 113, 15086, 4090, 24527, 377, 126, 4151, 660, 736, 2900, 2660, 2998, 878, 113, 44422, 1111, 8970, 119373, 6104, 104, 12606, 14227, 110, 94183, 378, 2136, 104, 25675, 11149, 126, 1201, 672, 2482, 121, 660, 5394, 939, 1336, 672, 3043, 104, 4750, 133, 2188, 42953, 29206, 401, 113, 2069, 14122, 126, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_data = train_tokenizer(text)\n",
    "tokenized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['[CLS]',\n",
       "  '–ø–æ—Ä–æ',\n",
       "  '##—à–µ–Ω–∫–æ',\n",
       "  '—Ä–∞–∑—Ä–µ—à–∏–ª',\n",
       "  '–Ω–µ',\n",
       "  '–≤–æ–∑–≤—Ä–∞—â–∞—Ç—å',\n",
       "  '–¥–æ–ª–≥',\n",
       "  '—Ä–æ—Å—Å–∏–∏',\n",
       "  '–ø–µ—Ç',\n",
       "  '##—Ä',\n",
       "  '–ø–æ—Ä–æ',\n",
       "  '##—à–µ–Ω–∫–æ',\n",
       "  '–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç',\n",
       "  '—É–∫—Ä–∞–∏–Ω',\n",
       "  '##—ã',\n",
       "  '–ø–µ—Ç',\n",
       "  '##—Ä',\n",
       "  '–ø–æ—Ä–æ',\n",
       "  '##—à–µ–Ω–∫–æ',\n",
       "  '–ø–æ–¥–ø–∏—Å–∞–ª',\n",
       "  '–∑–∞–∫–æ–Ω',\n",
       "  '–æ',\n",
       "  '–≤–≤–µ–¥–µ–Ω–∏–∏',\n",
       "  '–±–µ—Å—Å',\n",
       "  '##—Ä–æ—á–Ω–æ–≥–æ',\n",
       "  '–º–æ—Ä–∞—Ç–æ—Ä–∏—è',\n",
       "  '–Ω–∞',\n",
       "  '–≤—ã–ø–ª–∞—Ç—É',\n",
       "  '–¥–æ–ª–≥–∞',\n",
       "  '—Ä–æ—Å—Å–∏–∏',\n",
       "  ',',\n",
       "  '[',\n",
       "  'http',\n",
       "  ':',\n",
       "  '/',\n",
       "  '/',\n",
       "  'w',\n",
       "  '##1',\n",
       "  '.',\n",
       "  'c',\n",
       "  '##1',\n",
       "  '.',\n",
       "  'rad',\n",
       "  '##a',\n",
       "  '.',\n",
       "  'gov',\n",
       "  '.',\n",
       "  'ua',\n",
       "  '/',\n",
       "  'pl',\n",
       "  '##s',\n",
       "  '/',\n",
       "  'z',\n",
       "  '##we',\n",
       "  '##b',\n",
       "  '##2',\n",
       "  '/',\n",
       "  'web',\n",
       "  '##pro',\n",
       "  '##c',\n",
       "  '##4',\n",
       "  '_',\n",
       "  '1',\n",
       "  '?',\n",
       "  'p',\n",
       "  '##f',\n",
       "  '##35',\n",
       "  '##11',\n",
       "  '=',\n",
       "  '57',\n",
       "  '##47',\n",
       "  '##9',\n",
       "  '—Å–æ–æ–±—â–∞–µ—Ç—Å—è',\n",
       "  ']',\n",
       "  '–Ω–∞',\n",
       "  '—Å–∞',\n",
       "  '##–∏—Ç–µ',\n",
       "  '–≤–µ—Ä—Ö–æ–≤',\n",
       "  '##–Ω–æ–∏',\n",
       "  '—Ä–∞–¥—ã',\n",
       "  '.',\n",
       "  '–æ–¥–æ–±—Ä–µ–Ω',\n",
       "  '##–Ω—ã',\n",
       "  '##–∏',\n",
       "  '–ø–∞—Ä–ª–∞–º–µ–Ω—Ç–æ–º',\n",
       "  '12',\n",
       "  '–∞–ø—Ä–µ–ª—è',\n",
       "  '–∏',\n",
       "  '–ø–æ–¥–ø–∏—Å–∞–Ω',\n",
       "  '##–Ω—ã',\n",
       "  '##–∏',\n",
       "  '–µ—â–µ',\n",
       "  '29',\n",
       "  '–∞–ø—Ä–µ–ª—è',\n",
       "  '–∑–∞–∫–æ–Ω',\n",
       "  '–æ—Ç–º–µ–Ω—è–µ—Ç',\n",
       "  '–∫–æ–Ω–µ—á–Ω—É—é',\n",
       "  '–¥–∞—Ç—É',\n",
       "  '–º–æ—Ä–∞—Ç–æ—Ä–∏—è',\n",
       "  '‚Äî',\n",
       "  '1',\n",
       "  '–∏—é–ª—è',\n",
       "  '2016',\n",
       "  '–≥–æ–¥–∞',\n",
       "  ',',\n",
       "  '—É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–æ–≥–æ',\n",
       "  '–≤',\n",
       "  '–∑–∞–∫–æ–Ω–µ',\n",
       "  '¬´',\n",
       "  '–æ–±',\n",
       "  '–æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—è—Ö',\n",
       "  '–æ—Å—É—â–µ—Å—Ç–≤–ª–µ–Ω–∏—è',\n",
       "  '—Å–¥–µ–ª–æ–∫',\n",
       "  '—Å',\n",
       "  '–≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã–º',\n",
       "  ',',\n",
       "  '–≥–∞—Ä–∞–Ω—Ç–∏',\n",
       "  '##—Ä–æ–≤–∞–Ω–Ω—ã–º',\n",
       "  '–≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–æ–º',\n",
       "  '–¥–æ–ª–≥–æ–º',\n",
       "  '–∏',\n",
       "  '–º–µ—Å—Ç–Ω—ã–º',\n",
       "  '–¥–æ–ª–≥–æ–º',\n",
       "  '¬ª',\n",
       "  '.',\n",
       "  '—Ä–µ—á—å',\n",
       "  '–∏–¥–µ—Ç',\n",
       "  '–æ',\n",
       "  '–∫—Ä–µ–¥–∏—Ç–µ',\n",
       "  '–≤',\n",
       "  '–≤–∏–¥–µ',\n",
       "  '–ø–æ–∫—É–ø–∫–∏',\n",
       "  '–µ–≤—Ä–æ–±–æ–Ω',\n",
       "  '##–¥–æ–≤',\n",
       "  '–Ω–∞',\n",
       "  '—Å—É–º–º—É',\n",
       "  '3',\n",
       "  '–º–ª—Ä–¥',\n",
       "  '–¥–æ–ª–ª–∞—Ä–æ–≤',\n",
       "  '—Å—à–∞',\n",
       "  ',',\n",
       "  '–∫–æ—Ç–æ—Ä—ã',\n",
       "  '##–∏',\n",
       "  '—Ä–æ—Å—Å–∏—è',\n",
       "  '–≤—ã–¥–∞–ª–∞',\n",
       "  '—É–∫—Ä–∞–∏–Ω',\n",
       "  '##–µ',\n",
       "  '–≤–æ',\n",
       "  '–≤—Ä–µ–º—è',\n",
       "  '–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç—Å—Ç–≤–∞',\n",
       "  '–≤–∏–∫—Ç–æ',\n",
       "  '##—Ä–∞',\n",
       "  '—è–Ω',\n",
       "  '##—É–∫–æ',\n",
       "  '##–≤–∏—á–∞',\n",
       "  '–≤',\n",
       "  '–¥–µ–∫–∞–±—Ä–µ',\n",
       "  '2013',\n",
       "  '–≥–æ–¥–∞',\n",
       "  ',',\n",
       "  '–∏',\n",
       "  '–≥–∞—Ä–∞–Ω—Ç–∏',\n",
       "  '##—Ä–æ–≤–∞–Ω–Ω—ã—Ö',\n",
       "  '—É–∫—Ä–∞–∏–Ω–æ',\n",
       "  '##–∏',\n",
       "  '–¥–æ–ª–≥–∞—Ö',\n",
       "  '–º–µ—Å—Ç–Ω—ã—Ö',\n",
       "  '–ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏–∏',\n",
       "  '–Ω–∞',\n",
       "  '–æ–±—â—É—é',\n",
       "  '—Å—É–º–º—É',\n",
       "  '–±–æ–ª–µ–µ',\n",
       "  '500',\n",
       "  '–º–ª–Ω',\n",
       "  '–¥–æ–ª–ª–∞—Ä–æ–≤',\n",
       "  '—Å—à–∞',\n",
       "  '.',\n",
       "  '–¥–æ–ª–≥',\n",
       "  '–ø–µ—Ä–µ–¥',\n",
       "  '—Ä–æ—Å—Å–∏',\n",
       "  '##–µ',\n",
       "  '##–∏',\n",
       "  '–≤',\n",
       "  '3',\n",
       "  '–º–ª—Ä–¥',\n",
       "  '–∏',\n",
       "  '75',\n",
       "  '–º–ª–Ω',\n",
       "  '–Ω–∞–±–µ',\n",
       "  '##–∂–∞–≤—à–∏—Ö',\n",
       "  '–Ω–∞',\n",
       "  '—Ç–æ—Ç',\n",
       "  '–º–æ–º–µ–Ω—Ç',\n",
       "  '–ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤',\n",
       "  '–¥–æ–ª–∂–µ–Ω',\n",
       "  '–±—ã–ª',\n",
       "  '–±—ã—Ç—å',\n",
       "  '–ø–æ–≥–∞',\n",
       "  '##—à–µ–Ω',\n",
       "  '–¥–æ',\n",
       "  '31',\n",
       "  '–¥–µ–∫–∞–±—Ä—è',\n",
       "  '2015',\n",
       "  '–≥–æ–¥–∞',\n",
       "  '.',\n",
       "  '–ø–æ—Å–ª–µ',\n",
       "  '–±–µ–≥—Å—Ç–≤–∞',\n",
       "  '—è–Ω',\n",
       "  '##—É–∫–æ',\n",
       "  '##–≤–∏—á–∞',\n",
       "  '–∏',\n",
       "  '—Å–º–µ–Ω—ã',\n",
       "  '–≤–ª–∞—Å—Ç–∏',\n",
       "  '–≤',\n",
       "  '—É–∫—Ä–∞–∏–Ω',\n",
       "  '##–µ',\n",
       "  '–º–æ—Å–∫',\n",
       "  '##–≤–∞',\n",
       "  '–∏',\n",
       "  '–∫–∏–µ–≤',\n",
       "  '–Ω–µ',\n",
       "  '—Å–º–æ–≥–ª–∏',\n",
       "  '–¥–æ–≥–æ–≤–æ—Ä–∏—Ç—å—Å—è',\n",
       "  '–æ',\n",
       "  '—Ä–µ—Å—Ç—Ä—É–∫—Ç—É—Ä–∏–∑–∞—Ü–∏–∏',\n",
       "  '–¥–æ–ª–≥–∞',\n",
       "  '.',\n",
       "  '—É–∫—Ä–∞–∏–Ω–∞',\n",
       "  ',',\n",
       "  '—Å—á–∏—Ç–∞—é',\n",
       "  '##—â–∞—è',\n",
       "  '—ç—Ç–æ—Ç',\n",
       "  '–∫—Ä–µ–¥–∏—Ç',\n",
       "  '–ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–∏',\n",
       "  '–æ–±—É—Å–ª–æ–≤–ª–µ–Ω',\n",
       "  '##–Ω—ã–º',\n",
       "  ',',\n",
       "  '—Ä–µ—à–∏–ª–∞',\n",
       "  '–Ω–µ',\n",
       "  '–≤–æ–∑–≤—Ä–∞—â–∞—Ç—å',\n",
       "  '–µ–≥–æ',\n",
       "  '–Ω–∞',\n",
       "  '–ø—Ä–µ–∂–Ω–∏—Ö',\n",
       "  '—É—Å–ª–æ–≤–∏—è—Ö',\n",
       "  '.',\n",
       "  '–¥–ª—è',\n",
       "  '—ç—Ç–æ–≥–æ',\n",
       "  '–∫–∞–±–∏–Ω–µ—Ç',\n",
       "  '–º–∏–Ω–∏—Å—Ç—Ä–æ–≤',\n",
       "  '–≤',\n",
       "  '–¥–µ–∫–∞–±—Ä–µ',\n",
       "  '2015',\n",
       "  '–≥–æ–¥–∞',\n",
       "  '–≤–≤–µ–ª',\n",
       "  '–º–æ—Ä–∞',\n",
       "  '##—Ç–æ—Ä–∏–∏',\n",
       "  '–Ω–∞',\n",
       "  '–µ–≥–æ',\n",
       "  '–≤—ã–ø–ª–∞—Ç—É',\n",
       "  '.',\n",
       "  '–∫—Ä–æ–º–µ',\n",
       "  '—Ç–æ–≥–æ',\n",
       "  ',',\n",
       "  '—É–∫—Ä–∞–∏–Ω–∞',\n",
       "  '–ø—Ä–æ–≤–µ–ª–∞',\n",
       "  '—Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω—É—é',\n",
       "  '—Ä–∞—Å—á–∏',\n",
       "  '##—Å—Ç–∫—É',\n",
       "  '—Å–≤–æ–∏—Ö',\n",
       "  '–∫—Ä–µ–¥–∏—Ç–Ω—ã—Ö',\n",
       "  '–æ–±—è–∑–∞—Ç–µ–ª—å—Å—Ç–≤',\n",
       "  ',',\n",
       "  '—Ä–µ—Å—Ç—Ä—É–∫—Ç—É—Ä–∏',\n",
       "  '##–∑–∏—Ä–æ–≤–∞–≤',\n",
       "  '–∏—Ö',\n",
       "  '–ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏',\n",
       "  '—Å–æ',\n",
       "  '–≤—Å–µ–º–∏',\n",
       "  '—Å—Ç–æ—Ä–æ–Ω–∞–º–∏',\n",
       "  '–∑–∞',\n",
       "  '–∏—Å–∫–ª—é—á–µ–Ω–∏–µ–º',\n",
       "  '—Ä–æ—Å—Å–∏–∏',\n",
       "  ',',\n",
       "  '–∫–æ—Ç–æ—Ä–∞—è',\n",
       "  '–Ω–∞—Å—Ç–∞–∏–≤–∞–ª–∞',\n",
       "  '–Ω–∞',\n",
       "  '—ç–∫—Å–∫–ª—é–∑–∏–≤–Ω–æ–º',\n",
       "  '—Å—Ç–∞—Ç—É—Å–µ',\n",
       "  '.',\n",
       "  '–¥–æ–ª–≥–æ–≤',\n",
       "  '##–æ–∏',\n",
       "  '—Å–ø–æ—Ä',\n",
       "  '–º–µ–∂–¥—É',\n",
       "  '–≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–∞–º–∏',\n",
       "  '—Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç—Å—è',\n",
       "  '—Å–µ',\n",
       "  '##–∏—á–∞',\n",
       "  '##—Å',\n",
       "  '–≤',\n",
       "  '–≤—ã—Å–æ–∫–æ–º',\n",
       "  '—Å—É–¥–µ',\n",
       "  '–ª–æ–Ω–¥–æ–Ω',\n",
       "  '##–∞',\n",
       "  '.',\n",
       "  '–Ω–µ—Å–º–æ—Ç—Ä—è',\n",
       "  '–Ω–∞',\n",
       "  '—ç—Ç–æ',\n",
       "  '26',\n",
       "  '—Ñ–µ–≤—Ä–∞–ª—è',\n",
       "  '2016',\n",
       "  '–≥–æ–¥–∞',\n",
       "  '–≤',\n",
       "  '—Ä–æ—Å—Å–∏–∏',\n",
       "  '##—Å–∫–æ–º',\n",
       "  '–º–∏–Ω',\n",
       "  '##—Ñ–∏–Ω–µ',\n",
       "  '–∑–∞—è–≤–∏–ª–∏',\n",
       "  '–æ',\n",
       "  '–≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏',\n",
       "  '–æ–±—Å—É–∂–¥–∞—Ç—å',\n",
       "  '—Å',\n",
       "  '—É–∫—Ä–∞–∏–Ω–æ',\n",
       "  '##–∏',\n",
       "  '–≤–æ–ø—Ä–æ—Å',\n",
       "  '–æ',\n",
       "  '—Ä–µ—Å—Ç—Ä—É–∫—Ç—É—Ä–∏–∑–∞—Ü–∏–∏',\n",
       "  '–¥–æ–ª–≥–∞',\n",
       "  '.',\n",
       "  '—Ç–µ–º',\n",
       "  '–Ω–µ',\n",
       "  '–º–µ–Ω–µ–µ',\n",
       "  ',',\n",
       "  '–Ω–∞',\n",
       "  '—Å–µ–≥–æ–¥–Ω—è—à',\n",
       "  '##–Ω–∏–∏',\n",
       "  '–¥–µ–Ω—å',\n",
       "  '–Ω–µ',\n",
       "  '–∏–∑–≤–µ—Å—Ç–Ω–æ',\n",
       "  '–æ',\n",
       "  '–∫–∞–∫–∏—Ö',\n",
       "  '-',\n",
       "  '–ª–∏–±–æ',\n",
       "  '–ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö',\n",
       "  '–ø—Ä–æ–¥–≤–∏–∂–µ–Ω–∏—è',\n",
       "  '##—Ö',\n",
       "  '–≤',\n",
       "  '—ç—Ç–∏—Ö',\n",
       "  '–ø–µ—Ä–µ–≥–æ–≤–æ—Ä–∞—Ö',\n",
       "  '.',\n",
       "  '[SEP]'],\n",
       " ['O',\n",
       "  'B-PERSON',\n",
       "  'B-PERSON',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B-COUNTRY',\n",
       "  'B-PERSON',\n",
       "  'B-PERSON',\n",
       "  'I-PERSON',\n",
       "  'I-PERSON',\n",
       "  'B-PROFESSION',\n",
       "  'B-COUNTRY',\n",
       "  'B-COUNTRY',\n",
       "  'B-PERSON',\n",
       "  'B-PERSON',\n",
       "  'I-PERSON',\n",
       "  'I-PERSON',\n",
       "  'B-EVENT',\n",
       "  'I-EVENT',\n",
       "  'I-LAW',\n",
       "  'I-LAW',\n",
       "  'I-LAW',\n",
       "  'I-LAW',\n",
       "  'I-LAW',\n",
       "  'I-LAW',\n",
       "  'I-LAW',\n",
       "  'I-LAW',\n",
       "  'B-COUNTRY',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B-ORGANIZATION',\n",
       "  'B-ORGANIZATION',\n",
       "  'I-ORGANIZATION',\n",
       "  'O',\n",
       "  'B-EVENT',\n",
       "  'B-EVENT',\n",
       "  'B-EVENT',\n",
       "  'B-ORGANIZATION',\n",
       "  'B-DATE',\n",
       "  'I-DATE',\n",
       "  'O',\n",
       "  'B-EVENT',\n",
       "  'B-EVENT',\n",
       "  'B-EVENT',\n",
       "  'O',\n",
       "  'B-DATE',\n",
       "  'I-DATE',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B-EVENT',\n",
       "  'O',\n",
       "  'B-DATE',\n",
       "  'I-DATE',\n",
       "  'I-DATE',\n",
       "  'I-DATE',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B-LAW',\n",
       "  'I-LAW',\n",
       "  'I-LAW',\n",
       "  'I-LAW',\n",
       "  'I-LAW',\n",
       "  'I-LAW',\n",
       "  'I-LAW',\n",
       "  'I-LAW',\n",
       "  'I-LAW',\n",
       "  'I-LAW',\n",
       "  'I-LAW',\n",
       "  'I-LAW',\n",
       "  'I-LAW',\n",
       "  'I-LAW',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B-EVENT',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B-EVENT',\n",
       "  'I-EVENT',\n",
       "  'I-EVENT',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B-MONEY',\n",
       "  'I-MONEY',\n",
       "  'I-MONEY',\n",
       "  'I-MONEY',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B-COUNTRY',\n",
       "  'O',\n",
       "  'B-COUNTRY',\n",
       "  'B-COUNTRY',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B-PROFESSION',\n",
       "  'B-PERSON',\n",
       "  'B-PERSON',\n",
       "  'I-PERSON',\n",
       "  'I-PERSON',\n",
       "  'I-PERSON',\n",
       "  'B-DATE',\n",
       "  'I-DATE',\n",
       "  'I-DATE',\n",
       "  'I-DATE',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B-COUNTRY',\n",
       "  'B-COUNTRY',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B-MONEY',\n",
       "  'I-MONEY',\n",
       "  'I-MONEY',\n",
       "  'I-MONEY',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B-COUNTRY',\n",
       "  'B-COUNTRY',\n",
       "  'B-COUNTRY',\n",
       "  'B-MONEY',\n",
       "  'B-MONEY',\n",
       "  'I-MONEY',\n",
       "  'O',\n",
       "  'B-MONEY',\n",
       "  'I-MONEY',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B-DATE',\n",
       "  'I-DATE',\n",
       "  'I-DATE',\n",
       "  'I-DATE',\n",
       "  'I-DATE',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B-EVENT',\n",
       "  'B-PERSON',\n",
       "  'B-PERSON',\n",
       "  'B-PERSON',\n",
       "  'O',\n",
       "  'B-EVENT',\n",
       "  'I-EVENT',\n",
       "  'O',\n",
       "  'B-COUNTRY',\n",
       "  'B-COUNTRY',\n",
       "  'B-CITY',\n",
       "  'B-CITY',\n",
       "  'O',\n",
       "  'B-CITY',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B-EVENT',\n",
       "  'I-EVENT',\n",
       "  'O',\n",
       "  'B-COUNTRY',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B-ORGANIZATION',\n",
       "  'I-ORGANIZATION',\n",
       "  'B-DATE',\n",
       "  'I-DATE',\n",
       "  'I-DATE',\n",
       "  'I-DATE',\n",
       "  'O',\n",
       "  'B-EVENT',\n",
       "  'B-EVENT',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B-COUNTRY',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B-COUNTRY',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B-EVENT',\n",
       "  'B-EVENT',\n",
       "  'I-EVENT',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B-DATE',\n",
       "  'B-DATE',\n",
       "  'B-DATE',\n",
       "  'O',\n",
       "  'B-ORGANIZATION',\n",
       "  'I-ORGANIZATION',\n",
       "  'B-CITY',\n",
       "  'B-CITY',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B-DATE',\n",
       "  'I-DATE',\n",
       "  'I-DATE',\n",
       "  'I-DATE',\n",
       "  'O',\n",
       "  'B-COUNTRY',\n",
       "  'B-COUNTRY',\n",
       "  'B-ORGANIZATION',\n",
       "  'B-ORGANIZATION',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B-COUNTRY',\n",
       "  'B-COUNTRY',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B-EVENT',\n",
       "  'I-EVENT',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B-DATE',\n",
       "  'B-DATE',\n",
       "  'I-DATE',\n",
       "  'I-DATE',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B-EVENT',\n",
       "  'O',\n",
       "  'O'])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(tokenized_data['input_ids']))\n",
    "token_list = train_tokenizer.convert_ids_to_tokens(tokenized_data[\"input_ids\"])\n",
    "predictions, _, _ = trainer.predict([tokenized_data])\n",
    "predictions = np.argmax(predictions, axis=2)[0]\n",
    "res = [id2label[prediction] for prediction in predictions]\n",
    "print(len(res))\n",
    "token_list, res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_tag(tag):\n",
    "    return tag.replace(\" ##–∏\", \"–π\").replace(\" ##\", \"\").replace(\" . \", \".\")\\\n",
    "        .replace(\" ( \", \"(\").replace(\" )\", \")\").replace(\" ) \", \")\").strip().title()\n",
    "\n",
    "\n",
    "def transform_model_output(token_list, token_labels):\n",
    "    tag = \"\"\n",
    "    tag_label = \"\"\n",
    "    tags = []\n",
    "    tag_labels = []\n",
    "\n",
    "    for token, label in zip(token_list, token_labels):\n",
    "        if label == \"O\":\n",
    "            if tag != \"\":\n",
    "                tags.append(transform_tag(tag))\n",
    "                tag_labels.append(tag_label)\n",
    "                tag = \"\"\n",
    "                tag_label = \"\"\n",
    "            continue\n",
    "        if label.startswith(\"B\"):\n",
    "            if tag != \"\":\n",
    "                tags.append(transform_tag(tag))\n",
    "                tag_labels.append(tag_label)\n",
    "                tag = \"\"\n",
    "            tag += (\" \" + token)\n",
    "            tag_label = label[2:]\n",
    "        if label.startswith(\"I\"):\n",
    "            tag += (\" \" + token)\n",
    "\n",
    "    return tags, tag_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['–ü–æ—Ä–æ',\n",
       "  '–®–µ–Ω–∫–æ',\n",
       "  '–†–æ—Å—Å–∏–∏',\n",
       "  '–ü–µ—Ç',\n",
       "  '–† –ü–æ—Ä–æ—à–µ–Ω–∫–æ',\n",
       "  '–ü—Ä–µ–∑–∏–¥–µ–Ω—Ç',\n",
       "  '–£–∫—Ä–∞–∏–Ω',\n",
       "  '–´',\n",
       "  '–ü–µ—Ç',\n",
       "  '–† –ü–æ—Ä–æ—à–µ–Ω–∫–æ',\n",
       "  '–ü–æ–¥–ø–∏—Å–∞–ª –ó–∞–∫–æ–Ω –û –í–≤–µ–¥–µ–Ω–∏–∏ –ë–µ—Å—Å—Ä–æ—á–Ω–æ–≥–æ –ú–æ—Ä–∞—Ç–æ—Ä–∏—è –ù–∞ –í—ã–ø–ª–∞—Ç—É –î–æ–ª–≥–∞',\n",
       "  '–†–æ—Å—Å–∏–∏',\n",
       "  '–í–µ—Ä—Ö–æ–≤',\n",
       "  '–ù–æ–∏ –†–∞–¥—ã',\n",
       "  '–û–¥–æ–±—Ä–µ–Ω',\n",
       "  '–ù—ã',\n",
       "  '–ô',\n",
       "  '–ü–∞—Ä–ª–∞–º–µ–Ω—Ç–æ–º',\n",
       "  '12 –ê–ø—Ä–µ–ª—è',\n",
       "  '–ü–æ–¥–ø–∏—Å–∞–Ω',\n",
       "  '–ù—ã',\n",
       "  '–ô',\n",
       "  '29 –ê–ø—Ä–µ–ª—è',\n",
       "  '–ú–æ—Ä–∞—Ç–æ—Ä–∏—è',\n",
       "  '1 –ò—é–ª—è 2016 –ì–æ–¥–∞',\n",
       "  '–û–± –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—è—Ö –û—Å—É—â–µ—Å—Ç–≤–ª–µ–Ω–∏—è –°–¥–µ–ª–æ–∫ –° –ì–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã–º , –ì–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –ì–æ—Å—É–¥–∞—Ä—Å—Ç–≤–æ–º –î–æ–ª–≥–æ–º –ò –ú–µ—Å—Ç–Ω—ã–º –î–æ–ª–≥–æ–º',\n",
       "  '–ö—Ä–µ–¥–∏—Ç–µ',\n",
       "  '–ü–æ–∫—É–ø–∫–∏ –ï–≤—Ä–æ–±–æ–Ω–¥–æ–≤',\n",
       "  '3 –ú–ª—Ä–¥ –î–æ–ª–ª–∞—Ä–æ–≤ –°—à–∞',\n",
       "  '–†–æ—Å—Å–∏—è',\n",
       "  '–£–∫—Ä–∞–∏–Ω',\n",
       "  '–ï',\n",
       "  '–ü—Ä–µ–∑–∏–¥–µ–Ω—Ç—Å—Ç–≤–∞',\n",
       "  '–í–∏–∫—Ç–æ',\n",
       "  '–†–∞ –Ø–Ω—É–∫–æ–≤–∏—á–∞',\n",
       "  '–í –î–µ–∫–∞–±—Ä–µ 2013 –ì–æ–¥–∞',\n",
       "  '–£–∫—Ä–∞–∏–Ω–æ',\n",
       "  '–ô',\n",
       "  '500 –ú–ª–Ω –î–æ–ª–ª–∞—Ä–æ–≤ –°—à–∞',\n",
       "  '–†–æ—Å—Å–∏',\n",
       "  '–ï',\n",
       "  '–ô',\n",
       "  '–í',\n",
       "  '3 –ú–ª—Ä–¥',\n",
       "  '75 –ú–ª–Ω',\n",
       "  '–î–æ 31 –î–µ–∫–∞–±—Ä—è 2015 –ì–æ–¥–∞',\n",
       "  '–ë–µ–≥—Å—Ç–≤–∞',\n",
       "  '–Ø–Ω',\n",
       "  '–£–∫–æ',\n",
       "  '–í–∏—á–∞',\n",
       "  '–°–º–µ–Ω—ã –í–ª–∞—Å—Ç–∏',\n",
       "  '–£–∫—Ä–∞–∏–Ω',\n",
       "  '–ï',\n",
       "  '–ú–æ—Å–∫',\n",
       "  '–í–∞',\n",
       "  '–ö–∏–µ–≤',\n",
       "  '–†–µ—Å—Ç—Ä—É–∫—Ç—É—Ä–∏–∑–∞—Ü–∏–∏ –î–æ–ª–≥–∞',\n",
       "  '–£–∫—Ä–∞–∏–Ω–∞',\n",
       "  '–ö–∞–±–∏–Ω–µ—Ç –ú–∏–Ω–∏—Å—Ç—Ä–æ–≤',\n",
       "  '–í –î–µ–∫–∞–±—Ä–µ 2015 –ì–æ–¥–∞',\n",
       "  '–ú–æ—Ä–∞',\n",
       "  '–¢–æ—Ä–∏–∏',\n",
       "  '–£–∫—Ä–∞–∏–Ω–∞',\n",
       "  '–†–æ—Å—Å–∏–∏',\n",
       "  '–î–æ–ª–≥–æ–≤',\n",
       "  '–û–∏ –°–ø–æ—Ä',\n",
       "  '–°–µ',\n",
       "  '–ô—á–∞',\n",
       "  '–°',\n",
       "  '–í—ã—Å–æ–∫–æ–º –°—É–¥–µ',\n",
       "  '–õ–æ–Ω–¥–æ–Ω',\n",
       "  '–ê',\n",
       "  '26 –§–µ–≤—Ä–∞–ª—è 2016 –ì–æ–¥–∞',\n",
       "  '–†–æ—Å—Å–∏–∏',\n",
       "  '–°–∫–æ–º',\n",
       "  '–ú–∏–Ω',\n",
       "  '–§–∏–Ω–µ',\n",
       "  '–£–∫—Ä–∞–∏–Ω–æ',\n",
       "  '–ô',\n",
       "  '–†–µ—Å—Ç—Ä—É–∫—Ç—É—Ä–∏–∑–∞—Ü–∏–∏ –î–æ–ª–≥–∞',\n",
       "  '–ù–∞',\n",
       "  '–°–µ–≥–æ–¥–Ω—è—à–Ω–∏–∏ –î–µ–Ω—å',\n",
       "  '–ü–µ—Ä–µ–≥–æ–≤–æ—Ä–∞—Ö'],\n",
       " ['PERSON',\n",
       "  'PERSON',\n",
       "  'COUNTRY',\n",
       "  'PERSON',\n",
       "  'PERSON',\n",
       "  'PROFESSION',\n",
       "  'COUNTRY',\n",
       "  'COUNTRY',\n",
       "  'PERSON',\n",
       "  'PERSON',\n",
       "  'EVENT',\n",
       "  'COUNTRY',\n",
       "  'ORGANIZATION',\n",
       "  'ORGANIZATION',\n",
       "  'EVENT',\n",
       "  'EVENT',\n",
       "  'EVENT',\n",
       "  'ORGANIZATION',\n",
       "  'DATE',\n",
       "  'EVENT',\n",
       "  'EVENT',\n",
       "  'EVENT',\n",
       "  'DATE',\n",
       "  'EVENT',\n",
       "  'DATE',\n",
       "  'LAW',\n",
       "  'EVENT',\n",
       "  'EVENT',\n",
       "  'MONEY',\n",
       "  'COUNTRY',\n",
       "  'COUNTRY',\n",
       "  'COUNTRY',\n",
       "  'PROFESSION',\n",
       "  'PERSON',\n",
       "  'PERSON',\n",
       "  'DATE',\n",
       "  'COUNTRY',\n",
       "  'COUNTRY',\n",
       "  'MONEY',\n",
       "  'COUNTRY',\n",
       "  'COUNTRY',\n",
       "  'COUNTRY',\n",
       "  'MONEY',\n",
       "  'MONEY',\n",
       "  'MONEY',\n",
       "  'DATE',\n",
       "  'EVENT',\n",
       "  'PERSON',\n",
       "  'PERSON',\n",
       "  'PERSON',\n",
       "  'EVENT',\n",
       "  'COUNTRY',\n",
       "  'COUNTRY',\n",
       "  'CITY',\n",
       "  'CITY',\n",
       "  'CITY',\n",
       "  'EVENT',\n",
       "  'COUNTRY',\n",
       "  'ORGANIZATION',\n",
       "  'DATE',\n",
       "  'EVENT',\n",
       "  'EVENT',\n",
       "  'COUNTRY',\n",
       "  'COUNTRY',\n",
       "  'EVENT',\n",
       "  'EVENT',\n",
       "  'DATE',\n",
       "  'DATE',\n",
       "  'DATE',\n",
       "  'ORGANIZATION',\n",
       "  'CITY',\n",
       "  'CITY',\n",
       "  'DATE',\n",
       "  'COUNTRY',\n",
       "  'COUNTRY',\n",
       "  'ORGANIZATION',\n",
       "  'ORGANIZATION',\n",
       "  'COUNTRY',\n",
       "  'COUNTRY',\n",
       "  'EVENT',\n",
       "  'DATE',\n",
       "  'DATE',\n",
       "  'EVENT'])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_list, res = transform_model_output(token_list, res)\n",
    "token_list, res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'f1': 0.863608568223612}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions, labels, b = trainer.predict(tokenized_datasets[\"dev\"])\n",
    "predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "# Remove ignored index (special tokens)\n",
    "true_predictions = [\n",
    "   [p for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "true_labels = [\n",
    "    [l for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "\n",
    "m = MultiLabelBinarizer().fit(true_labels)\n",
    "\n",
    "results = {\n",
    "    \"f1\": f1_score(m.transform(true_predictions), m.transform(true_labels), average='macro'),\n",
    "}\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[   101,   3692,   3353,  24972,    672,  35751,   9832,  44422,   5203,\n",
      "            382,   3692,   3353,   2598,   1890,    391,   5203,    382,   3692,\n",
      "           3353,   8447,   2135,    104,  23626,   7302,  75058,  81947,    660,\n",
      "          35188,  11149,  44422,    121,    241,  10843,    162,    197,    197,\n",
      "            217,    412,    126,    196,    412,    126,  70397,    435,    126,\n",
      "          59414,    126,   4979,    197,  24498,    454,    197,    244,  13744,\n",
      "            483,    420,    197,  87447, 107501,    467,    442,    233,    141,\n",
      "            161,    201,    484,  17166,  12131,    242,   8154,  26058,    430,\n",
      "           6438,    240,    660,    798,  42699,  13635, 110870,  13092,    126,\n",
      "          50396,    667,    378,  40729,   1586,   2866,    107,  17179,    667,\n",
      "            378,   1025,   3246,   2866,   2135,  49414, 105174,  20457,  81947,\n",
      "            179,    141,   2757,   2998,    878,    121,  37968,    113,  23959,\n",
      "            151,    721,  53455,  20384,  25959,    110,  20573,    121,  11593,\n",
      "          13680,  12322,  34648,    107,  17273,  34648,    150,    126,   3975,\n",
      "           3071,    104, 119095,    113,   2080,  15407,  75144,   1121,    660,\n",
      "           6171,    168,   2869,   3123,  67899,    121,    862,    378,   6556,\n",
      "          44738,   1890,    376,    703,   1012,  54474,  43784,    649,   2075,\n",
      "          61805,   3840,    113,   6473,   3223,    878,    121,    107,  11593,\n",
      "           6177,  94183,    378,  83827,   6109,  24097,    660,  13747,   6171,\n",
      "           1184,   4818,   2326,   3123,  67899,    126,   9832,   1582,   1247,\n",
      "            376,    378,    113,    168,   2869,    107,   5938,   2326,  18262,\n",
      "          42968,    660,   1778,   2105,   5444,   2081,    905,   1202,   8396,\n",
      "           1096,    708,   3510,   2988,   1763,    878,    126,    934,  45359,\n",
      "           2075,  61805,   3840,    107,  17628,   2245,    113,   1890,    376,\n",
      "          13448,    661,    107,   9019,    672,   6271,  16128,    104,  25675,\n",
      "          11149,    126, 111110,    121,   7943,   1795,   1373,  16148,  31460,\n",
      "          58987,    815,    121,   7042,    672,  35751,    806,    660,  25624,\n",
      "           4252,    126,    849,   1164,   9465,   9965,    113,   6473,   1763,\n",
      "            878,  24511,   6979,   6040,    660,    806,  35188,    126,   3283,\n",
      "           1093,    121, 111110,  10881,  59124,  27346,  21787,   1841,  26725,\n",
      "          16051,    121,  18496,  68568,    972,   3732,    689,   5439,  27007,\n",
      "            681,   9058,  44422,    121,   1623,  46580,    660,  79958,  19513,\n",
      "            126,  16078,  73272,   3854,   1289,  26583,  20621,    794,  86425,\n",
      "            381,    113,  15086,   4090,  24527,    377,    126,   4151,    660,\n",
      "            736,   2900,   2660,   2998,    878,    113,  44422,   1111,   8970,\n",
      "         119373,   6104,    104,  12606,  14227,    110,  94183,    378,   2136,\n",
      "            104,  25675,  11149,    126,   1201,    672,   2482,    121,    660,\n",
      "           5394,    939,   1336,    672,   3043,    104,   4750,    133,   2188,\n",
      "          42953,  29206,    401,    113,   2069,  14122,    126,    102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper__index_select)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-90-528eab9b62f2>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;32mwith\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mno_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m     \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      8\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0mpredicted_labels\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0margmax\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moutputs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlogits\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdim\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msqueeze\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtolist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1192\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1195\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1196\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m   1765\u001B[0m             \u001B[0moutput_attentions\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0moutput_attentions\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1766\u001B[0m             \u001B[0moutput_hidden_states\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0moutput_hidden_states\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1767\u001B[0;31m             \u001B[0mreturn_dict\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mreturn_dict\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1768\u001B[0m         )\n\u001B[1;32m   1769\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1192\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1195\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1196\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m   1016\u001B[0m             \u001B[0mtoken_type_ids\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtoken_type_ids\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1017\u001B[0m             \u001B[0minputs_embeds\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minputs_embeds\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1018\u001B[0;31m             \u001B[0mpast_key_values_length\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mpast_key_values_length\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1019\u001B[0m         )\n\u001B[1;32m   1020\u001B[0m         encoder_outputs = self.encoder(\n",
      "\u001B[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1192\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1195\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1196\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.7/site-packages/lsg_converter/bert/modeling_lsg_bert.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001B[0m\n\u001B[1;32m    436\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    437\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0minputs_embeds\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 438\u001B[0;31m             \u001B[0minputs_embeds\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mword_embeddings\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput_ids\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    439\u001B[0m         \u001B[0mtoken_type_embeddings\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtoken_type_embeddings\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtoken_type_ids\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m:\u001B[0m\u001B[0mseq_length\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    440\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1192\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1195\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1196\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/sparse.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    160\u001B[0m         return F.embedding(\n\u001B[1;32m    161\u001B[0m             \u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpadding_idx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmax_norm\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 162\u001B[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001B[0m\u001B[1;32m    163\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    164\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mextra_repr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.7/site-packages/torch/nn/functional.py\u001B[0m in \u001B[0;36membedding\u001B[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001B[0m\n\u001B[1;32m   2208\u001B[0m         \u001B[0;31m# remove once script supports set_grad_enabled\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2209\u001B[0m         \u001B[0m_no_grad_embedding_renorm_\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmax_norm\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnorm_type\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2210\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0membedding\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpadding_idx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mscale_grad_by_freq\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msparse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2211\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2212\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper__index_select)"
     ]
    }
   ],
   "source": [
    "inputs = train_tokenizer(text, return_tensors=\"pt\")\n",
    "inputs = {k: v.to(\"cpu\") for k, v in inputs.items()}\n",
    "\n",
    "print(inputs)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "predicted_labels = torch.argmax(outputs.logits, dim=2).squeeze().tolist()\n",
    "\n",
    "token_list = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"].squeeze().tolist())\n",
    "\n",
    "token_labels = [model.config.id2label[label_id] for label_id in predicted_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XLfJSn-KYoUw"
   },
   "source": [
    "You can now upload the result of the training to the Hub, just execute this instruction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "QWwDBfzNYoUw"
   },
   "outputs": [],
   "source": [
    "# trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "otWUEziQYoUw"
   },
   "source": [
    "You can now share this model with all your friends, family, favorite pets: they can all load it with the identifier `\"your-username/the-name-you-picked\"` so for instance:\n",
    "\n",
    "```python\n",
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"sgugger/my-awesome-model\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XiRmYXjEYoUw"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Token Classification",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
