{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X4cRE8IbIrIV"
   },
   "source": [
    "If you're opening this Notebook on colab, you will probably need to install 🤗 Transformers and 🤗 Datasets. Uncomment the following cell and run it."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MOsHUjgdIrIW",
    "ExecuteTime": {
     "end_time": "2024-04-10T09:22:09.436478Z",
     "start_time": "2024-04-10T09:22:06.253438Z"
    }
   },
   "source": "! pip install datasets transformers seqeval",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /Users/nikolaystepanov/PycharmProjects/NLP/venv/lib/python3.9/site-packages (2.17.1)\r\n",
      "Requirement already satisfied: transformers in /Users/nikolaystepanov/PycharmProjects/NLP/venv/lib/python3.9/site-packages (4.38.2)\r\n",
      "Requirement already satisfied: seqeval in /Users/nikolaystepanov/PycharmProjects/NLP/venv/lib/python3.9/site-packages (1.2.2)\r\n",
      "Requirement already satisfied: filelock in /Users/nikolaystepanov/PycharmProjects/NLP/venv/lib/python3.9/site-packages (from datasets) (3.13.1)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/nikolaystepanov/PycharmProjects/NLP/venv/lib/python3.9/site-packages (from datasets) (1.26.4)\r\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /Users/nikolaystepanov/PycharmProjects/NLP/venv/lib/python3.9/site-packages (from datasets) (15.0.0)\r\n",
      "Requirement already satisfied: pyarrow-hotfix in /Users/nikolaystepanov/PycharmProjects/NLP/venv/lib/python3.9/site-packages (from datasets) (0.6)\r\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/nikolaystepanov/PycharmProjects/NLP/venv/lib/python3.9/site-packages (from datasets) (0.3.8)\r\n",
      "Requirement already satisfied: pandas in /Users/nikolaystepanov/PycharmProjects/NLP/venv/lib/python3.9/site-packages (from datasets) (2.2.1)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/nikolaystepanov/PycharmProjects/NLP/venv/lib/python3.9/site-packages (from datasets) (2.31.0)\r\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/nikolaystepanov/PycharmProjects/NLP/venv/lib/python3.9/site-packages (from datasets) (4.66.2)\r\n",
      "Requirement already satisfied: xxhash in /Users/nikolaystepanov/PycharmProjects/NLP/venv/lib/python3.9/site-packages (from datasets) (3.4.1)\r\n",
      "Requirement already satisfied: multiprocess in /Users/nikolaystepanov/PycharmProjects/NLP/venv/lib/python3.9/site-packages (from datasets) (0.70.16)\r\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /Users/nikolaystepanov/PycharmProjects/NLP/venv/lib/python3.9/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets) (2023.10.0)\r\n",
      "Requirement already satisfied: aiohttp in /Users/nikolaystepanov/PycharmProjects/NLP/venv/lib/python3.9/site-packages (from datasets) (3.9.3)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /Users/nikolaystepanov/PycharmProjects/NLP/venv/lib/python3.9/site-packages (from datasets) (0.20.3)\r\n",
      "Requirement already satisfied: packaging in /Users/nikolaystepanov/PycharmProjects/NLP/venv/lib/python3.9/site-packages (from datasets) (23.2)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/nikolaystepanov/PycharmProjects/NLP/venv/lib/python3.9/site-packages (from datasets) (6.0.1)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/nikolaystepanov/PycharmProjects/NLP/venv/lib/python3.9/site-packages (from transformers) (2023.12.25)\r\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/nikolaystepanov/PycharmProjects/NLP/venv/lib/python3.9/site-packages (from transformers) (0.15.2)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/nikolaystepanov/PycharmProjects/NLP/venv/lib/python3.9/site-packages (from transformers) (0.4.2)\r\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /Users/nikolaystepanov/PycharmProjects/NLP/venv/lib/python3.9/site-packages (from seqeval) (1.4.1.post1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/nikolaystepanov/PycharmProjects/NLP/venv/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.1)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/nikolaystepanov/PycharmProjects/NLP/venv/lib/python3.9/site-packages (from aiohttp->datasets) (23.2.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/nikolaystepanov/PycharmProjects/NLP/venv/lib/python3.9/site-packages (from aiohttp->datasets) (1.4.1)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/nikolaystepanov/PycharmProjects/NLP/venv/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.5)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/nikolaystepanov/PycharmProjects/NLP/venv/lib/python3.9/site-packages (from aiohttp->datasets) (1.9.4)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Users/nikolaystepanov/PycharmProjects/NLP/venv/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.3)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/nikolaystepanov/PycharmProjects/NLP/venv/lib/python3.9/site-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/nikolaystepanov/PycharmProjects/NLP/venv/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nikolaystepanov/PycharmProjects/NLP/venv/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/nikolaystepanov/PycharmProjects/NLP/venv/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2.2.1)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nikolaystepanov/PycharmProjects/NLP/venv/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\r\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/nikolaystepanov/PycharmProjects/NLP/venv/lib/python3.9/site-packages (from scikit-learn>=0.21.3->seqeval) (1.12.0)\r\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/nikolaystepanov/PycharmProjects/NLP/venv/lib/python3.9/site-packages (from scikit-learn>=0.21.3->seqeval) (1.3.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/nikolaystepanov/PycharmProjects/NLP/venv/lib/python3.9/site-packages (from scikit-learn>=0.21.3->seqeval) (3.3.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/nikolaystepanov/PycharmProjects/NLP/venv/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/nikolaystepanov/PycharmProjects/NLP/venv/lib/python3.9/site-packages (from pandas->datasets) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/nikolaystepanov/PycharmProjects/NLP/venv/lib/python3.9/site-packages (from pandas->datasets) (2024.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/nikolaystepanov/PycharmProjects/NLP/venv/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\r\n"
     ]
    }
   ],
   "execution_count": 249
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZQ9oei3PYoUi"
   },
   "source": [
    "If you're opening this notebook locally, make sure your environment has an install from the last version of those libraries.\n",
    "\n",
    "To be able to share your model with the community and generate results like the one shown in the picture below via the inference API, there are a few more steps to follow.\n",
    "\n",
    "First you have to store your authentication token from the Hugging Face website (sign up [here](https://huggingface.co/join) if you haven't already!) then execute the following cell and input your username and password:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zNZJzDgFYoUj",
    "ExecuteTime": {
     "end_time": "2024-04-10T09:22:09.742491Z",
     "start_time": "2024-04-10T09:22:09.438623Z"
    }
   },
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(\"your_token\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /Users/nikolaystepanov/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "execution_count": 250
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r0kWpldrYoUj"
   },
   "source": [
    "Then you need to install Git-LFS. Uncomment the following instructions:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UogHw1uOYoUj",
    "ExecuteTime": {
     "end_time": "2024-04-10T09:22:09.755987Z",
     "start_time": "2024-04-10T09:22:09.746984Z"
    }
   },
   "source": [
    "# !apt install git-lfs"
   ],
   "outputs": [],
   "execution_count": 251
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wBhatPuGYoUk"
   },
   "source": [
    "Make sure your version of Transformers is at least 4.11.0 since the functionality was introduced in that version:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "48_bU0zVYoUk",
    "ExecuteTime": {
     "end_time": "2024-04-10T09:22:09.767499Z",
     "start_time": "2024-04-10T09:22:09.762223Z"
    }
   },
   "source": [
    "import transformers\n",
    "\n",
    "print(transformers.__version__)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.38.2\n"
     ]
    }
   ],
   "execution_count": 252
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HFASsisvIrIb"
   },
   "source": [
    "You can find a script version of this notebook to fine-tune your model in a distributed fashion using multiple GPUs or TPUs [here](https://github.com/huggingface/transformers/tree/master/examples/token-classification)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z0IkEJXkYoUk"
   },
   "source": [
    "We also quickly upload some telemetry - this tells us which examples and software versions are getting used so we know where to prioritize our maintenance efforts. We don't collect (or care about) any personally identifiable information, but if you'd prefer not to be counted, feel free to skip this step or delete this cell entirely."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NO1ubRh8YoUl",
    "ExecuteTime": {
     "end_time": "2024-04-10T09:22:09.776456Z",
     "start_time": "2024-04-10T09:22:09.768710Z"
    }
   },
   "source": [
    "from transformers.utils import send_example_telemetry\n",
    "\n",
    "send_example_telemetry(\"token_classification_notebook\", framework=\"pytorch\")"
   ],
   "outputs": [],
   "execution_count": 253
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rEJBSTyZIrIb"
   },
   "source": [
    "# Fine-tuning a model on a token classification task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mcib0_rLYoUl"
   },
   "source": [
    "In this notebook, we will see how to fine-tune one of the [🤗 Transformers](https://github.com/huggingface/transformers) model to a token classification task, which is the task of predicting a label for each token.\n",
    "\n",
    "![Widget inference representing the NER task](https://github.com/huggingface/notebooks/blob/main/examples/images/token_classification.png?raw=1)\n",
    "\n",
    "The most common token classification tasks are:\n",
    "\n",
    "- NER (Named-entity recognition) Classify the entities in the text (person, organization, location...).\n",
    "- POS (Part-of-speech tagging) Grammatically classify the tokens (noun, verb, adjective...)\n",
    "- Chunk (Chunking) Grammatically classify the tokens and group them into \"chunks\" that go together\n",
    "\n",
    "We will see how to easily load a dataset for these kinds of tasks and use the `Trainer` API to fine-tune a model on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4RRkXuteIrIh"
   },
   "source": [
    "This notebook is built to run on any token classification task, with any model checkpoint from the [Model Hub](https://huggingface.co/models) as long as that model has a version with a token classification head and a fast tokenizer (check on [this table](https://huggingface.co/transformers/index.html#bigtable) if this is the case). It might just need some small adjustments if you decide to use a different dataset than the one used here. Depending on you model and the GPU you are using, you might need to adjust the batch size to avoid out-of-memory errors. Set those three parameters, then the rest of the notebook should run smoothly:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zVvslsfMIrIh",
    "ExecuteTime": {
     "end_time": "2024-04-10T09:22:09.784073Z",
     "start_time": "2024-04-10T09:22:09.779240Z"
    }
   },
   "source": [
    "task = \"ner\" # Should be one of \"ner\", \"pos\" or \"chunk\"\n",
    "model_checkpoint = \"ai-forever/ruBert-base\"\n",
    "batch_size = 16"
   ],
   "outputs": [],
   "execution_count": 254
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whPRbBNbIrIl"
   },
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W7QYTpxXIrIl"
   },
   "source": [
    "We will use the [🤗 Datasets](https://github.com/huggingface/datasets) library to download the data and get the metric we need to use for evaluation (to compare our model to the benchmark). This can be easily done with the functions `load_dataset` and `load_metric`.  "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "IreSlFmlIrIm",
    "ExecuteTime": {
     "end_time": "2024-04-10T09:22:09.791762Z",
     "start_time": "2024-04-10T09:22:09.787607Z"
    }
   },
   "source": [
    "from datasets import load_dataset, load_metric"
   ],
   "outputs": [],
   "execution_count": 255
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CKx2zKs5IrIq"
   },
   "source": [
    "For our example here, we'll use the [CONLL 2003 dataset](https://www.aclweb.org/anthology/W03-0419.pdf). The notebook should work with any token classification dataset provided by the 🤗 Datasets library. If you're using your own dataset defined from a JSON or csv file (see the [Datasets documentation](https://huggingface.co/docs/datasets/loading_datasets.html#from-local-files) on how to load them), it might need some adjustments in the names of the columns used."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270,
     "referenced_widgets": [
      "69caab03d6264fef9fc5649bffff5e20",
      "3f74532faa86412293d90d3952f38c4a",
      "50615aa59c7247c4804ca5cbc7945bd7",
      "fe962391292a413ca55dc932c4279fa7",
      "299f4b4c07654e53a25f8192bd1d7bbd",
      "ad04ed1038154081bbb0c1444784dcc2",
      "7c667ad22b5740d5a6319f1b1e3a8097",
      "46c2b043c0f84806978784a45a4e203b",
      "80e2943be35f46eeb24c8ab13faa6578",
      "de5956b5008d4fdba807bae57509c393",
      "931db1f7a42f4b46b7ff8c2e1262b994",
      "6c1db72efff5476e842c1386fadbbdba",
      "ccd2f37647c547abb4c719b75a26f2de",
      "d30a66df5c0145e79693e09789d96b81",
      "5fa26fc336274073abbd1d550542ee33",
      "2b34de08115d49d285def9269a53f484",
      "d426be871b424affb455aeb7db5e822e",
      "160bf88485f44f5cb6eaeecba5e0901f",
      "745c0d47d672477b9bb0dae77b926364",
      "d22ab78269cd4ccfbcf70c707057c31b",
      "d298eb19eeff453cba51c2804629d3f4",
      "a7204ade36314c86907c562e0a2158b8",
      "e35d42b2d352498ca3fc8530393786b2",
      "75103f83538d44abada79b51a1cec09e",
      "f6253931d90543e9b5fd0bb2d615f73a",
      "051aa783ff9e47e28d1f9584043815f5",
      "0984b2a14115454bbb009df71c1cf36f",
      "8ab9dfce29854049912178941ef1b289",
      "c9de740e007141958545e269372780a4",
      "cbea68b25d6d4ba09b2ce0f27b1726d5",
      "5781fc45cf8d486cb06ed68853b2c644",
      "d2a92143a08a4951b55bab9bc0a6d0d3",
      "a14c3e40e5254d61ba146f6ec88eae25",
      "c4ffe6f624ce4e978a0d9b864544941a",
      "1aca01c1d8c940dfadd3e7144bb35718",
      "9fbbaae50e6743f2aa19342152398186",
      "fea27ca6c9504fc896181bc1ff5730e5",
      "940d00556cb849b3a689d56e274041c2",
      "5cdf9ed939fb42d4bf77301c80b8afca",
      "94b39ccfef0b4b08bf2fb61bb0a657c1",
      "9a55087c85b74ea08b3e952ac1d73cbe",
      "2361ab124daf47cc885ff61f2899b2af",
      "1a65887eb37747ddb75dc4a40f7285f2",
      "3c946e2260704e6c98593136bd32d921",
      "50d325cdb9844f62a9ecc98e768cb5af",
      "aa781f0cfe454e9da5b53b93e9baabd8",
      "6bb68d3887ef43809eb23feb467f9723",
      "7e29a8b952cf4f4ea42833c8bf55342f",
      "dd5997d01d8947e4b1c211433969b89b",
      "2ace4dc78e2f4f1492a181bcd63304e7",
      "bbee008c2791443d8610371d1f16b62b",
      "31b1c8a2e3334b72b45b083688c1a20c",
      "7fb7c36adc624f7dbbcb4a831c1e4f63",
      "0b7c8f1939074794b3d9221244b1344d",
      "a71908883b064e1fbdddb547a8c41743",
      "2f5223f26c8541fc87e91d2205c39995"
     ]
    },
    "id": "s_AY1ATSIrIq",
    "outputId": "fd0578d1-8895-443d-b56f-5908de9f1b6b",
    "ExecuteTime": {
     "end_time": "2024-04-10T09:22:12.238152Z",
     "start_time": "2024-04-10T09:22:09.794070Z"
    }
   },
   "source": "datasets = load_dataset(\"iluvvatar/NEREL\", trust_remote_code=True)",
   "outputs": [],
   "execution_count": 256
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RzfPtOMoIrIu"
   },
   "source": [
    "The `datasets` object itself is [`DatasetDict`](https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasetdict), which contains one key for the training, validation and test set."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GWiVUF0jIrIv",
    "outputId": "35e3ea43-f397-4a54-c90c-f2cf8d36873e",
    "ExecuteTime": {
     "end_time": "2024-04-10T09:22:12.252429Z",
     "start_time": "2024-04-10T09:22:12.243438Z"
    }
   },
   "source": [
    "datasets"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'text', 'entities', 'relations', 'links'],\n",
       "        num_rows: 746\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'text', 'entities', 'relations', 'links'],\n",
       "        num_rows: 93\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['id', 'text', 'entities', 'relations', 'links'],\n",
       "        num_rows: 94\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 257
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9lzzOQLDYoUm"
   },
   "source": [
    "We can see the training, validation and test sets all have a column for the tokens (the input texts split into words) and one column of labels for each kind of task we introduced before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u3EtYfeHIrIz"
   },
   "source": [
    "To access an actual element, you need to select a split first, then give an index:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "X6HrpprwIrIz",
    "outputId": "d7670bc0-42e4-4c09-8a6a-5c018ded7d95",
    "ExecuteTime": {
     "end_time": "2024-04-10T09:22:12.265278Z",
     "start_time": "2024-04-10T09:22:12.254267Z"
    }
   },
   "source": [
    "datasets[\"train\"][0]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'text': 'Пулеметы, автоматы и снайперские винтовки изъяты в арендуемом американцами доме в Бишкеке\\n\\n05/08/2008 10:35\\n\\nБИШКЕК, 5 августа /Новости-Грузия/. Правоохранительные органы Киргизии обнаружили в доме, арендуемом гражданами США в Бишкеке, пулеметы, автоматы и снайперские винтовки, сообщает во вторник пресс-служба МВД Киргизии.\\n\\n\"В ходе проведения оперативно-профилактического мероприятия под кодовым названием \"Арсенал\" в новостройке Ынтымак, в доме, принадлежащем 66-летнему гражданину Киргизии и арендуемом гражданами США, обнаружены и изъяты: шесть крупнокалиберных пулеметов с оптическим прицелом и с приборами ночного видения, 26 автоматов калибра 5,56 миллиметра, два винчестера марки МОСВЕГА 12-го калибра, четыре ствола от крупнокалиберного пулемета, два подствольных гранатомета, четыре снайперские винтовки с оптическим прицелом защитного цвета, шесть пистолетов калибра 9 миллиметров марки Беретта, одна винтовка\", - говорится в сообщении МВД.\\n\\nПресс-служба отмечает, что на момент обыска \"в доме находились несколько сотрудников посольства США, обладающих дипломатическим иммунитетом, и 10 военнослужащих, якобы прибывших из США для проведения тренинга с сотрудниками спецподразделения одной из силовых структур республики, личности которых в настоящее время устанавливаются\".\\n\\nСогласно сообщению, в доме было обнаружено и значительное количество боеприпасов. \"Два ножа, 2920 штук патронов калибра 5,56 миллиметра, 10556 штук патронов калибра 9 миллиметров, два ящика патронов калибра 50 миллиметров, в каждом 350 штук, патроны калибра 12 миллиметров в количестве 478 штук, маркировочные (трассирующие) патроны (красного цвета) 1000 штук, 66 штук пустых магазинов от автоматического оружия, 57 штук пустых магазинов от пистолета Беретта\", - говорится в пресс-релизе.\\n\\nПресс-служба МВД сообщила, что расследование по данному факту проводит прокуратура Бишкека. Сейчас выясняется, кому именно принадлежит изъятое оружие, передает РИА Новости.\\n\\nОружие, изъятое у граждан США правоохранительными органами Киргизии, находилось в республике с ведома правительства Киргизии, сообщил во вторник представитель пресс-службы посольства США.\\n\\n\"Все оборудование находилось на территории Киргизии с ведома и разрешения киргизских властей\", - сказал собеседник агентства. Военнослужащие и оружие \"прибыли в республику по приглашению правительства с целью обеспечения антитеррористических учений для министерств\", заявило американское дипломатическое ведомство.\\n\\n\"Дом и оборудование находились под защитой киргизских властей\", - отмечает пресс-служба.\\n\\nПосольство США считает случившееся \"неприятным инцидентом\" и выражает надежду что \"США и Киргизия могли бы продолжить усилия по улучшению антитеррористических возможностей Киргизии\".\\n\\nПресс-служба американской военной базы расположенной в международном аэропорту \"Манас\" столицы Киргизии отказалась комментировать данный инцидент с участием американских военных.\\n\\n\"Всеми вопросами, связанными с данным случаем, занимается посольство США\", - сообщили РИА Новости в пресс-службе базы.',\n",
       " 'entities': ['T1\\tNATIONALITY 62 74\\tамериканцами',\n",
       "  'T2\\tCITY 82 89\\tБишкеке',\n",
       "  'T3\\tDATE 117 126\\t5 августа',\n",
       "  'T4\\tCOUNTRY 136 142\\tГрузия',\n",
       "  'T5\\tORGANIZATION 145 179\\tПравоохранительные органы Киргизии',\n",
       "  'T6\\tCOUNTRY 171 179\\tКиргизии',\n",
       "  'T7\\tCOUNTRY 221 224\\tСША',\n",
       "  'T8\\tCITY 227 234\\tБишкеке',\n",
       "  'T9\\tDATE 288 298\\tво вторник',\n",
       "  'T10\\tORGANIZATION 312 315\\tМВД',\n",
       "  'T11\\tDATE 91 101\\t05/08/2008',\n",
       "  'T12\\tCITY 433 440\\tЫнтымак',\n",
       "  'T13\\tAGE 464 474\\t66-летнему',\n",
       "  'T14\\tCOUNTRY 486 494\\tКиргизии',\n",
       "  'T15\\tCOUNTRY 519 522\\tСША',\n",
       "  'T16\\tNUMBER 545 550\\tшесть',\n",
       "  'T17\\tNUMBER 631 633\\t26',\n",
       "  'T18\\tNUMBER 652 667\\t5,56 миллиметра',\n",
       "  'T19\\tNUMBER 669 672\\tдва',\n",
       "  'T20\\tPRODUCT 690 697\\tМОСВЕГА',\n",
       "  'T21\\tNUMBER 713 719\\tчетыре',\n",
       "  'T22\\tNUMBER 758 761\\tдва',\n",
       "  'T23\\tNUMBER 788 794\\tчетыре',\n",
       "  'T24\\tNUMBER 855 860\\tшесть',\n",
       "  'T25\\tNUMBER 880 893\\t9 миллиметров',\n",
       "  'T26\\tPRODUCT 900 907\\tБеретта',\n",
       "  'T27\\tNUMBER 909 913\\tодна',\n",
       "  'T28\\tORGANIZATION 949 952\\tМВД',\n",
       "  'T29\\tNUMBER 1098 1100\\t10',\n",
       "  'T30\\tCOUNTRY 1136 1139\\tСША',\n",
       "  'T31\\tNUMBER 1372 1375\\tДва',\n",
       "  'T32\\tNUMBER 1382 1386\\t2920',\n",
       "  'T33\\tNUMBER 1409 1424\\t5,56 миллиметра',\n",
       "  'T34\\tNUMBER 1426 1431\\t10556',\n",
       "  'T35\\tNUMBER 1454 1467\\t9 миллиметров',\n",
       "  'T36\\tNUMBER 1469 1472\\tдва',\n",
       "  'T37\\tNUMBER 1496 1510\\t50 миллиметров',\n",
       "  'T38\\tNUMBER 1521 1524\\t350',\n",
       "  'T39\\tNUMBER 1547 1561\\t12 миллиметров',\n",
       "  'T40\\tNUMBER 1575 1578\\t478',\n",
       "  'T41\\tNUMBER 1639 1643\\t1000',\n",
       "  'T42\\tORGANIZATION 312 324\\tМВД Киргизии',\n",
       "  'T43\\tNUMBER 1650 1652\\t66',\n",
       "  'T44\\tORGANIZATION 1792 1795\\tМВД',\n",
       "  'T45\\tNUMBER 1702 1704\\t57',\n",
       "  'T46\\tPRODUCT 1740 1747\\tБеретта',\n",
       "  'T47\\tORGANIZATION 1779 1795\\tПресс-служба МВД',\n",
       "  'T48\\tORGANIZATION 1850 1861\\tпрокуратура',\n",
       "  'T49\\tORGANIZATION 1939 1950\\tРИА Новости',\n",
       "  'T50\\tCOUNTRY 1979 1982\\tСША',\n",
       "  'T51\\tCOUNTRY 2012 2020\\tКиргизии',\n",
       "  'T52\\tORGANIZATION 2055 2077\\tправительства Киргизии',\n",
       "  'T53\\tDATE 2087 2097\\tво вторник',\n",
       "  'T54\\tORGANIZATION 2216 2234\\tкиргизских властей',\n",
       "  'T55\\tCOUNTRY 2185 2193\\tКиргизии',\n",
       "  'T56\\tCOUNTRY 2216 2226\\tкиргизских',\n",
       "  'T57\\tCOUNTRY 2417 2429\\tамериканское',\n",
       "  'T58\\tCOUNTRY 2501 2511\\tкиргизских',\n",
       "  'T59\\tCITY 2819 2835\\tстолицы Киргизии',\n",
       "  'T60\\tCOUNTRY 2631 2634\\tСША',\n",
       "  'T61\\tCOUNTRY 2637 2645\\tКиргизия',\n",
       "  'T62\\tCOUNTRY 2720 2728\\tКиргизии',\n",
       "  'T63\\tNUMBER 698 711\\t12-го калибра',\n",
       "  'T64\\tFACILITY 2812 2817\\tМанас',\n",
       "  'T65\\tCOUNTRY 2827 2835\\tКиргизии',\n",
       "  'T66\\tCOUNTRY 2889 2901\\tамериканских',\n",
       "  'T67\\tCOUNTRY 2745 2757\\tамериканской',\n",
       "  'T68\\tORGANIZATION 2998 3009\\tРИА Новости',\n",
       "  'T69\\tTIME 91 107\\t05/08/2008 10:35',\n",
       "  'T70\\tEVENT 410 417\\tАрсенал',\n",
       "  'T71\\tCITY 109 115\\tБИШКЕК',\n",
       "  'T72\\tORGANIZATION 128 142\\tНовости-Грузия',\n",
       "  'T73\\tCOUNTRY 316 324\\tКиргизии',\n",
       "  'T74\\tORGANIZATION 299 324\\tпресс-служба МВД Киргизии',\n",
       "  'T75\\tCOUNTRY 1051 1054\\tСША',\n",
       "  'T76\\tORGANIZATION 1040 1054\\tпосольства США',\n",
       "  'T77\\tPROFESSION 1028 1054\\tсотрудников посольства США',\n",
       "  'T78\\tPROFESSION 1101 1115\\tвоеннослужащих',\n",
       "  'T79\\tNATIONALITY 1971 1982\\tграждан США',\n",
       "  'T80\\tPROFESSION 1166 1196\\tсотрудниками спецподразделения',\n",
       "  'T81\\tCOUNTRY 2136 2139\\tСША',\n",
       "  'T82\\tORGANIZATION 1850 1869\\tпрокуратура Бишкека',\n",
       "  'T83\\tCITY 1862 1869\\tБишкека',\n",
       "  'T84\\tTIME 1871 1877\\tСейчас',\n",
       "  'T85\\tORGANIZATION 1983 2020\\tправоохранительными органами Киргизии',\n",
       "  'T86\\tCOUNTRY 2069 2077\\tКиргизии',\n",
       "  'T87\\tORGANIZATION 2125 2139\\tпосольства США',\n",
       "  'T88\\tPROFESSION 2098 2139\\tпредставитель пресс-службы посольства США',\n",
       "  'T89\\tORGANIZATION 2112 2139\\tпресс-службы посольства США',\n",
       "  'T90\\tPROFESSION 2268 2282\\tВоеннослужащие',\n",
       "  'T91\\tORGANIZATION 2395 2406\\tминистерств',\n",
       "  'T92\\tORGANIZATION 2329 2342\\tправительства',\n",
       "  'T93\\tORGANIZATION 2417 2455\\tамериканское дипломатическое ведомство',\n",
       "  'T94\\tORGANIZATION 2430 2455\\tдипломатическое ведомство',\n",
       "  'T95\\tORGANIZATION 2533 2545\\tпресс-служба',\n",
       "  'T96\\tCOUNTRY 2559 2562\\tСША',\n",
       "  'T97\\tORGANIZATION 2548 2562\\tПосольство США',\n",
       "  'T98\\tORGANIZATION 2732 2770\\tПресс-служба американской военной базы',\n",
       "  'T100\\tORGANIZATION 2745 2770\\tамериканской военной базы',\n",
       "  'T101\\tNATIONALITY 475 494\\tгражданину Киргизии',\n",
       "  'T102\\tPROFESSION 2902 2909\\tвоенных',\n",
       "  'T103\\tORGANIZATION 2970 2984\\tпосольство США',\n",
       "  'T104\\tNATIONALITY 210 224\\tгражданами США',\n",
       "  'T105\\tNATIONALITY 508 522\\tгражданами США',\n",
       "  'T106\\tEVENT 524 543\\tобнаружены и изъяты',\n",
       "  'T107\\tORGANIZATION 2501 2519\\tкиргизских властей',\n",
       "  'T108\\tCOUNTRY 2981 2984\\tСША'],\n",
       " 'relations': ['R1\\tTAKES_PLACE_IN Arg1:T70 Arg2:T12',\n",
       "  'R2\\tAGE_IS Arg1:T101 Arg2:T13',\n",
       "  'R3\\tHEADQUARTERED_IN Arg1:T72 Arg2:T4',\n",
       "  'R4\\tHEADQUARTERED_IN Arg1:T5 Arg2:T6',\n",
       "  'R5\\tHEADQUARTERED_IN Arg1:T42 Arg2:T73',\n",
       "  'R6\\tORGANIZES Arg1:T5 Arg2:T70',\n",
       "  'R7\\tLOCATED_IN Arg1:T12 Arg2:T8',\n",
       "  'R8\\tLOCATED_IN Arg1:T8 Arg2:T6',\n",
       "  'R9\\tOWNER_OF Arg1:T101 Arg2:T12',\n",
       "  'R10\\tSUBEVENT_OF Arg1:T106 Arg2:T70',\n",
       "  'R11\\tHEADQUARTERED_IN Arg1:T82 Arg2:T83',\n",
       "  'R12\\tWORKPLACE Arg1:T88 Arg2:T89',\n",
       "  'R13\\tHEADQUARTERED_IN Arg1:T54 Arg2:T56',\n",
       "  'R14\\tALTERNATIVE_NAME Arg1:T56 Arg2:T55',\n",
       "  'R15\\tALTERNATIVE_NAME Arg1:T87 Arg2:T93',\n",
       "  'R16\\tALTERNATIVE_NAME Arg1:T81 Arg2:T57',\n",
       "  'R17\\tALTERNATIVE_NAME Arg1:T93 Arg2:T97',\n",
       "  'R18\\tALTERNATIVE_NAME Arg1:T57 Arg2:T96',\n",
       "  'R19\\tLOCATED_IN Arg1:T64 Arg2:T59',\n",
       "  'R20\\tORIGINS_FROM Arg1:T102 Arg2:T66',\n",
       "  'R21\\tOWNER_OF Arg1:T108 Arg2:T103',\n",
       "  'R22\\tORIGINS_FROM Arg1:T104 Arg2:T7',\n",
       "  'R23\\tALTERNATIVE_NAME Arg1:T1 Arg2:T104',\n",
       "  'R24\\tORIGINS_FROM Arg1:T105 Arg2:T15',\n",
       "  'R25\\tORIGINS_FROM Arg1:T101 Arg2:T14',\n",
       "  'R26\\tWORKPLACE Arg1:T77 Arg2:T76',\n",
       "  'R27\\tPART_OF Arg1:T74 Arg2:T42',\n",
       "  'R28\\tOWNER_OF Arg1:T96 Arg2:T97',\n",
       "  'R29\\tLOCATED_IN Arg1:T59 Arg2:T65',\n",
       "  'R30\\tPART_OF Arg1:T98 Arg2:T100',\n",
       "  'R31\\tOWNER_OF Arg1:T67 Arg2:T100',\n",
       "  'R32\\tOWNER_OF Arg1:T75 Arg2:T76',\n",
       "  'R33\\tPART_OF Arg1:T47 Arg2:T44',\n",
       "  'R34\\tORIGINS_FROM Arg1:T79 Arg2:T50',\n",
       "  'R35\\tHEADQUARTERED_IN Arg1:T93 Arg2:T57',\n",
       "  'R36\\tHEADQUARTERED_IN Arg1:T107 Arg2:T58',\n",
       "  'R37\\tHEADQUARTERED_IN Arg1:T85 Arg2:T51',\n",
       "  'R38\\tHEADQUARTERED_IN Arg1:T52 Arg2:T86'],\n",
       " 'links': ['N1\\tReference T5 Wikidata:Q813\\tКиргизия',\n",
       "  'N2\\tReference T10 Wikidata:Q6589202\\tминистерство внутренних дел',\n",
       "  'N3\\tReference T12 Wikidata:Q13648730\\tЫнтымак',\n",
       "  'N4\\tReference T20 Wikidata:NULL\\t',\n",
       "  'N5\\tReference T46 Wikidata:Q324782\\tBeretta',\n",
       "  'N6\\tReference T47 Wikidata:NULL\\t',\n",
       "  'N7\\tReference T48 Wikidata:Q1092499\\tпрокуратура',\n",
       "  'N8\\tReference T49 Wikidata:Q821172\\tРИА Новости',\n",
       "  'N9\\tReference T52 Wikidata:NULL\\t',\n",
       "  'N10\\tReference T62 Wikidata:Q813\\tКиргизия',\n",
       "  'N11\\tReference T64 Wikidata:Q32997\\tМанас',\n",
       "  'N12\\tReference T71 Wikidata:Q9361\\tБишкек',\n",
       "  'N13\\tReference T72 Wikidata:NULL\\t',\n",
       "  'N14\\tReference T4 Wikidata:Q230\\tГрузия',\n",
       "  'N15\\tReference T74 Wikidata:NULL\\t',\n",
       "  'N16\\tReference T75 Wikidata:Q30\\tСША',\n",
       "  'N17\\tReference T76 Wikidata:NULL\\t',\n",
       "  'N18\\tReference T77 Wikidata:NULL\\t',\n",
       "  'N19\\tReference T78 Wikidata:Q47064\\tвоеннослужащий',\n",
       "  'N20\\tReference T80 Wikidata:NULL\\t',\n",
       "  'N21\\tReference T82 Wikidata:NULL\\t',\n",
       "  'N22\\tReference T88 Wikidata:NULL\\t',\n",
       "  'N23\\tReference T89 Wikidata:NULL\\t',\n",
       "  'N24\\tReference T91 Wikidata:Q192350\\tминистерство',\n",
       "  'N25\\tReference T92 Wikidata:Q7188\\tправительство',\n",
       "  'N26\\tReference T94 Wikidata:NULL\\t',\n",
       "  'N27\\tReference T95 Wikidata:NULL\\t',\n",
       "  'N28\\tReference T98 Wikidata:NULL\\t',\n",
       "  'N29\\tReference T100 Wikidata:Q245016\\tвоенная база',\n",
       "  'N30\\tReference T102 Wikidata:Q47064\\tвоеннослужащий',\n",
       "  'N31\\tReference T101 Wikidata:NULL\\t',\n",
       "  'N32\\tReference T105 Wikidata:Q846570\\t',\n",
       "  'N33\\tReference T42 Wikidata:NULL\\t',\n",
       "  'N34\\tReference T59 Wikidata:Q9361\\tБишкек',\n",
       "  'N35\\tReference T107 Wikidata:NULL\\t',\n",
       "  'N36\\tReference T85 Wikidata:Q813\\tКиргизия',\n",
       "  'N37\\tReference T44 Wikidata:Q6589202\\tминистерство внутренних дел',\n",
       "  'N38\\tReference T28 Wikidata:Q6589202\\tминистерство внутренних дел',\n",
       "  'N39\\tReference T26 Wikidata:Q324782\\tBeretta',\n",
       "  'N40\\tReference T68 Wikidata:Q821172\\tРИА Новости',\n",
       "  'N41\\tReference T51 Wikidata:Q813\\tКиргизия',\n",
       "  'N42\\tReference T61 Wikidata:Q813\\tКиргизия',\n",
       "  'N43\\tReference T56 Wikidata:Q813\\tКиргизия',\n",
       "  'N44\\tReference T14 Wikidata:Q813\\tКиргизия',\n",
       "  'N45\\tReference T86 Wikidata:Q813\\tКиргизия',\n",
       "  'N46\\tReference T65 Wikidata:Q813\\tКиргизия',\n",
       "  'N47\\tReference T73 Wikidata:Q813\\tКиргизия',\n",
       "  'N48\\tReference T55 Wikidata:Q813\\tКиргизия',\n",
       "  'N49\\tReference T58 Wikidata:Q813\\tКиргизия',\n",
       "  'N50\\tReference T6 Wikidata:Q813\\tКиргизия',\n",
       "  'N51\\tReference T8 Wikidata:Q9361\\tБишкек',\n",
       "  'N52\\tReference T83 Wikidata:Q9361\\tБишкек',\n",
       "  'N53\\tReference T2 Wikidata:Q9361\\tБишкек',\n",
       "  'N54\\tReference T57 Wikidata:Q30\\tСША',\n",
       "  'N55\\tReference T96 Wikidata:Q30\\tСША',\n",
       "  'N56\\tReference T15 Wikidata:Q30\\tСША',\n",
       "  'N57\\tReference T108 Wikidata:Q30\\tСША',\n",
       "  'N58\\tReference T7 Wikidata:Q30\\tСША',\n",
       "  'N59\\tReference T81 Wikidata:Q30\\tСША',\n",
       "  'N60\\tReference T30 Wikidata:Q30\\tСША',\n",
       "  'N61\\tReference T67 Wikidata:Q30\\tСША',\n",
       "  'N62\\tReference T50 Wikidata:Q30\\tСША',\n",
       "  'N63\\tReference T66 Wikidata:Q30\\tСША',\n",
       "  'N64\\tReference T60 Wikidata:Q30\\tСША',\n",
       "  'N65\\tReference T90 Wikidata:Q47064\\tвоеннослужащий',\n",
       "  'N66\\tReference T79 Wikidata:Q846570\\t',\n",
       "  'N67\\tReference T1 Wikidata:Q846570\\t',\n",
       "  'N68\\tReference T104 Wikidata:Q846570\\t',\n",
       "  'N69\\tReference T103 Wikidata:NULL\\t',\n",
       "  'N70\\tReference T87 Wikidata:NULL\\t',\n",
       "  'N71\\tReference T93 Wikidata:NULL\\t',\n",
       "  'N72\\tReference T97 Wikidata:NULL\\t',\n",
       "  'N73\\tReference T54 Wikidata:NULL\\t']}"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 258
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vVA333xvYoUn"
   },
   "source": [
    "The labels are already coded as integer ids to be easily usable by our model, but the correspondence with the actual categories is stored in the `features` of the dataset:"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T09:22:12.273169Z",
     "start_time": "2024-04-10T09:22:12.266987Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "def transform_entities(entities):\n",
    "    markup = []\n",
    "    for i in entities:\n",
    "        splited = re.split('\\t', i)\n",
    "        data = re.split(' ', splited[1])\n",
    "        if \";\" in data[2]:\n",
    "            data[2] = data[2].split(\";\")[0]\n",
    "        markup.append({'id': splited[0],\n",
    "               'type': data[0],\n",
    "               'start': int(data[1]),\n",
    "               'stop': int(data[2]),\n",
    "               'text': splited[2]})\n",
    "    markup.sort(key=lambda x: x[\"start\"])\n",
    "    return markup"
   ],
   "outputs": [],
   "execution_count": 259
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T09:22:12.293707Z",
     "start_time": "2024-04-10T09:22:12.274460Z"
    }
   },
   "cell_type": "code",
   "source": "transform_entities(datasets[\"train\"][0]['entities'])",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'T1',\n",
       "  'type': 'NATIONALITY',\n",
       "  'start': 62,\n",
       "  'stop': 74,\n",
       "  'text': 'американцами'},\n",
       " {'id': 'T2', 'type': 'CITY', 'start': 82, 'stop': 89, 'text': 'Бишкеке'},\n",
       " {'id': 'T11', 'type': 'DATE', 'start': 91, 'stop': 101, 'text': '05/08/2008'},\n",
       " {'id': 'T69',\n",
       "  'type': 'TIME',\n",
       "  'start': 91,\n",
       "  'stop': 107,\n",
       "  'text': '05/08/2008 10:35'},\n",
       " {'id': 'T71', 'type': 'CITY', 'start': 109, 'stop': 115, 'text': 'БИШКЕК'},\n",
       " {'id': 'T3', 'type': 'DATE', 'start': 117, 'stop': 126, 'text': '5 августа'},\n",
       " {'id': 'T72',\n",
       "  'type': 'ORGANIZATION',\n",
       "  'start': 128,\n",
       "  'stop': 142,\n",
       "  'text': 'Новости-Грузия'},\n",
       " {'id': 'T4', 'type': 'COUNTRY', 'start': 136, 'stop': 142, 'text': 'Грузия'},\n",
       " {'id': 'T5',\n",
       "  'type': 'ORGANIZATION',\n",
       "  'start': 145,\n",
       "  'stop': 179,\n",
       "  'text': 'Правоохранительные органы Киргизии'},\n",
       " {'id': 'T6',\n",
       "  'type': 'COUNTRY',\n",
       "  'start': 171,\n",
       "  'stop': 179,\n",
       "  'text': 'Киргизии'},\n",
       " {'id': 'T104',\n",
       "  'type': 'NATIONALITY',\n",
       "  'start': 210,\n",
       "  'stop': 224,\n",
       "  'text': 'гражданами США'},\n",
       " {'id': 'T7', 'type': 'COUNTRY', 'start': 221, 'stop': 224, 'text': 'США'},\n",
       " {'id': 'T8', 'type': 'CITY', 'start': 227, 'stop': 234, 'text': 'Бишкеке'},\n",
       " {'id': 'T9', 'type': 'DATE', 'start': 288, 'stop': 298, 'text': 'во вторник'},\n",
       " {'id': 'T74',\n",
       "  'type': 'ORGANIZATION',\n",
       "  'start': 299,\n",
       "  'stop': 324,\n",
       "  'text': 'пресс-служба МВД Киргизии'},\n",
       " {'id': 'T10',\n",
       "  'type': 'ORGANIZATION',\n",
       "  'start': 312,\n",
       "  'stop': 315,\n",
       "  'text': 'МВД'},\n",
       " {'id': 'T42',\n",
       "  'type': 'ORGANIZATION',\n",
       "  'start': 312,\n",
       "  'stop': 324,\n",
       "  'text': 'МВД Киргизии'},\n",
       " {'id': 'T73',\n",
       "  'type': 'COUNTRY',\n",
       "  'start': 316,\n",
       "  'stop': 324,\n",
       "  'text': 'Киргизии'},\n",
       " {'id': 'T70', 'type': 'EVENT', 'start': 410, 'stop': 417, 'text': 'Арсенал'},\n",
       " {'id': 'T12', 'type': 'CITY', 'start': 433, 'stop': 440, 'text': 'Ынтымак'},\n",
       " {'id': 'T13', 'type': 'AGE', 'start': 464, 'stop': 474, 'text': '66-летнему'},\n",
       " {'id': 'T101',\n",
       "  'type': 'NATIONALITY',\n",
       "  'start': 475,\n",
       "  'stop': 494,\n",
       "  'text': 'гражданину Киргизии'},\n",
       " {'id': 'T14',\n",
       "  'type': 'COUNTRY',\n",
       "  'start': 486,\n",
       "  'stop': 494,\n",
       "  'text': 'Киргизии'},\n",
       " {'id': 'T105',\n",
       "  'type': 'NATIONALITY',\n",
       "  'start': 508,\n",
       "  'stop': 522,\n",
       "  'text': 'гражданами США'},\n",
       " {'id': 'T15', 'type': 'COUNTRY', 'start': 519, 'stop': 522, 'text': 'США'},\n",
       " {'id': 'T106',\n",
       "  'type': 'EVENT',\n",
       "  'start': 524,\n",
       "  'stop': 543,\n",
       "  'text': 'обнаружены и изъяты'},\n",
       " {'id': 'T16', 'type': 'NUMBER', 'start': 545, 'stop': 550, 'text': 'шесть'},\n",
       " {'id': 'T17', 'type': 'NUMBER', 'start': 631, 'stop': 633, 'text': '26'},\n",
       " {'id': 'T18',\n",
       "  'type': 'NUMBER',\n",
       "  'start': 652,\n",
       "  'stop': 667,\n",
       "  'text': '5,56 миллиметра'},\n",
       " {'id': 'T19', 'type': 'NUMBER', 'start': 669, 'stop': 672, 'text': 'два'},\n",
       " {'id': 'T20',\n",
       "  'type': 'PRODUCT',\n",
       "  'start': 690,\n",
       "  'stop': 697,\n",
       "  'text': 'МОСВЕГА'},\n",
       " {'id': 'T63',\n",
       "  'type': 'NUMBER',\n",
       "  'start': 698,\n",
       "  'stop': 711,\n",
       "  'text': '12-го калибра'},\n",
       " {'id': 'T21', 'type': 'NUMBER', 'start': 713, 'stop': 719, 'text': 'четыре'},\n",
       " {'id': 'T22', 'type': 'NUMBER', 'start': 758, 'stop': 761, 'text': 'два'},\n",
       " {'id': 'T23', 'type': 'NUMBER', 'start': 788, 'stop': 794, 'text': 'четыре'},\n",
       " {'id': 'T24', 'type': 'NUMBER', 'start': 855, 'stop': 860, 'text': 'шесть'},\n",
       " {'id': 'T25',\n",
       "  'type': 'NUMBER',\n",
       "  'start': 880,\n",
       "  'stop': 893,\n",
       "  'text': '9 миллиметров'},\n",
       " {'id': 'T26',\n",
       "  'type': 'PRODUCT',\n",
       "  'start': 900,\n",
       "  'stop': 907,\n",
       "  'text': 'Беретта'},\n",
       " {'id': 'T27', 'type': 'NUMBER', 'start': 909, 'stop': 913, 'text': 'одна'},\n",
       " {'id': 'T28',\n",
       "  'type': 'ORGANIZATION',\n",
       "  'start': 949,\n",
       "  'stop': 952,\n",
       "  'text': 'МВД'},\n",
       " {'id': 'T77',\n",
       "  'type': 'PROFESSION',\n",
       "  'start': 1028,\n",
       "  'stop': 1054,\n",
       "  'text': 'сотрудников посольства США'},\n",
       " {'id': 'T76',\n",
       "  'type': 'ORGANIZATION',\n",
       "  'start': 1040,\n",
       "  'stop': 1054,\n",
       "  'text': 'посольства США'},\n",
       " {'id': 'T75', 'type': 'COUNTRY', 'start': 1051, 'stop': 1054, 'text': 'США'},\n",
       " {'id': 'T29', 'type': 'NUMBER', 'start': 1098, 'stop': 1100, 'text': '10'},\n",
       " {'id': 'T78',\n",
       "  'type': 'PROFESSION',\n",
       "  'start': 1101,\n",
       "  'stop': 1115,\n",
       "  'text': 'военнослужащих'},\n",
       " {'id': 'T30', 'type': 'COUNTRY', 'start': 1136, 'stop': 1139, 'text': 'США'},\n",
       " {'id': 'T80',\n",
       "  'type': 'PROFESSION',\n",
       "  'start': 1166,\n",
       "  'stop': 1196,\n",
       "  'text': 'сотрудниками спецподразделения'},\n",
       " {'id': 'T31', 'type': 'NUMBER', 'start': 1372, 'stop': 1375, 'text': 'Два'},\n",
       " {'id': 'T32', 'type': 'NUMBER', 'start': 1382, 'stop': 1386, 'text': '2920'},\n",
       " {'id': 'T33',\n",
       "  'type': 'NUMBER',\n",
       "  'start': 1409,\n",
       "  'stop': 1424,\n",
       "  'text': '5,56 миллиметра'},\n",
       " {'id': 'T34', 'type': 'NUMBER', 'start': 1426, 'stop': 1431, 'text': '10556'},\n",
       " {'id': 'T35',\n",
       "  'type': 'NUMBER',\n",
       "  'start': 1454,\n",
       "  'stop': 1467,\n",
       "  'text': '9 миллиметров'},\n",
       " {'id': 'T36', 'type': 'NUMBER', 'start': 1469, 'stop': 1472, 'text': 'два'},\n",
       " {'id': 'T37',\n",
       "  'type': 'NUMBER',\n",
       "  'start': 1496,\n",
       "  'stop': 1510,\n",
       "  'text': '50 миллиметров'},\n",
       " {'id': 'T38', 'type': 'NUMBER', 'start': 1521, 'stop': 1524, 'text': '350'},\n",
       " {'id': 'T39',\n",
       "  'type': 'NUMBER',\n",
       "  'start': 1547,\n",
       "  'stop': 1561,\n",
       "  'text': '12 миллиметров'},\n",
       " {'id': 'T40', 'type': 'NUMBER', 'start': 1575, 'stop': 1578, 'text': '478'},\n",
       " {'id': 'T41', 'type': 'NUMBER', 'start': 1639, 'stop': 1643, 'text': '1000'},\n",
       " {'id': 'T43', 'type': 'NUMBER', 'start': 1650, 'stop': 1652, 'text': '66'},\n",
       " {'id': 'T45', 'type': 'NUMBER', 'start': 1702, 'stop': 1704, 'text': '57'},\n",
       " {'id': 'T46',\n",
       "  'type': 'PRODUCT',\n",
       "  'start': 1740,\n",
       "  'stop': 1747,\n",
       "  'text': 'Беретта'},\n",
       " {'id': 'T47',\n",
       "  'type': 'ORGANIZATION',\n",
       "  'start': 1779,\n",
       "  'stop': 1795,\n",
       "  'text': 'Пресс-служба МВД'},\n",
       " {'id': 'T44',\n",
       "  'type': 'ORGANIZATION',\n",
       "  'start': 1792,\n",
       "  'stop': 1795,\n",
       "  'text': 'МВД'},\n",
       " {'id': 'T48',\n",
       "  'type': 'ORGANIZATION',\n",
       "  'start': 1850,\n",
       "  'stop': 1861,\n",
       "  'text': 'прокуратура'},\n",
       " {'id': 'T82',\n",
       "  'type': 'ORGANIZATION',\n",
       "  'start': 1850,\n",
       "  'stop': 1869,\n",
       "  'text': 'прокуратура Бишкека'},\n",
       " {'id': 'T83', 'type': 'CITY', 'start': 1862, 'stop': 1869, 'text': 'Бишкека'},\n",
       " {'id': 'T84', 'type': 'TIME', 'start': 1871, 'stop': 1877, 'text': 'Сейчас'},\n",
       " {'id': 'T49',\n",
       "  'type': 'ORGANIZATION',\n",
       "  'start': 1939,\n",
       "  'stop': 1950,\n",
       "  'text': 'РИА Новости'},\n",
       " {'id': 'T79',\n",
       "  'type': 'NATIONALITY',\n",
       "  'start': 1971,\n",
       "  'stop': 1982,\n",
       "  'text': 'граждан США'},\n",
       " {'id': 'T50', 'type': 'COUNTRY', 'start': 1979, 'stop': 1982, 'text': 'США'},\n",
       " {'id': 'T85',\n",
       "  'type': 'ORGANIZATION',\n",
       "  'start': 1983,\n",
       "  'stop': 2020,\n",
       "  'text': 'правоохранительными органами Киргизии'},\n",
       " {'id': 'T51',\n",
       "  'type': 'COUNTRY',\n",
       "  'start': 2012,\n",
       "  'stop': 2020,\n",
       "  'text': 'Киргизии'},\n",
       " {'id': 'T52',\n",
       "  'type': 'ORGANIZATION',\n",
       "  'start': 2055,\n",
       "  'stop': 2077,\n",
       "  'text': 'правительства Киргизии'},\n",
       " {'id': 'T86',\n",
       "  'type': 'COUNTRY',\n",
       "  'start': 2069,\n",
       "  'stop': 2077,\n",
       "  'text': 'Киргизии'},\n",
       " {'id': 'T53',\n",
       "  'type': 'DATE',\n",
       "  'start': 2087,\n",
       "  'stop': 2097,\n",
       "  'text': 'во вторник'},\n",
       " {'id': 'T88',\n",
       "  'type': 'PROFESSION',\n",
       "  'start': 2098,\n",
       "  'stop': 2139,\n",
       "  'text': 'представитель пресс-службы посольства США'},\n",
       " {'id': 'T89',\n",
       "  'type': 'ORGANIZATION',\n",
       "  'start': 2112,\n",
       "  'stop': 2139,\n",
       "  'text': 'пресс-службы посольства США'},\n",
       " {'id': 'T87',\n",
       "  'type': 'ORGANIZATION',\n",
       "  'start': 2125,\n",
       "  'stop': 2139,\n",
       "  'text': 'посольства США'},\n",
       " {'id': 'T81', 'type': 'COUNTRY', 'start': 2136, 'stop': 2139, 'text': 'США'},\n",
       " {'id': 'T55',\n",
       "  'type': 'COUNTRY',\n",
       "  'start': 2185,\n",
       "  'stop': 2193,\n",
       "  'text': 'Киргизии'},\n",
       " {'id': 'T54',\n",
       "  'type': 'ORGANIZATION',\n",
       "  'start': 2216,\n",
       "  'stop': 2234,\n",
       "  'text': 'киргизских властей'},\n",
       " {'id': 'T56',\n",
       "  'type': 'COUNTRY',\n",
       "  'start': 2216,\n",
       "  'stop': 2226,\n",
       "  'text': 'киргизских'},\n",
       " {'id': 'T90',\n",
       "  'type': 'PROFESSION',\n",
       "  'start': 2268,\n",
       "  'stop': 2282,\n",
       "  'text': 'Военнослужащие'},\n",
       " {'id': 'T92',\n",
       "  'type': 'ORGANIZATION',\n",
       "  'start': 2329,\n",
       "  'stop': 2342,\n",
       "  'text': 'правительства'},\n",
       " {'id': 'T91',\n",
       "  'type': 'ORGANIZATION',\n",
       "  'start': 2395,\n",
       "  'stop': 2406,\n",
       "  'text': 'министерств'},\n",
       " {'id': 'T57',\n",
       "  'type': 'COUNTRY',\n",
       "  'start': 2417,\n",
       "  'stop': 2429,\n",
       "  'text': 'американское'},\n",
       " {'id': 'T93',\n",
       "  'type': 'ORGANIZATION',\n",
       "  'start': 2417,\n",
       "  'stop': 2455,\n",
       "  'text': 'американское дипломатическое ведомство'},\n",
       " {'id': 'T94',\n",
       "  'type': 'ORGANIZATION',\n",
       "  'start': 2430,\n",
       "  'stop': 2455,\n",
       "  'text': 'дипломатическое ведомство'},\n",
       " {'id': 'T58',\n",
       "  'type': 'COUNTRY',\n",
       "  'start': 2501,\n",
       "  'stop': 2511,\n",
       "  'text': 'киргизских'},\n",
       " {'id': 'T107',\n",
       "  'type': 'ORGANIZATION',\n",
       "  'start': 2501,\n",
       "  'stop': 2519,\n",
       "  'text': 'киргизских властей'},\n",
       " {'id': 'T95',\n",
       "  'type': 'ORGANIZATION',\n",
       "  'start': 2533,\n",
       "  'stop': 2545,\n",
       "  'text': 'пресс-служба'},\n",
       " {'id': 'T97',\n",
       "  'type': 'ORGANIZATION',\n",
       "  'start': 2548,\n",
       "  'stop': 2562,\n",
       "  'text': 'Посольство США'},\n",
       " {'id': 'T96', 'type': 'COUNTRY', 'start': 2559, 'stop': 2562, 'text': 'США'},\n",
       " {'id': 'T60', 'type': 'COUNTRY', 'start': 2631, 'stop': 2634, 'text': 'США'},\n",
       " {'id': 'T61',\n",
       "  'type': 'COUNTRY',\n",
       "  'start': 2637,\n",
       "  'stop': 2645,\n",
       "  'text': 'Киргизия'},\n",
       " {'id': 'T62',\n",
       "  'type': 'COUNTRY',\n",
       "  'start': 2720,\n",
       "  'stop': 2728,\n",
       "  'text': 'Киргизии'},\n",
       " {'id': 'T98',\n",
       "  'type': 'ORGANIZATION',\n",
       "  'start': 2732,\n",
       "  'stop': 2770,\n",
       "  'text': 'Пресс-служба американской военной базы'},\n",
       " {'id': 'T67',\n",
       "  'type': 'COUNTRY',\n",
       "  'start': 2745,\n",
       "  'stop': 2757,\n",
       "  'text': 'американской'},\n",
       " {'id': 'T100',\n",
       "  'type': 'ORGANIZATION',\n",
       "  'start': 2745,\n",
       "  'stop': 2770,\n",
       "  'text': 'американской военной базы'},\n",
       " {'id': 'T64',\n",
       "  'type': 'FACILITY',\n",
       "  'start': 2812,\n",
       "  'stop': 2817,\n",
       "  'text': 'Манас'},\n",
       " {'id': 'T59',\n",
       "  'type': 'CITY',\n",
       "  'start': 2819,\n",
       "  'stop': 2835,\n",
       "  'text': 'столицы Киргизии'},\n",
       " {'id': 'T65',\n",
       "  'type': 'COUNTRY',\n",
       "  'start': 2827,\n",
       "  'stop': 2835,\n",
       "  'text': 'Киргизии'},\n",
       " {'id': 'T66',\n",
       "  'type': 'COUNTRY',\n",
       "  'start': 2889,\n",
       "  'stop': 2901,\n",
       "  'text': 'американских'},\n",
       " {'id': 'T102',\n",
       "  'type': 'PROFESSION',\n",
       "  'start': 2902,\n",
       "  'stop': 2909,\n",
       "  'text': 'военных'},\n",
       " {'id': 'T103',\n",
       "  'type': 'ORGANIZATION',\n",
       "  'start': 2970,\n",
       "  'stop': 2984,\n",
       "  'text': 'посольство США'},\n",
       " {'id': 'T108', 'type': 'COUNTRY', 'start': 2981, 'stop': 2984, 'text': 'США'},\n",
       " {'id': 'T68',\n",
       "  'type': 'ORGANIZATION',\n",
       "  'start': 2998,\n",
       "  'stop': 3009,\n",
       "  'text': 'РИА Новости'}]"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 260
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T09:22:12.300969Z",
     "start_time": "2024-04-10T09:22:12.295097Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def transform(text, markup): \n",
    "    tokens = [text[0:markup[0]['start']]]\n",
    "    tags = ['O']\n",
    "    \n",
    "    for i in range(len(markup[:-1])):\n",
    "        tokens.append(text[markup[i]['start']:markup[i]['stop']])\n",
    "        tags.append(markup[i]['type'])\n",
    "        tokens.append(text[markup[i]['stop']:markup[i + 1]['start']])\n",
    "        tags.append('O')\n",
    "\n",
    "    tokens.append(text[markup[-1]['start']:markup[-1]['stop']])\n",
    "    tags.append(markup[-1]['type'])\n",
    "    tokens.append(text[markup[-1]['stop']:])\n",
    "    tags.append('O')\n",
    "    \n",
    "    final_tokens = []\n",
    "    final_tags = []\n",
    "    \n",
    "    for i in range(len(tokens)):\n",
    "        size = len(tokens[i].split())\n",
    "        final_tokens += tokens[i].split()\n",
    "        if tags[i] != \"O\":\n",
    "            final_tags.append(\"B-\" + tags[i])\n",
    "            final_tags += [\"I-\" + tags[i]] * (size - 1)\n",
    "        else:\n",
    "            final_tags += [tags[i]] * size\n",
    "        \n",
    "    return final_tokens, final_tags"
   ],
   "outputs": [],
   "execution_count": 261
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T09:22:12.307535Z",
     "start_time": "2024-04-10T09:22:12.301974Z"
    }
   },
   "cell_type": "code",
   "source": "tokens, entities = transform(datasets[\"train\"][0]['text'], transform_entities(datasets[\"train\"][0]['entities']))",
   "outputs": [],
   "execution_count": 262
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T09:22:12.312957Z",
     "start_time": "2024-04-10T09:22:12.308735Z"
    }
   },
   "cell_type": "code",
   "source": "len(tokens), len(entities)",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(445, 445)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 263
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RddCu-oqYoUn",
    "outputId": "a4aa7160-f27b-476f-d1cc-074562f8e944",
    "ExecuteTime": {
     "end_time": "2024-04-10T09:22:12.321979Z",
     "start_time": "2024-04-10T09:22:12.314660Z"
    }
   },
   "source": "entities",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-NATIONALITY',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-CITY',\n",
       " 'B-DATE',\n",
       " 'B-TIME',\n",
       " 'I-TIME',\n",
       " 'B-CITY',\n",
       " 'O',\n",
       " 'B-DATE',\n",
       " 'I-DATE',\n",
       " 'O',\n",
       " 'B-ORGANIZATION',\n",
       " 'B-COUNTRY',\n",
       " 'O',\n",
       " 'B-ORGANIZATION',\n",
       " 'I-ORGANIZATION',\n",
       " 'I-ORGANIZATION',\n",
       " 'B-COUNTRY',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-NATIONALITY',\n",
       " 'I-NATIONALITY',\n",
       " 'B-COUNTRY',\n",
       " 'O',\n",
       " 'B-CITY',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-DATE',\n",
       " 'I-DATE',\n",
       " 'B-ORGANIZATION',\n",
       " 'I-ORGANIZATION',\n",
       " 'I-ORGANIZATION',\n",
       " 'B-ORGANIZATION',\n",
       " 'B-ORGANIZATION',\n",
       " 'I-ORGANIZATION',\n",
       " 'B-COUNTRY',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-EVENT',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-CITY',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-AGE',\n",
       " 'B-NATIONALITY',\n",
       " 'I-NATIONALITY',\n",
       " 'B-COUNTRY',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-NATIONALITY',\n",
       " 'I-NATIONALITY',\n",
       " 'B-COUNTRY',\n",
       " 'O',\n",
       " 'B-EVENT',\n",
       " 'I-EVENT',\n",
       " 'I-EVENT',\n",
       " 'O',\n",
       " 'B-NUMBER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-NUMBER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-NUMBER',\n",
       " 'I-NUMBER',\n",
       " 'O',\n",
       " 'B-NUMBER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-PRODUCT',\n",
       " 'B-NUMBER',\n",
       " 'I-NUMBER',\n",
       " 'O',\n",
       " 'B-NUMBER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-NUMBER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-NUMBER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-NUMBER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-NUMBER',\n",
       " 'I-NUMBER',\n",
       " 'O',\n",
       " 'B-PRODUCT',\n",
       " 'O',\n",
       " 'B-NUMBER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-ORGANIZATION',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-PROFESSION',\n",
       " 'I-PROFESSION',\n",
       " 'I-PROFESSION',\n",
       " 'B-ORGANIZATION',\n",
       " 'I-ORGANIZATION',\n",
       " 'B-COUNTRY',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-NUMBER',\n",
       " 'B-PROFESSION',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-COUNTRY',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-PROFESSION',\n",
       " 'I-PROFESSION',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-NUMBER',\n",
       " 'O',\n",
       " 'B-NUMBER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-NUMBER',\n",
       " 'I-NUMBER',\n",
       " 'O',\n",
       " 'B-NUMBER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-NUMBER',\n",
       " 'I-NUMBER',\n",
       " 'O',\n",
       " 'B-NUMBER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-NUMBER',\n",
       " 'I-NUMBER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-NUMBER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-NUMBER',\n",
       " 'I-NUMBER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-NUMBER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-NUMBER',\n",
       " 'O',\n",
       " 'B-NUMBER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-NUMBER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-PRODUCT',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-ORGANIZATION',\n",
       " 'I-ORGANIZATION',\n",
       " 'B-ORGANIZATION',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-ORGANIZATION',\n",
       " 'B-ORGANIZATION',\n",
       " 'I-ORGANIZATION',\n",
       " 'B-CITY',\n",
       " 'O',\n",
       " 'B-TIME',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-ORGANIZATION',\n",
       " 'I-ORGANIZATION',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-NATIONALITY',\n",
       " 'I-NATIONALITY',\n",
       " 'B-COUNTRY',\n",
       " 'B-ORGANIZATION',\n",
       " 'I-ORGANIZATION',\n",
       " 'I-ORGANIZATION',\n",
       " 'B-COUNTRY',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-ORGANIZATION',\n",
       " 'I-ORGANIZATION',\n",
       " 'B-COUNTRY',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-DATE',\n",
       " 'I-DATE',\n",
       " 'B-PROFESSION',\n",
       " 'I-PROFESSION',\n",
       " 'I-PROFESSION',\n",
       " 'I-PROFESSION',\n",
       " 'B-ORGANIZATION',\n",
       " 'I-ORGANIZATION',\n",
       " 'I-ORGANIZATION',\n",
       " 'B-ORGANIZATION',\n",
       " 'I-ORGANIZATION',\n",
       " 'B-COUNTRY',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-COUNTRY',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-ORGANIZATION',\n",
       " 'I-ORGANIZATION',\n",
       " 'B-COUNTRY',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-PROFESSION',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-ORGANIZATION',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-ORGANIZATION',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-COUNTRY',\n",
       " 'B-ORGANIZATION',\n",
       " 'I-ORGANIZATION',\n",
       " 'I-ORGANIZATION',\n",
       " 'B-ORGANIZATION',\n",
       " 'I-ORGANIZATION',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-COUNTRY',\n",
       " 'B-ORGANIZATION',\n",
       " 'I-ORGANIZATION',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-ORGANIZATION',\n",
       " 'O',\n",
       " 'B-ORGANIZATION',\n",
       " 'I-ORGANIZATION',\n",
       " 'B-COUNTRY',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-COUNTRY',\n",
       " 'O',\n",
       " 'B-COUNTRY',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-COUNTRY',\n",
       " 'O',\n",
       " 'B-ORGANIZATION',\n",
       " 'I-ORGANIZATION',\n",
       " 'I-ORGANIZATION',\n",
       " 'I-ORGANIZATION',\n",
       " 'B-COUNTRY',\n",
       " 'B-ORGANIZATION',\n",
       " 'I-ORGANIZATION',\n",
       " 'I-ORGANIZATION',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-FACILITY',\n",
       " 'O',\n",
       " 'B-CITY',\n",
       " 'I-CITY',\n",
       " 'B-COUNTRY',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-COUNTRY',\n",
       " 'B-PROFESSION',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-ORGANIZATION',\n",
       " 'I-ORGANIZATION',\n",
       " 'B-COUNTRY',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-ORGANIZATION',\n",
       " 'I-ORGANIZATION',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O']"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 264
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z30lbCjLYoUn"
   },
   "source": [
    "So for the NER tags, 0 corresponds to 'O', 1 to 'B-PER' etc... On top of the 'O' (which means no special entity), there are four labels for NER here, each prefixed with 'B-' (for beginning) or 'I-' (for intermediate), that indicate if the token is the first one for the current group with the label or not:\n",
    "- 'PER' for person\n",
    "- 'ORG' for organization\n",
    "- 'LOC' for location\n",
    "- 'MISC' for miscellaneous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TYqXmDFdYoUn"
   },
   "source": [
    "Since the labels are lists of `ClassLabel`, the actual names of the labels are nested in the `feature` attribute of the object above:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WHUmphG3IrI3"
   },
   "source": [
    "To get a sense of what the data looks like, the following function will show some examples picked randomly in the dataset (automatically decoding the labels in passing)."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T09:22:12.869969Z",
     "start_time": "2024-04-10T09:22:12.863739Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class OwnDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.dataset[idx]\n",
    "        text = item['text']\n",
    "        tokens, entities = transform(item['text'], transform_entities(item['entities']))\n",
    "        return {\"text\": text,\n",
    "                \"tokens\": tokens,\n",
    "                \"ner_tags\": entities}"
   ],
   "outputs": [],
   "execution_count": 265
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T09:22:13.105133Z",
     "start_time": "2024-04-10T09:22:13.101263Z"
    }
   },
   "cell_type": "code",
   "source": "train_dataset = OwnDataset(datasets['train'])",
   "outputs": [],
   "execution_count": 266
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "i3j8APAoIrI3",
    "ExecuteTime": {
     "end_time": "2024-04-10T09:22:13.384790Z",
     "start_time": "2024-04-10T09:22:13.377002Z"
    }
   },
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "\n",
    "    df = pd.DataFrame(columns=[\"text\", \"tokens\", \"ner_tags\"])\n",
    "    for idx in range(num_examples):\n",
    "        df.at[idx, \"text\"] = dataset[picks[idx]][\"text\"]\n",
    "        df.at[idx, \"tokens\"] = dataset[picks[idx]][\"tokens\"]\n",
    "        df.at[idx, \"ner_tags\"] = dataset[picks[idx]][\"ner_tags\"]\n",
    "    display(HTML(df.to_html()))"
   ],
   "outputs": [],
   "execution_count": 267
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SZy5tRB_IrI7",
    "outputId": "ba8f2124-e485-488f-8c0c-254f34f24f13",
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-04-10T09:22:13.729672Z",
     "start_time": "2024-04-10T09:22:13.641417Z"
    }
   },
   "source": "show_random_elements(train_dataset)",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>ner_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Две лесбиянки со взрослым сыном из России поженились и попросили политического убежища в Аргентине\\nВ день четырёхлетия принятия закона об однополом браке в Аргентине — 15 июля 2014 года, в Буэнос-Айресе две российские лесбиянки — Марина Миронова и Оксана Тимофеева, воспитывающие 16-летноего сына, поженились и пропросили политического убежища в этой стране.\\nОб этом ообщает агентство EFE со ссылкой на Федерацию лесбиянок, геев, бисексуалов и транссексуалов Аргентины (FALGBT).\\n\\nЧерез четыре года после принятия закона об однополом браке в Аргентине, две русские женщины женились в Буэнос-Айресе, 15 июля 2014 года. Источник видео.\\n\\nЖенщины заявили, что дата совпала случайно, а их выбор пал на Аргентину, так как они хотят жить «свободно и в безопасности», и эта страна может предоставить им такую возможность.\\n\\nВице-президент FALGBT Клаудия Кастросин Верду, ставшая свидетелем на свадьбе, пояснила, что пара искала помощи у аргентинской федерации, страдая от преследований гомосексуалистов в России, начавшихся в конце 2012 года, после принятия закона о запрете пропаганды гомосексуализма среди несовершеннолетних:\\nУ них есть 16-летний сын, которого они не хотят потерять.\\n\\nКастросин Верду также выразила обеспокоенность ущемлением в России прав сексуальных меньшинств.\\n\\nЖенщины 38 и 36 лет приехали в Аргентину месяц назад после того, как узнали о якобы готовящемся законе, по которому у однополых пар смогут отбирать детей.\\nСМИ отмечают, что они фактически бежали из России в Аргентину, не зная в должной мере ни английского ни испанского языка.\\n\\nМарина Миронова (мать 16-летнего парня) также сообщила изданию Télam, что в России она работала учителем и была уволена, после того как в школе узнали о том, что она живёт с женщиной.\\n\\nС конца 2012 года, когда в России был принят «антигейский» закон, давление на лиц «нетрадиционной» ориентации только усиливается.\\n\\nИм запрещают проводить акции и шествия в защиту своих прав.\\n\\nДикторы российского телевидения допускают оскорбительные и провокационные высказывания в адрес ЛГБТ-сообщества, предлагая сжигать в печах «сердца геев» и их самих.\\n\\nВ сентябре 2013 года депутат Госдумы РФ от Единой России, председатель политической партии «Родина» Алексей Журавлёв выступил инициатором законопроекта о лишении родительских прав лиц нетрадиционной сексуальной ориентации.\\nДокладчик ПАСЕ по правам ЛГБТ Х. Хаугли расценил эту инициативу как проявление гомофобной пропаганды, противоречащее международным обязательствам России.\\n</td>\n",
       "      <td>[Две, лесбиянки, со, взрослым, сыном, из, России, поженились, и, попросили, политического, убежища, в, Аргентине, В, день, четырёхлетия, принятия, закона, закона, об, однополом, браке, в, Аргентине, —, 15, июля, 2014, года, ,, в, Буэнос-Айресе, две, российские, лесбиянки, —, Марина, Миронова, и, Оксана, Тимофеева, ,, воспитывающие, 16-летноего, сына,, поженились, и, пропросили, политического, убежища, в, этой, стране., Об, этом, ообщает, агентство, EFE, со, ссылкой, на, Федерацию, лесбиянок,, геев,, бисексуалов, и, транссексуалов, Аргентины, Аргентины, (, FALGBT, )., Через, четыре, года, после, принятия, закона, об, однополом, браке, закона, об, однополом, браке, в, Аргентине, ,, две, русские, женщины, женились, в, Буэнос-Айресе, ,, 15, июля, 2014, года, ...]</td>\n",
       "      <td>[B-NUMBER, B-EVENT, O, O, O, O, B-COUNTRY, O, O, O, O, O, O, B-COUNTRY, B-DATE, I-DATE, B-AGE, B-EVENT, I-EVENT, B-LAW, I-LAW, I-LAW, I-LAW, O, B-COUNTRY, O, B-DATE, I-DATE, I-DATE, I-DATE, O, O, B-CITY, B-NUMBER, B-NATIONALITY, O, O, B-PERSON, I-PERSON, O, B-PERSON, I-PERSON, O, O, B-AGE, O, B-EVENT, O, B-EVENT, I-EVENT, I-EVENT, O, O, O, O, O, O, O, B-ORGANIZATION, O, O, O, B-ORGANIZATION, I-ORGANIZATION, I-ORGANIZATION, I-ORGANIZATION, I-ORGANIZATION, I-ORGANIZATION, I-ORGANIZATION, B-COUNTRY, O, B-ORGANIZATION, O, B-DATE, I-DATE, I-DATE, O, B-EVENT, I-EVENT, I-EVENT, I-EVENT, I-EVENT, B-LAW, I-LAW, I-LAW, I-LAW, O, B-COUNTRY, O, B-NUMBER, B-NATIONALITY, O, B-EVENT, O, B-CITY, O, B-DATE, I-DATE, I-DATE, I-DATE, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>В Польше найден мёртвым сын экс-президента Леха Валенсы\\nПолицейский автомобиль в Гданьске\\nВ Гданьске найден мёртвым в своей квартире сын экс-президента Польши Леха Валенсы.\\n\\nПо данным полиции, тело 43-летнего Пшемыслава Валенсы обнаружил его сын в квартире, где жил скончавшийся.\\nОн же и вызвал скорую помощь.\\nСейчас устанавливается причина смерти мужчины.\\n\\nПо предварительным данным, телесных повреждений на его теле не зафиксировано.\\nИзвестно, что ранее умерший сын бывшего президента неоднократно становился виновником ДТП из-за вождения в нетрезвом виде (в 1993 и 2003 годах).\\n\\nВсего у Леха Валенсы и его жены восемь детей — четверо сыновей и четыре дочери.\\nПшемыслав был третьим ребенком в семье, он родился в 1974 году.\\nУ него у самого два сына.\\nОдин из них — Доминик — попадал в скандал: ранил ножом свою девушку.\\n</td>\n",
       "      <td>[В, Польше, найден, мёртвым, сын, экс-, президента, Леха, Валенсы, Полицейский, автомобиль, в, Гданьске, В, Гданьске, найден, мёртвым, в, своей, квартире, сын, экс-, президента, Польши, президента, Польши, Леха, Валенсы, ., По, данным, полиции,, тело, 43-летнего, Пшемыслава, Валенсы, обнаружил, его, сын, в, квартире,, где, жил, скончавшийся., Он, же, и, вызвал, скорую, помощь., Сейчас, устанавливается, причина, смерти, мужчины., По, предварительным, данным,, телесных, повреждений, на, его, теле, не, зафиксировано., Известно,, что, ранее, умерший, сын, бывшего, президента, неоднократно, становился, виновником, ДТП, из-за, вождения, в, нетрезвом, виде, (, в, 1993, и, 2003, годах, )., Всего, у, Леха, Валенсы, и, его, жены, восемь, детей, —, четверо, сыновей, ...]</td>\n",
       "      <td>[O, B-COUNTRY, B-EVENT, I-EVENT, O, O, B-PROFESSION, B-PERSON, I-PERSON, O, O, O, B-CITY, O, B-CITY, B-EVENT, I-EVENT, O, O, O, O, O, B-PROFESSION, I-PROFESSION, B-PROFESSION, B-COUNTRY, B-PERSON, I-PERSON, O, O, O, O, O, B-AGE, B-PERSON, I-PERSON, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-PROFESSION, O, O, O, O, O, O, O, O, O, O, B-DATE, I-DATE, O, B-DATE, I-DATE, O, O, O, B-PERSON, I-PERSON, O, O, O, B-NUMBER, O, O, B-NUMBER, O, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>С последнего альбома Rammstein сняты все запреты\\n\\n\\nАдминистративный суд Кёльна снял с последнего альбома немецкой индастриал-метал группы Rammstein «Liebe ist für alle da» все ограничения на реализацию. Суд счёл необоснованными запрет на продажу альбома лицам до восемнадцати лет и цензуру обложки, которые были введены осенью прошлого года.\\nТилль Линдеманн с огнемётом на сцене.\\n\\n«Liebe ist für alle da» подвергся цензуре в ноябре 2009 года, когда Немецким Федеральным Комитетом по Оценке СМИ обложка диска была названа пропагандирующей садомазохизм. К тому же неприличным был объявлен текст песни «Ich tu dir weh», в результате чего композицию запретили для исполнения на публике.\\n\\nСуд Кёльна выносил вердикт, ссылаясь на отсутствие в песнях непосредственного упоминания действий насильственного характера. Также доводом в пользу снятия запретных мер стало то, что предыдущее решение не поясняло причин пагубного влияния описания садомазохизма на молодёжь. Таким образом, постановление суда разрешает распространение пластинки в прозрачной упаковке и даёт возможность покупать её детям младше восемнадцати лет.\\n\\nТем не менее, вердикт носит временный характер. Это связано с тем, что Комитет по Оценке СМИ решил опротестовать решение Кёльнского суда. По предварительным оценкам на процесс может уйти не менее полугода. В этот период планируется продавать альбом в обычном режиме, т.е без каких бы то ни было ограничений.\\n\\nКроме того, стоит отметить, что в феврале 2010 года Rammstein стали объектом жёсткой критики со стороны белорусских властей. Тогда в преддверии минского концерта группы Общественный совет по нравственности и Министерство культуры Белоруссии заподозрили немецких металлистов в пропаганде насилия, сексуальных извращений и нацизма.\\n\\nТем не менее раннее творчество Rammstein не вызывало столь критичного отношения со стороны государственных органов, несмотря на присутствие в нём темы сексуального насилия.\\n</td>\n",
       "      <td>[С, последнего, альбома, Rammstein, сняты, все, запреты, Административный, суд, Кёльна, Кёльна, снял, с, последнего, альбома, немецкой, индастриал-метал, группы, Rammstein, «, Liebe, ist, für, alle, da, », все, ограничения, на, реализацию, ., Суд, счёл, необоснованными, запрет, на, продажу, альбома, лицам, до, восемнадцати, лет, и, цензуру, обложки,, которые, были, введены, осенью, прошлого, года, ., Тилль, Линдеманн, с, огнемётом, на, сцене., «, Liebe, ist, für, alle, da, », подвергся, цензуре, в, ноябре, 2009, года, ,, когда, Немецким, Федеральным, Комитетом, по, Оценке, СМИ, Немецким, Федеральным, Комитетом, по, Оценке, СМИ, обложка, диска, была, названа, пропагандирующей, садомазохизм, садомазохизм, ., К, тому, же, неприличным, был, объявлен, текст, ...]</td>\n",
       "      <td>[O, O, O, B-ORGANIZATION, O, O, O, B-ORGANIZATION, I-ORGANIZATION, I-ORGANIZATION, B-CITY, O, O, O, O, B-COUNTRY, O, O, B-ORGANIZATION, O, B-WORK_OF_ART, I-WORK_OF_ART, I-WORK_OF_ART, I-WORK_OF_ART, I-WORK_OF_ART, O, O, B-EVENT, I-EVENT, I-EVENT, O, O, O, O, O, O, O, O, O, B-AGE, I-AGE, I-AGE, O, O, O, O, O, O, B-DATE, I-DATE, I-DATE, O, B-PERSON, I-PERSON, O, O, O, O, O, B-WORK_OF_ART, I-WORK_OF_ART, I-WORK_OF_ART, I-WORK_OF_ART, I-WORK_OF_ART, O, B-EVENT, I-EVENT, B-DATE, I-DATE, I-DATE, I-DATE, O, O, B-ORGANIZATION, I-ORGANIZATION, I-ORGANIZATION, I-ORGANIZATION, I-ORGANIZATION, I-ORGANIZATION, B-COUNTRY, O, O, O, O, O, O, O, O, O, B-CRIME, I-CRIME, B-IDEOLOGY, O, O, O, O, O, O, O, O, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Экс-губернатор Миннесоты метит в президенты\\n\\n''У Барака Обамы появился еще один соперник на предстоящих выборах президента Соединённых штатов''\\n\\nБывший губернатор штата Миннесота член Республиканской партии США Тим Поленти, официально заявил о своем вступлении в борьбу за то, чтобы представлять Республиканскую партию на предстоящих выборах президента США.\\n\\n«Нашей стране нужно новое руководство. Нам нужно вновь заставить работать нашу экономику. К сожалению, у президента Обамы не хватает мужества посмотреть простым американцам в глаза и рассказать им горькую правду о том, что мы должны будем сделать для того, чтобы обуздать наши расходы. А я это сделаю», — заявил Тим Поленти.\\n\\nПоленти 50 лет, в период с 2003 по 2011 годы он занимал пост губернатора Миннесоты, он не имеет большой известности в политической среде. Но некоторые аналитики полагают что у Поленти есть все шансы стать единым кандидатом от Республиканской партии. Сейчас фаворитом предвыборной гонки от его партии остается Митт Ромни.\\n\\nО первостепенных задачах Поленти рассказал на на телеканале NBC в программе «Сегодня»\\n</td>\n",
       "      <td>[Экс-, губернатор, Миннесоты, губернатор, Миннесоты, метит, в, президенты, ''У, Барака, Обамы, появился, еще, один, соперник, на, предстоящих, выборах, выборах, президента, президента, Соединённых, штатов, Соединённых, штатов, '', Бывший, губернатор, штата, Миннесота, губернатор, штата, Миннесота, губернатор, штата, Миннесота, член, Республиканской, партии, США, Республиканской, партии, США, Тим, Поленти, ,, официально, заявил, о, своем, вступлении, в, борьбу, за, то,, чтобы, представлять, Республиканскую, партию, Республиканскую, партию, на, предстоящих, выборах, выборах, президента, президента, США, США, ., «Нашей, стране, нужно, новое, руководство., Нам, нужно, вновь, заставить, работать, нашу, экономику., К, сожалению,, у, президента, Обамы, не, хватает, мужества, посмотреть, простым, американцам, в, глаза, и, рассказать, им, горькую, правду, ...]</td>\n",
       "      <td>[O, B-PROFESSION, I-PROFESSION, B-PROFESSION, B-STATE_OR_PROVINCE, O, O, B-PROFESSION, O, B-PERSON, I-PERSON, O, O, O, O, O, O, B-EVENT, B-EVENT, I-EVENT, B-PROFESSION, I-PROFESSION, I-PROFESSION, B-COUNTRY, I-COUNTRY, O, O, B-PROFESSION, I-PROFESSION, I-PROFESSION, B-PROFESSION, I-PROFESSION, I-PROFESSION, B-PROFESSION, O, B-STATE_OR_PROVINCE, O, B-ORGANIZATION, I-ORGANIZATION, I-ORGANIZATION, B-IDEOLOGY, O, B-COUNTRY, B-PERSON, I-PERSON, O, O, O, O, O, O, O, O, O, O, O, O, B-ORGANIZATION, I-ORGANIZATION, B-IDEOLOGY, O, O, O, B-EVENT, B-EVENT, I-EVENT, B-PROFESSION, I-PROFESSION, B-COUNTRY, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-PROFESSION, B-PERSON, O, O, O, O, O, B-NATIONALITY, O, O, O, O, O, O, O, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ФИФА: Роналду — лучший футболист, Зидан — тренер, Буффон — вратарь\\nКриштиану Роналду\\nВ понедельник, 23 октября 2017 года, в лондонском эстрадном театре «Палладиум» прошла церемония вручения наград ФИФА.\\n\\nНападающий «Реала» и сборной Португалии Криштиану Роналду признан лучшим футболистом 2017 года. Он опередил в споре за это звание Лионеля Месси («Барселона») и Неймара («Барселона»/«ПСЖ»).\\n\\nРоналду является действующим обладателем награды. В 2017 году в составе «Реала» он выиграл чемпионат Испании и Лигу чемпионов, став лучшим бомбардиром турнира.\\n\\nЗинедин Зидан\\nГлавный тренер мадридского «Реала» Зинедин Зидан стал лучшим тренером 2017 года. В споре за это звание он опередил главного тренера «Челси» Антонио Конте и рулевого «Ювентуса» Массимилиано Аллегри.\\n\\nДжанлуиджи Буффон\\nИтальянский голкипер Джанлуиджи Буффон (Ювентус) признан ФИФА лучшим вратарём года и стал первым обладателем этой награды. Получив приз, голкипер, которому в январе исполнится 40 лет, сказал, что он польщен получить столь почетное признание в таком почтенном возрасте.\\n\\nЛауреатом приза за честную игру от FIFA стал нападающий чешского клуба «Словацко» (1. FC Slovácko) Франсис Коне (Francis Koné), который во время матча с «Богемиансом» спас жизнь вратарю соперника Мартину Берковецу (Martin Berkovec). Голкипер врезался в своего защитника и потерял сознание. У Берковеца запал язык, и Коне оказал ему первую помощь.\\n\\nПолузащитник испанской «Барселоны» и сборной Нидерландов Лике Мартенс признана лучшей футболисткой года. В составе сборной Нидерландов она стала чемпионкой Европы 2017 года. Мартенс забила три мяча, сделала две голевые передачи и получила звание лучшего игрока турнира.\\n\\nЛучшими болельщиками года стали фанаты «Селтика».\\n\\nНа протяжении шести лет ФИФА вручала лучшему игроку планеты «Золотой мяч» совместно с редакцией журнала ''France Football'', однако с 2016 года французское издание, учредившее свой приз в 1956 году, и ФИФА вновь вручают награды по отдельности.\\n</td>\n",
       "      <td>[ФИФА, :, Роналду, —, лучший, футболист, футболист, ,, Зидан, —, тренер, ,, Буффон, —, вратарь, Криштиану, Роналду, В, понедельник,, 23, октября, 2017, года, ,, в, лондонском, эстрадном, театре, «, Палладиум, », прошла, церемония, вручения, наград, ФИФА, ., Нападающий, Нападающий, «Реала, Реала, », и, сборной, Португалии, Португалии, Криштиану, Роналду, признан, лучшим, футболистом, лучшим, футболистом, 2017, года, футболистом, 2017, года, ., Он, опередил, в, споре, за, это, звание, Лионеля, Месси, («, Барселона, »), и, Неймара, («, Барселона, »/«, ПСЖ, »)., Роналду, является, действующим, обладателем, награды., В, 2017, году, в, составе, «, Реала, », он, выиграл, чемпионат, Испании, Испании, и, Лигу, чемпионов, ,, ...]</td>\n",
       "      <td>[B-ORGANIZATION, O, B-PERSON, O, B-AWARD, I-AWARD, B-PROFESSION, O, B-PERSON, O, B-PROFESSION, O, B-PERSON, O, B-PROFESSION, B-PERSON, I-PERSON, B-DATE, I-DATE, I-DATE, I-DATE, I-DATE, I-DATE, O, O, B-CITY, O, O, O, B-FACILITY, O, O, B-EVENT, I-EVENT, I-EVENT, B-ORGANIZATION, O, B-PROFESSION, B-PROFESSION, I-PROFESSION, B-ORGANIZATION, O, O, B-ORGANIZATION, I-ORGANIZATION, B-COUNTRY, B-PERSON, I-PERSON, O, B-AWARD, I-AWARD, B-AWARD, I-AWARD, I-AWARD, I-AWARD, B-PROFESSION, B-DATE, I-DATE, O, O, O, O, O, O, O, O, B-PERSON, I-PERSON, O, B-ORGANIZATION, O, O, B-PERSON, O, B-ORGANIZATION, O, B-ORGANIZATION, O, B-PERSON, O, O, O, O, B-DATE, I-DATE, I-DATE, O, O, O, B-ORGANIZATION, O, O, O, B-EVENT, I-EVENT, B-COUNTRY, O, B-EVENT, I-EVENT, O, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Во время взрыва автомобиля в Киеве пострадала модель Dior\\nМагазин Christian Dior\\nВ автомобиле, который взорвался вчера, 8 сентября 2017 года, в районе Бессарабской площади в Киеве находилась модель Christian Dior Наталья Кошель, ей оторвало ногу, также она получила травмы глаз, сообщают СМИ.\\n\\nРанее подруга девушки Оксана Лазебник сообщила СМИ, что в момент взрыва в машине находилась «всемирно известная модель, которая является лицом марки Dior».\\n\\nВ настоящее время за её жизнь борются врачи 17-й больницы украинской столицы.\\nЗаведующий отделением политравм киевской больницы № 17 Дмитрий Мясников заявил, что женщину оперируют три бригады хирургов.\\n\\n«У пациентки есть термическая травма, ожоги, поражения органов, травма костей и травма мягких тканей», — сказал врач.\\n\\nМодель находилась в машине вместе с шестилетним мальчиком по имени Антон. Ребёнка доставили в ожоговый центр. О его состоянии ничего не сообщается.\\n\\nИз-за взрыва на месте происшествия погиб находившийся в машине гражданин Грузии боец чеченского батальона имени шейха Мансура чеченец Тимур Махаури.\\n\\nИнцидент произошел в пятницу около 18:00 между ул. Бассейной и Большой Васильковской. Взорвавшийся автомобиль «Тойота Камри» полностью уничтожен.\\n\\nДиректор департамента коммуникации МВД Украины Артём Шевченко сообщал СМИ:\\nСегодня произошел взрыв автомобиля, в котором находились три человека. Это человек, который погиб, женщина, которая получила серьезные повреждения и сейчас за ее жизнь борются медики, и ребенок, выживший и жизни которого ничего не угрожает.\\n\\nПо словам Шевченко, в 2017 году Махаури — «лицо, достаточно известное в криминальных кругах, которое имело устойчивые связи с разного рода чеченскими кругами», был задержан за незаконное хранение оружия. Позже он заключил сделку со следствием и получил условный срок.\\n\\nВозбуждено уголовное производство по ст. 115 ч. 2 «Умышленное убийство, совершенное общественно опасным способом». Согласно предварительным данным, в автомобиле сработало взрывное устройство.\\n\\nПолиция и Нацгвардия усилили патрулирование центра Киева и метро после взрыва на Бессарабке.\\n</td>\n",
       "      <td>[Во, время, взрыва, взрыва, автомобиля, в, Киеве, пострадала, модель, модель, Dior, Dior, Магазин, Christian, Dior, В, автомобиле,, который, взорвался, вчера,, 8, сентября, 2017, года, ,, в, районе, Бессарабской, площади, в, Киеве, находилась, модель, модель, Christian, Dior, Christian, Dior, Наталья, Кошель, ,, ей, оторвало, ногу, ,, также, она, получила, травмы, глаз, ,, сообщают, СМИ., Ранее, подруга, девушки, Оксана, Лазебник, сообщила, СМИ,, что, в, момент, взрыва, в, машине, находилась, «всемирно, известная, модель, ,, которая, является, лицом, марки, Dior, »., В, настоящее, время, за, её, жизнь, борются, врачи, 17-й, больницы, украинской, украинской, столицы, ., Заведующий, отделением, политравм, киевской, больницы, №, 17, Заведующий, отделением, ...]</td>\n",
       "      <td>[O, O, B-EVENT, B-EVENT, I-EVENT, O, B-CITY, O, B-PROFESSION, B-PROFESSION, I-PROFESSION, B-ORGANIZATION, O, B-ORGANIZATION, I-ORGANIZATION, O, O, O, B-EVENT, B-DATE, I-DATE, I-DATE, I-DATE, I-DATE, O, O, O, B-FACILITY, I-FACILITY, O, B-CITY, O, B-PROFESSION, B-PROFESSION, I-PROFESSION, I-PROFESSION, B-ORGANIZATION, I-ORGANIZATION, B-PERSON, I-PERSON, O, O, B-DISEASE, I-DISEASE, O, O, O, O, B-DISEASE, I-DISEASE, O, O, O, O, O, O, B-PERSON, I-PERSON, O, O, O, O, O, B-EVENT, O, O, O, O, O, B-PROFESSION, O, O, O, O, O, B-ORGANIZATION, O, O, O, O, O, O, O, O, O, B-FACILITY, I-FACILITY, B-COUNTRY, B-CITY, I-CITY, O, B-PROFESSION, I-PROFESSION, I-PROFESSION, I-PROFESSION, I-PROFESSION, I-PROFESSION, I-PROFESSION, B-PROFESSION, I-PROFESSION, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Экс-советник Трампа получил от российских компаний $68 000\\nМайкл Флинн\\nОтставной генерал Армии США Майкл Флинн, которого президент Дональд Трамп назначил, а затем под давлением общества уволил с поста советника по национальной безопасности, в 2015 году получил почти 68 000 долларов от российских компаний.\\n\\nОб этом стало известно из недавно обнародованных документов.\\n\\nПолученная Флинном сумма, оказавшаяся выше, чем предполагалось ранее, в основном состоит из вознаграждения в размере 45 386 долларов, которое ему выплатил российский государственный телеканал RT.\\n\\nФлинн приезжал в Москву по случаю 10-летнего юбилея канала и присутствовал на торжественном приёме, где сидел за одним столом с российским президентом Владимиром Путиным.\\n\\nКроме того, Флинн получил два платежа по 11 250 долларов: один — от американского филиала российской компании в области кибербезопасности, другой — от чартерных авиалиний «Волга-Днепр».\\n\\nПодробности о полученных Флинном платежах привёл конгрессмен Элайджа Каммингс (Elijah Cummings), главный демократ в комитете по надзору Палаты представителей.\\n\\nВ письме, обращённом к Трампу, министру обороны Джиму Мэттису и директору ФБР Джеймсу Коми, Каммингс спросил, предоставил ли Флинн правительству полную информацию о своих связях с Россией и Турцией, прежде чем прошёл проверку благонадёжности и был назначен на должность в Белом доме.\\n</td>\n",
       "      <td>[Экс-, советник, Трампа, Трампа, получил, от, российских, компаний, $68, 000, Майкл, Флинн, Отставной, генерал, генерал, Армии, США, Армии, США, США, Майкл, Флинн, ,, которого, президент, Дональд, Трамп, назначил,, а, затем, под, давлением, общества, уволил, с, поста, советника, по, национальной, безопасности, ,, в, 2015, году, получил, почти, 68, 000, долларов, от, российских, компаний., Об, этом, стало, известно, из, недавно, обнародованных, документов., Полученная, Флинном, сумма,, оказавшаяся, выше,, чем, предполагалось, ранее,, в, основном, состоит, из, вознаграждения, в, размере, 45, 386, долларов, ,, которое, ему, выплатил, российский, государственный, телеканал, RT, ., Флинн, приезжал, в, Москву, по, случаю, 10-летнего, юбилея, канала, и, присутствовал, на, торжественном, ...]</td>\n",
       "      <td>[O, B-PROFESSION, I-PROFESSION, B-PERSON, O, O, B-COUNTRY, O, B-MONEY, I-MONEY, B-PERSON, I-PERSON, O, B-PROFESSION, B-PROFESSION, I-PROFESSION, I-PROFESSION, B-ORGANIZATION, I-ORGANIZATION, B-COUNTRY, B-PERSON, I-PERSON, O, O, B-PROFESSION, B-PERSON, I-PERSON, O, O, O, O, O, O, O, O, O, B-PROFESSION, I-PROFESSION, I-PROFESSION, I-PROFESSION, O, B-DATE, I-DATE, I-DATE, O, B-MONEY, I-MONEY, I-MONEY, I-MONEY, O, B-COUNTRY, O, O, O, O, O, O, O, O, O, O, B-PERSON, O, O, O, O, O, O, O, O, O, O, O, O, O, B-MONEY, I-MONEY, I-MONEY, O, O, O, O, B-COUNTRY, O, O, B-ORGANIZATION, O, B-PERSON, O, O, B-CITY, O, O, B-AGE, O, O, O, O, O, B-EVENT, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Максим Орешкин назначен министром экономического развития\\nМаксим Орешкин\\n30 ноября 2016 года новым министром экономического развития назначен 34-летний Максим Орешкин, который ранее занимал пост заместителя министра финансов.\\n\\nПрезидент РФ Владимир Путин спросил у Орешкина, что по его мнению самое важное в работе ведомства, на что тот ответил:\\nСамое плохое уже позади и сейчас важно подготовить ключевые меры, которые позволят снять структурные преграды для роста российской экономики.\\n\\nПосле чего Путин ответил:\\nМаксим Станиславович, вы человек достаточно молодой, но молодым специалистом вас уже не назовешь. Вы человек грамотный и зрелый специалист, опытный. Я желаю вам удачи.\\n\\nМаксим Орешкин родился в 1982 году. Свою юность провёл в Москве, Ховрино. Орешкин имеет десятилетний стаж в коммерческой сфере, поработав в «Росбанк», «ВТБ-Капитал», также занимал пост ведущего экономиста в Центробанке и успел поработать в правительстве директором департамента, затем заместителем министра финансов.\\n</td>\n",
       "      <td>[Максим, Орешкин, назначен, министром, экономического, развития, Максим, Орешкин, 30, ноября, 2016, года, новым, министром, экономического, развития, министром, экономического, развития, назначен, 34-летний, Максим, Орешкин, ,, который, ранее, занимал, пост, заместителя, министра, финансов, министра, финансов, ., Президент, Президент, РФ, РФ, Владимир, Путин, спросил, у, Орешкина, ,, что, по, его, мнению, самое, важное, в, работе, ведомства,, на, что, тот, ответил:, Самое, плохое, уже, позади, и, сейчас, важно, подготовить, ключевые, меры,, которые, позволят, снять, структурные, преграды, для, роста, российской, экономики., После, чего, Путин, ответил:, Максим, Станиславович, ,, вы, человек, достаточно, молодой,, но, молодым, специалистом, вас, уже, не, назовешь., Вы, человек, грамотный, и, зрелый, специалист,, ...]</td>\n",
       "      <td>[B-PERSON, I-PERSON, B-EVENT, B-PROFESSION, I-PROFESSION, I-PROFESSION, B-PERSON, I-PERSON, B-DATE, I-DATE, I-DATE, I-DATE, O, B-PROFESSION, I-PROFESSION, I-PROFESSION, B-PROFESSION, O, O, B-EVENT, B-AGE, B-PERSON, I-PERSON, O, O, O, O, O, B-PROFESSION, I-PROFESSION, I-PROFESSION, B-PROFESSION, I-PROFESSION, O, B-PROFESSION, B-PROFESSION, I-PROFESSION, B-COUNTRY, B-PERSON, I-PERSON, O, O, B-PERSON, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-COUNTRY, O, O, O, B-PERSON, O, B-PERSON, I-PERSON, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Умер один из создателей мазера и лазера Чарлз Таунс\\nЧарлз Таунс\\nВ минувший вторник, 27 января 2015 года, в Окленде (штат Калифорния, США) в возрасте 99 лет умер американский физик, нобелевский лауреат Чарлз Таунс, чьи изобретения привели к созданию мазера и лазера.\\n\\nОсновные труды Таунса посвящены радиоспектроскопии, квантовой электронике и её приложениям, нелинейной оптике, радиоастрономии. Независимо от Александра Прохорова и Николая Басова выдвинул идею нового принципа генерации и усиления электромагнитных волн и на его основе совместно с сотрудниками создал первый квантовый генератор — мазер на аммиаке (1954). В 1958 году совместно с Артуром Шавловым обосновали и запатентовали возможность создания оптического квантового генератора (лазера). В 1964 году «за фундаментальные работы в области квантовой электроники, которые привели к созданию излучателей и усилителей на лазерно-мазерном принципе», Таунс совместно с Николаем Басовым и Александром Прохоровым был удостоен Нобелевской премии по физике.\\n\\nСозданные лазеры Таунс применил для высокоточной проверки эффектов теории относительности, для проведения исследований в области биологии и медицины. В области нелинейной оптики Таунс обнаружил вынужденное рассеяние Мандельштама — Бриллюэна, ввёл представление о критической мощности пучка света и явлении самофокусировки (1964).\\n\\nТаунс применил методы квантовой электроники и нелинейной оптики в астрофизике и совместно с другими в 1969 открыл мазерный эффект в космосе (излучение космических молекул воды на длине волны 1,35 см).\\n\\nЧарлз Хард Таунс родился в Гринвилле, там же учился, в 1935 году окончил Фурманский университет, в 1939 — в Калифорнийский технологический институт. В 1939—1948 — работал в фирме «Белл телефон», в 1948—1961 — в Колумбийском университете (с 1950 в должности профессора). В 1961—1966 Таунс являлся профессором и президентом Массачусетского технологического института, с 1967 возглавлял физический отдел Калифорнийского университета (Беркли). В 1967 году был избран президентом Американского физического общества.\\n</td>\n",
       "      <td>[Умер, один, из, создателей, мазера, и, лазера, Чарлз, Таунс, Чарлз, Таунс, В, минувший, вторник,, 27, января, 2015, года, ,, в, Окленде, (штат, Калифорния, ,, США, ), в, возрасте, 99, лет, умер, американский, физик, ,, нобелевский, лауреат, Чарлз, Таунс, ,, чьи, изобретения, привели, к, созданию, мазера, и, лазера., Основные, труды, Таунса, посвящены, радиоспектроскопии,, квантовой, электронике, и, её, приложениям,, нелинейной, оптике,, радиоастрономии., Независимо, от, Александра, Прохорова, и, Николая, Басова, выдвинул, идею, нового, принципа, генерации, и, усиления, электромагнитных, волн, и, на, его, основе, совместно, с, сотрудниками, создал, первый, квантовый, генератор, —, мазер, на, аммиаке, (, 1954, )., В, 1958, году, совместно, с, Артуром, ...]</td>\n",
       "      <td>[B-EVENT, O, O, O, O, O, O, B-PERSON, I-PERSON, B-PERSON, I-PERSON, B-DATE, I-DATE, I-DATE, I-DATE, I-DATE, I-DATE, I-DATE, O, O, B-CITY, O, B-STATE_OR_PROVINCE, O, B-COUNTRY, O, O, O, B-AGE, I-AGE, O, B-NATIONALITY, B-PROFESSION, O, B-AWARD, O, B-PERSON, I-PERSON, O, O, O, O, O, O, O, O, O, O, O, B-PERSON, O, O, O, O, O, O, O, O, O, O, O, O, B-PERSON, I-PERSON, O, B-PERSON, I-PERSON, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-ORDINAL, O, O, O, O, O, O, O, B-DATE, O, B-DATE, I-DATE, I-DATE, O, O, B-PERSON, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Прокуратура предлагает ограничить свободу передвижения Александра Лебедева\\nАлександр Лебедев\\nСергей Полонский\\nВ пятницу — 28 июня 2013 года российская прокуратура обратилась в московский суд с просьбой ограничить свободу передвижения медиамагната Александра Лебедева на 21 месяц за избиение своего оппонента — Сергея Полонского на телешоу.\\nИнтересно, что сам пострадавший попросил суд не наказывать обвиняемого.\\n\\nПри этом обвинение не потребовало для Лебедева тюремного заключения.\\n\\nФинансовый покровитель британских газет Independent и London Evening Standard, Лебедев говорит, что судебный процесс над ним является местью Кремля критику правительства и совладельцу российской газеты, которая критически настроена в отношении президента Владимира Путина.\\n\\nОн также видит в разбирательстве сигнал другим магнатам российского бизнеса.\\n\\nВ заключении по делу Лебедева прокуратура завила, что его следует признать виновным в проявлении ненависти по политическим мотивам, запретить менять место жительства или работу без уведомления властей и принимать участие в организации публичных мероприятий в течение года и девяти месяцев.\\n\\nСудья имеет право вынести более суровый приговор, если признает Лебедева виновным в хулиганстве и нанесении побоев.\\n\\nЭти статьи предусматривают наказание до пяти лет тюремного заключение, но вынесение такого вердикта маловероятно, учитывая обращение прокурора.\\n\\nРешение суда ожидается в понедельник.\\n\\nСуд над 53-летним Лебедевым начался в мае и был связан с дракой 2011 года, когда во время записи телевизионного ток-шоу он вскочил со стула и несколько рас ударил бизнесмена Сергея Полонского.\\n\\nЛебедев признал свое участие в драке, но отверг обвинения в хулиганстве и политической ненависти. Во время выступления прокурора он молча сидел, скрестив ноги и работая со своим планшетным компьютером.\\n\\nГлавной же сенсацией сегодняшнего заседания стало поступившее от потерпевшего заявление, в котором он якобы прощает обвиняемого и просит суд «не выносить обвинительный приговор Лебедеву в связи с тем, что тюрьму он не выдержит, а штраф для него незначимое наказание. Прошу простить Лебедева за его психическую неуравновешенность».\\n</td>\n",
       "      <td>[Прокуратура, предлагает, ограничить, свободу, передвижения, Александра, Лебедева, Александр, Лебедев, Сергей, Полонский, В, пятницу, —, 28, июня, 2013, года, российская, российская, прокуратура, прокуратура, обратилась, в, московский, московский, суд, с, просьбой, ограничить, свободу, передвижения, медиамагната, Александра, Лебедева, на, 21, месяц, за, избиение, своего, оппонента, —, Сергея, Полонского, на, телешоу., Интересно,, что, сам, пострадавший, попросил, суд, не, наказывать, обвиняемого., При, этом, обвинение, не, потребовало, для, Лебедева, тюремного, заключения, ., Финансовый, покровитель, британских, газет, Independent, и, London, Evening, Standard, London, Evening, Standard,, Лебедев, говорит,, что, судебный, процесс, над, ним, является, местью, Кремля, критику, правительства, и, совладельцу, российской, газеты, российской, газеты,, которая, критически, настроена, в, ...]</td>\n",
       "      <td>[B-ORGANIZATION, O, B-PENALTY, I-PENALTY, I-PENALTY, B-PERSON, I-PERSON, B-PERSON, I-PERSON, B-PERSON, I-PERSON, B-DATE, I-DATE, I-DATE, I-DATE, I-DATE, I-DATE, I-DATE, B-COUNTRY, B-ORGANIZATION, I-ORGANIZATION, B-ORGANIZATION, O, O, B-CITY, B-ORGANIZATION, I-ORGANIZATION, O, O, B-PENALTY, I-PENALTY, I-PENALTY, B-PROFESSION, B-PERSON, I-PERSON, B-DATE, I-DATE, I-DATE, O, B-CRIME, O, O, O, B-PERSON, I-PERSON, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-PERSON, B-PENALTY, I-PENALTY, O, O, O, B-COUNTRY, O, B-ORGANIZATION, O, B-ORGANIZATION, I-ORGANIZATION, I-ORGANIZATION, B-CITY, O, O, B-PERSON, O, O, B-EVENT, I-EVENT, O, O, O, O, B-ORGANIZATION, O, B-ORGANIZATION, O, O, B-ORGANIZATION, I-ORGANIZATION, B-COUNTRY, O, O, O, O, O, ...]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 268
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n9qywopnIrJH"
   },
   "source": [
    "## Preprocessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YVx71GdAIrJH"
   },
   "source": [
    "Before we can feed those texts to our model, we need to preprocess them. This is done by a 🤗 Transformers `Tokenizer` which will (as the name indicates) tokenize the inputs (including converting the tokens to their corresponding IDs in the pretrained vocabulary) and put it in a format the model expects, as well as generate the other inputs that model requires.\n",
    "\n",
    "To do all of this, we instantiate our tokenizer with the `AutoTokenizer.from_pretrained` method, which will ensure:\n",
    "\n",
    "- we get a tokenizer that corresponds to the model architecture we want to use,\n",
    "- we download the vocabulary used when pretraining this specific checkpoint.\n",
    "\n",
    "That vocabulary will be cached, so it's not downloaded again the next time we run the cell."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "eXNLu_-nIrJI",
    "ExecuteTime": {
     "end_time": "2024-04-10T09:22:15.711264Z",
     "start_time": "2024-04-10T09:22:14.648741Z"
    }
   },
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ],
   "outputs": [],
   "execution_count": 269
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vl6IidfdIrJK"
   },
   "source": [
    "The following assertion ensures that our tokenizer is a fast tokenizers (backed by Rust) from the 🤗 Tokenizers library. Those fast tokenizers are available for almost all models, and we will need some of the special features they have for our preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-n0_1lnuYoUo",
    "ExecuteTime": {
     "end_time": "2024-04-10T09:22:15.735617Z",
     "start_time": "2024-04-10T09:22:15.722620Z"
    }
   },
   "source": [
    "import transformers\n",
    "assert isinstance(tokenizer, transformers.PreTrainedTokenizerFast)"
   ],
   "outputs": [],
   "execution_count": 270
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5nZHUROIYoUo"
   },
   "source": [
    "You can check which type of models have a fast tokenizer available and which don't on the [big table of models](https://huggingface.co/transformers/index.html#bigtable)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rowT4iCLIrJK"
   },
   "source": [
    "You can directly call this tokenizer on one sentence:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "a5hBlsrHIrJL",
    "outputId": "acdaa98a-a8cd-4a20-89b8-cc26437bbe90",
    "ExecuteTime": {
     "end_time": "2024-04-10T09:22:16.150438Z",
     "start_time": "2024-04-10T09:22:16.137458Z"
    }
   },
   "source": [
    "tokenizer(\"Hello, this is one sentence!\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 67124, 70471, 121, 26802, 13218, 30046, 118080, 12894, 177, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 271
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i28NrDEPYoUt"
   },
   "source": [
    "Depending on the model you selected, you will see different keys in the dictionary returned by the cell above. They don't matter much for what we're doing here (just know they are required by the model we will instantiate later), you can learn more about them in [this tutorial](https://huggingface.co/transformers/preprocessing.html) if you're interested.\n",
    "\n",
    "If, as is the case here, your inputs have already been split into words, you should pass the list of words to your tokenzier with the argument `is_split_into_words=True`:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "pteRZjrYYoUt",
    "outputId": "0eb65824-32c6-47e6-faab-298f97ae1749",
    "ExecuteTime": {
     "end_time": "2024-04-10T09:22:16.906183Z",
     "start_time": "2024-04-10T09:22:16.899938Z"
    }
   },
   "source": [
    "tokenizer([\"Hello\", \",\", \"this\", \"is\", \"one\", \"sentence\", \"split\", \"into\", \"words\", \".\"], is_split_into_words=True)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 67124, 70471, 121, 26802, 13218, 30046, 118080, 12894, 16994, 69821, 443, 42038, 119660, 454, 126, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 272
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gati9HKdYoUt"
   },
   "source": [
    "Note that transformers are often pretrained with subword tokenizers, meaning that even if your inputs have been split into words already, each of those words could be split again by the tokenizer. Let's look at an example of that:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "O3HfxAqUYoUt",
    "outputId": "5404d8cc-5203-4b13-c9d7-0cb393201451",
    "ExecuteTime": {
     "end_time": "2024-04-10T09:22:17.732955Z",
     "start_time": "2024-04-10T09:22:17.726517Z"
    }
   },
   "source": [
    "example = train_dataset[4]\n",
    "print(example[\"tokens\"])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Facebook', 'нашел', 'нового', 'финансового', 'директора', 'Финансовым', 'директором', 'социальной', 'сети', 'Facebook', 'назначен', '39-летний', 'Дэвид', 'Эберсман', '(', 'David', 'Ebersman', '),', 'сообщает', 'The', 'Wall', 'Street', 'Journal', '.', 'На', 'работу', 'в', 'Facebook', 'он', 'выйдет', 'в', 'сентябре', '.', 'Ранее', 'Эберсман', 'был', 'финансовым', 'директором', 'биотехнологической', 'компании', 'Genentech', '.', 'Эберсман', 'подчеркнул,', 'что', 'видит', 'много', 'общего', 'между', 'Facebook', 'и', 'Genentech', '.', 'В', 'частности,', 'это', 'две', 'быстрорастущие', 'компании', 'с', 'сильной', 'корпоративной', 'культурой.', 'Также', 'он', 'заявил,', 'что', 'Facebook', 'ожидает', '70-процентное', 'увеличение', 'выручки', 'в', '2009', 'году', '.', 'В', 'компании', 'Genentech', 'Дэвид', 'Эберсман', 'проработал', '15', 'лет', '.', 'Ее', 'финансовым', 'директором', 'он', 'стал', 'в', '2006', 'году', '.', 'На', 'этой', 'должности', 'Эберсман', 'проработал', 'до', 'апреля', '2009', 'года', ',', 'когда', 'Roche', 'Holding', 'купил', 'Genentech', '.', 'По', 'данным', 'The', 'Wall', 'Street', 'Journal', ',', 'на', 'должность', 'финансового', 'директора', 'финансового', 'директора', 'Facebook', 'Facebook', 'претендовали', '11', 'кандидатов.', 'Каждый', 'из', 'них', 'прошел', 'собеседование', 'с', 'основателем', 'Facebook', 'Марком', 'Цукербергом', '(', 'Mark', 'Zuckerberg', ')', 'и', 'другими', 'руководителями', 'компании', '.', 'Ранее', 'финансовым', 'директором', 'финансовым', 'директором', 'Facebook', 'Facebook', 'был', 'Гидеон', 'Ю', '(', 'Gideon', 'Yu', ').', 'Он', 'покинул', 'компанию', 'три', 'месяца', 'назад', '.', 'Вместо', 'него', 'социальная', 'сеть', 'решила', 'нанять', 'топ-менеджера', 'с', 'опытом', 'работы', 'в', 'публичной', 'компании.', 'Facebook', 'является', 'крупнейшей', 'западной', 'социальной', 'сетью.', 'За', 'пять', 'лет', 'существования', 'этого', 'проекта', 'его', 'аудитория', 'превысила', '200', 'миллионов', 'человек.']\n"
     ]
    }
   ],
   "execution_count": 273
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MPiR1SNxYoUt",
    "outputId": "3249e0f4-957a-4013-e1ed-9f67146c0c2f",
    "ExecuteTime": {
     "end_time": "2024-04-10T09:22:18.244377Z",
     "start_time": "2024-04-10T09:22:18.237036Z"
    }
   },
   "source": [
    "tokenized_input = tokenizer(example[\"tokens\"], is_split_into_words=True)\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "print(tokens)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'facebook', 'нашел', 'нового', 'финансового', 'директора', 'финансовым', 'директором', 'социально', '##и', 'сети', 'facebook', 'назначен', '39', '-', 'лет', '##нии', 'дэ', '##вид', 'э', '##бер', '##сман', '(', 'dav', '##id', 'e', '##ber', '##sm', '##an', ')', ',', 'сообщает', 'the', 'w', '##all', 'str', '##ee', '##t', 'j', '##ournal', '.', 'на', 'работу', 'в', 'facebook', 'он', 'выи', '##дет', 'в', 'сентябре', '.', 'ранее', 'э', '##бер', '##сман', 'был', 'финансовым', 'директором', 'биотехнологи', '##ческо', '##и', 'компании', 'gen', '##ente', '##ch', '.', 'э', '##бер', '##сман', 'подчеркнул', ',', 'что', 'видит', 'много', 'общего', 'между', 'facebook', 'и', 'gen', '##ente', '##ch', '.', 'в', 'частности', ',', 'это', 'две', 'быстрорасту', '##щие', 'компании', 'с', 'сильно', '##и', 'корпора', '##тивно', '##и', 'культуро', '##и', '.', 'также', 'он', 'заявил', ',', 'что', 'facebook', 'ожидает', '70', '-', 'процент', '##ное', 'увеличение', 'выручки', 'в', '2009', 'году', '.', 'в', 'компании', 'gen', '##ente', '##ch', 'дэ', '##вид', 'э', '##бер', '##сман', 'проработал', '15', 'лет', '.', 'ее', 'финансовым', 'директором', 'он', 'стал', 'в', '2006', 'году', '.', 'на', 'это', '##и', 'должности', 'э', '##бер', '##сман', 'проработал', 'до', 'апреля', '2009', 'года', ',', 'когда', 'ro', '##che', 'h', '##old', '##ing', 'купил', 'gen', '##ente', '##ch', '.', 'по', 'данным', 'the', 'w', '##all', 'str', '##ee', '##t', 'j', '##ournal', ',', 'на', 'должность', 'финансового', 'директора', 'финансового', 'директора', 'facebook', 'facebook', 'претендовали', '11', 'кандидатов', '.', 'кажды', '##и', 'из', 'них', 'прошел', 'собеседование', 'с', 'основателем', 'facebook', 'марк', '##ом', 'цу', '##кер', '##бергом', '(', 'mark', 'zu', '##ck', '##er', '##berg', ')', 'и', 'другими', 'руководителями', 'компании', '.', 'ранее', 'финансовым', 'директором', 'финансовым', 'директором', 'facebook', 'facebook', 'был', 'гид', '##е', '##он', 'ю', '(', 'g', '##ideo', '##n', 'y', '##u', ')', '.', 'он', 'покинул', 'компанию', 'три', 'месяца', 'назад', '.', 'вместо', 'него', 'социальная', 'сеть', 'решила', 'нанять', 'топ', '-', 'менеджера', 'с', 'опытом', 'работы', 'в', 'публично', '##и', 'компании', '.', 'facebook', 'является', 'круп', '##не', '##и', '##ше', '##и', 'западно', '##и', 'социально', '##и', 'сетью', '.', 'за', 'пять', 'лет', 'существования', 'этого', 'проекта', 'его', 'аудитория', 'превысила', '200', 'миллионов', 'человек', '.', '[SEP]']\n"
     ]
    }
   ],
   "execution_count": 274
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VPuTUJPhYoUt"
   },
   "source": [
    "Here the words \"Zwingmann\" and \"sheepmeat\" have been split in three subtokens.\n",
    "\n",
    "This means that we need to do some processing on our labels as the input ids returned by the tokenizer are longer than the lists of labels our dataset contain, first because some special tokens might be added (we can a `[CLS]` and a `[SEP]` above) and then because of those possible splits of words in multiple tokens:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "P21pkSmiYoUt",
    "outputId": "aca85ec0-3119-4967-dda8-91e24e4a9fd8",
    "ExecuteTime": {
     "end_time": "2024-04-10T09:22:19.216967Z",
     "start_time": "2024-04-10T09:22:19.212038Z"
    }
   },
   "source": [
    "len(example[f\"{task}_tags\"]), len(tokenized_input[\"input_ids\"])"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199, 283)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 275
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cdWxuHvoYoUu"
   },
   "source": [
    "Thankfully, the tokenizer returns outputs that have a `word_ids` method which can help us."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3FWUGBqQYoUu",
    "outputId": "7dbf269e-87d0-46c7-cd29-9244d43f08a7",
    "ExecuteTime": {
     "end_time": "2024-04-10T09:22:20.530392Z",
     "start_time": "2024-04-10T09:22:20.519374Z"
    }
   },
   "source": [
    "print(tokenized_input.word_ids())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 0, 1, 2, 3, 4, 5, 6, 7, 7, 8, 9, 10, 11, 11, 11, 11, 12, 12, 13, 13, 13, 14, 15, 15, 16, 16, 16, 16, 17, 17, 18, 19, 20, 20, 21, 21, 21, 22, 22, 23, 24, 25, 26, 27, 28, 29, 29, 30, 31, 32, 33, 34, 34, 34, 35, 36, 37, 38, 38, 38, 39, 40, 40, 40, 41, 42, 42, 42, 43, 43, 44, 45, 46, 47, 48, 49, 50, 51, 51, 51, 52, 53, 54, 54, 55, 56, 57, 57, 58, 59, 60, 60, 61, 61, 61, 62, 62, 62, 63, 64, 65, 65, 66, 67, 68, 69, 69, 69, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 78, 78, 79, 79, 80, 80, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 95, 96, 97, 97, 97, 98, 99, 100, 101, 102, 103, 104, 105, 105, 106, 106, 106, 107, 108, 108, 108, 109, 110, 111, 112, 113, 113, 114, 114, 114, 115, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 127, 128, 128, 129, 130, 131, 132, 133, 134, 135, 136, 136, 137, 137, 137, 138, 139, 140, 140, 140, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 155, 155, 156, 157, 158, 158, 158, 159, 159, 160, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 174, 174, 175, 176, 177, 178, 179, 179, 180, 180, 181, 182, 183, 183, 183, 183, 183, 184, 184, 185, 185, 186, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 198, None]\n"
     ]
    }
   ],
   "execution_count": 276
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hX6jEEBzYoUu"
   },
   "source": [
    "As we can see, it returns a list with the same number of elements as our processed input ids, mapping special tokens to `None` and all other tokens to their respective word. This way, we can align the labels with the processed input ids."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XY0QUrK5YoUu",
    "outputId": "bddcceab-a963-4483-c48a-cd5394a46cb6",
    "ExecuteTime": {
     "end_time": "2024-04-10T09:22:21.703751Z",
     "start_time": "2024-04-10T09:22:21.692054Z"
    }
   },
   "source": [
    "word_ids = tokenized_input.word_ids()\n",
    "aligned_labels = [-100 if i is None else example[f\"{task}_tags\"][i] for i in word_ids]\n",
    "print(len(aligned_labels), len(tokenized_input[\"input_ids\"]))\n",
    "for i in range(len(aligned_labels)):\n",
    "    print(*tokenizer.convert_ids_to_tokens([tokenized_input[\"input_ids\"][i]]), aligned_labels[i])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283 283\n",
      "[CLS] -100\n",
      "facebook B-ORGANIZATION\n",
      "нашел O\n",
      "нового O\n",
      "финансового B-PROFESSION\n",
      "директора I-PROFESSION\n",
      "финансовым B-PROFESSION\n",
      "директором I-PROFESSION\n",
      "социально O\n",
      "##и O\n",
      "сети O\n",
      "facebook B-ORGANIZATION\n",
      "назначен B-EVENT\n",
      "39 B-AGE\n",
      "- B-AGE\n",
      "лет B-AGE\n",
      "##нии B-AGE\n",
      "дэ B-PERSON\n",
      "##вид B-PERSON\n",
      "э I-PERSON\n",
      "##бер I-PERSON\n",
      "##сман I-PERSON\n",
      "( O\n",
      "dav B-PERSON\n",
      "##id B-PERSON\n",
      "e I-PERSON\n",
      "##ber I-PERSON\n",
      "##sm I-PERSON\n",
      "##an I-PERSON\n",
      ") O\n",
      ", O\n",
      "сообщает O\n",
      "the B-ORGANIZATION\n",
      "w I-ORGANIZATION\n",
      "##all I-ORGANIZATION\n",
      "str I-ORGANIZATION\n",
      "##ee I-ORGANIZATION\n",
      "##t I-ORGANIZATION\n",
      "j I-ORGANIZATION\n",
      "##ournal I-ORGANIZATION\n",
      ". O\n",
      "на O\n",
      "работу O\n",
      "в O\n",
      "facebook B-ORGANIZATION\n",
      "он O\n",
      "выи O\n",
      "##дет O\n",
      "в B-DATE\n",
      "сентябре I-DATE\n",
      ". O\n",
      "ранее O\n",
      "э B-PERSON\n",
      "##бер B-PERSON\n",
      "##сман B-PERSON\n",
      "был O\n",
      "финансовым B-PROFESSION\n",
      "директором I-PROFESSION\n",
      "биотехнологи O\n",
      "##ческо O\n",
      "##и O\n",
      "компании O\n",
      "gen B-ORGANIZATION\n",
      "##ente B-ORGANIZATION\n",
      "##ch B-ORGANIZATION\n",
      ". O\n",
      "э B-PERSON\n",
      "##бер B-PERSON\n",
      "##сман B-PERSON\n",
      "подчеркнул O\n",
      ", O\n",
      "что O\n",
      "видит O\n",
      "много O\n",
      "общего O\n",
      "между O\n",
      "facebook B-ORGANIZATION\n",
      "и O\n",
      "gen B-ORGANIZATION\n",
      "##ente B-ORGANIZATION\n",
      "##ch B-ORGANIZATION\n",
      ". O\n",
      "в O\n",
      "частности O\n",
      ", O\n",
      "это O\n",
      "две B-NUMBER\n",
      "быстрорасту O\n",
      "##щие O\n",
      "компании O\n",
      "с O\n",
      "сильно O\n",
      "##и O\n",
      "корпора O\n",
      "##тивно O\n",
      "##и O\n",
      "культуро O\n",
      "##и O\n",
      ". O\n",
      "также O\n",
      "он O\n",
      "заявил O\n",
      ", O\n",
      "что O\n",
      "facebook B-ORGANIZATION\n",
      "ожидает O\n",
      "70 B-PERCENT\n",
      "- B-PERCENT\n",
      "процент B-PERCENT\n",
      "##ное B-PERCENT\n",
      "увеличение O\n",
      "выручки O\n",
      "в B-DATE\n",
      "2009 I-DATE\n",
      "году I-DATE\n",
      ". O\n",
      "в O\n",
      "компании O\n",
      "gen B-ORGANIZATION\n",
      "##ente B-ORGANIZATION\n",
      "##ch B-ORGANIZATION\n",
      "дэ B-PERSON\n",
      "##вид B-PERSON\n",
      "э I-PERSON\n",
      "##бер I-PERSON\n",
      "##сман I-PERSON\n",
      "проработал O\n",
      "15 B-DATE\n",
      "лет I-DATE\n",
      ". O\n",
      "ее O\n",
      "финансовым B-PROFESSION\n",
      "директором I-PROFESSION\n",
      "он O\n",
      "стал O\n",
      "в B-DATE\n",
      "2006 I-DATE\n",
      "году I-DATE\n",
      ". O\n",
      "на O\n",
      "это O\n",
      "##и O\n",
      "должности O\n",
      "э B-PERSON\n",
      "##бер B-PERSON\n",
      "##сман B-PERSON\n",
      "проработал O\n",
      "до B-DATE\n",
      "апреля I-DATE\n",
      "2009 I-DATE\n",
      "года I-DATE\n",
      ", O\n",
      "когда O\n",
      "ro B-ORGANIZATION\n",
      "##che B-ORGANIZATION\n",
      "h I-ORGANIZATION\n",
      "##old I-ORGANIZATION\n",
      "##ing I-ORGANIZATION\n",
      "купил B-EVENT\n",
      "gen B-ORGANIZATION\n",
      "##ente B-ORGANIZATION\n",
      "##ch B-ORGANIZATION\n",
      ". O\n",
      "по O\n",
      "данным O\n",
      "the B-ORGANIZATION\n",
      "w I-ORGANIZATION\n",
      "##all I-ORGANIZATION\n",
      "str I-ORGANIZATION\n",
      "##ee I-ORGANIZATION\n",
      "##t I-ORGANIZATION\n",
      "j I-ORGANIZATION\n",
      "##ournal I-ORGANIZATION\n",
      ", O\n",
      "на O\n",
      "должность O\n",
      "финансового B-PROFESSION\n",
      "директора I-PROFESSION\n",
      "финансового B-PROFESSION\n",
      "директора I-PROFESSION\n",
      "facebook I-PROFESSION\n",
      "facebook B-ORGANIZATION\n",
      "претендовали O\n",
      "11 B-NUMBER\n",
      "кандидатов O\n",
      ". O\n",
      "кажды O\n",
      "##и O\n",
      "из O\n",
      "них O\n",
      "прошел O\n",
      "собеседование O\n",
      "с O\n",
      "основателем O\n",
      "facebook B-ORGANIZATION\n",
      "марк B-PERSON\n",
      "##ом B-PERSON\n",
      "цу I-PERSON\n",
      "##кер I-PERSON\n",
      "##бергом I-PERSON\n",
      "( O\n",
      "mark B-PERSON\n",
      "zu I-PERSON\n",
      "##ck I-PERSON\n",
      "##er I-PERSON\n",
      "##berg I-PERSON\n",
      ") O\n",
      "и O\n",
      "другими O\n",
      "руководителями B-PROFESSION\n",
      "компании I-PROFESSION\n",
      ". O\n",
      "ранее O\n",
      "финансовым B-PROFESSION\n",
      "директором I-PROFESSION\n",
      "финансовым B-PROFESSION\n",
      "директором I-PROFESSION\n",
      "facebook I-PROFESSION\n",
      "facebook B-ORGANIZATION\n",
      "был O\n",
      "гид B-PERSON\n",
      "##е B-PERSON\n",
      "##он B-PERSON\n",
      "ю I-PERSON\n",
      "( O\n",
      "g B-PERSON\n",
      "##ideo B-PERSON\n",
      "##n B-PERSON\n",
      "y I-PERSON\n",
      "##u I-PERSON\n",
      ") O\n",
      ". O\n",
      "он O\n",
      "покинул B-EVENT\n",
      "компанию I-EVENT\n",
      "три B-DATE\n",
      "месяца I-DATE\n",
      "назад I-DATE\n",
      ". O\n",
      "вместо O\n",
      "него O\n",
      "социальная O\n",
      "сеть O\n",
      "решила O\n",
      "нанять O\n",
      "топ B-PROFESSION\n",
      "- B-PROFESSION\n",
      "менеджера B-PROFESSION\n",
      "с O\n",
      "опытом O\n",
      "работы O\n",
      "в O\n",
      "публично O\n",
      "##и O\n",
      "компании O\n",
      ". O\n",
      "facebook B-ORGANIZATION\n",
      "является O\n",
      "круп O\n",
      "##не O\n",
      "##и O\n",
      "##ше O\n",
      "##и O\n",
      "западно B-LOCATION\n",
      "##и B-LOCATION\n",
      "социально O\n",
      "##и O\n",
      "сетью O\n",
      ". O\n",
      "за B-DATE\n",
      "пять I-DATE\n",
      "лет I-DATE\n",
      "существования O\n",
      "этого O\n",
      "проекта O\n",
      "его O\n",
      "аудитория O\n",
      "превысила O\n",
      "200 B-NUMBER\n",
      "миллионов I-NUMBER\n",
      "человек O\n",
      ". O\n",
      "[SEP] -100\n"
     ]
    }
   ],
   "execution_count": 277
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nejP5Y5DYoUu"
   },
   "source": [
    "Here we set the labels of all special tokens to -100 (the index that is ignored by PyTorch) and the labels of all other tokens to the label of the word they come from. Another strategy is to set the label only on the first token obtained from a given word, and give a label of -100 to the other subtokens from the same word. We propose the two strategies here, just change the value of the following flag:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DSfs0DqCYoUu",
    "ExecuteTime": {
     "end_time": "2024-04-10T09:22:22.977607Z",
     "start_time": "2024-04-10T09:22:22.974782Z"
    }
   },
   "source": [
    "label_all_tokens = True"
   ],
   "outputs": [],
   "execution_count": 278
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2C0hcmp9IrJQ"
   },
   "source": [
    "We're now ready to write the function that will preprocess our samples. We feed them to the `tokenizer` with the argument `truncation=True` (to truncate texts that are bigger than the maximum size allowed by the model) and `is_split_into_words=True` (as seen above). Then we align the labels with the token ids using the strategy we picked:"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T09:22:24.066217Z",
     "start_time": "2024-04-10T09:22:24.058013Z"
    }
   },
   "cell_type": "code",
   "source": [
    "label2id = {\n",
    "    'O': 0,\n",
    "    'B-AGE': 1,\n",
    "    'I-AGE': 2,\n",
    "    'B-AWARD': 3,\n",
    "    'I-AWARD': 4,\n",
    "    'B-CITY': 5,\n",
    "    'I-CITY': 6,\n",
    "    'B-COUNTRY': 7,\n",
    "    'I-COUNTRY': 8,\n",
    "    'B-CRIME': 9,\n",
    "    'I-CRIME': 10,\n",
    "    'B-DATE': 11,\n",
    "    'I-DATE': 12,\n",
    "    'B-DISEASE': 13,\n",
    "    'I-DISEASE': 14,\n",
    "    'B-DISTRICT': 15,\n",
    "    'I-DISTRICT': 16,\n",
    "    'B-EVENT': 17,\n",
    "    'I-EVENT': 18,\n",
    "    'B-FACILITY': 19,\n",
    "    'I-FACILITY': 20,\n",
    "    'B-FAMILY': 21,\n",
    "    'I-FAMILY': 22,\n",
    "    'B-IDEOLOGY': 23,\n",
    "    'I-IDEOLOGY': 24,\n",
    "    'B-LANGUAGE': 25,\n",
    "    'I-LANGUAGE': 26,\n",
    "    'B-LAW': 27,\n",
    "    'I-LAW': 28,\n",
    "    'B-LOCATION': 29,\n",
    "    'I-LOCATION': 30,\n",
    "    'B-MONEY': 31,\n",
    "    'I-MONEY': 32,\n",
    "    'B-NATIONALITY': 33,\n",
    "    'I-NATIONALITY': 34,\n",
    "    'B-NUMBER': 35,\n",
    "    'I-NUMBER': 36,\n",
    "    'B-ORDINAL': 37,\n",
    "    'I-ORDINAL': 38,\n",
    "    'B-ORGANIZATION': 39,\n",
    "    'I-ORGANIZATION': 40,\n",
    "    'B-PENALTY': 41,\n",
    "    'I-PENALTY': 42,\n",
    "    'B-PERCENT': 43,\n",
    "    'I-PERCENT': 44,\n",
    "    'B-PERSON': 45,\n",
    "    'I-PERSON': 46,\n",
    "    'B-PRODUCT': 47,\n",
    "    'I-PRODUCT': 48,\n",
    "    'B-PROFESSION': 49,\n",
    "    'I-PROFESSION': 50,\n",
    "    'B-RELIGION': 51,\n",
    "    'I-RELIGION': 52,\n",
    "    'B-STATE_OR_PROVINCE': 53,\n",
    "    'I-STATE_OR_PROVINCE': 54,\n",
    "    'B-TIME': 55,\n",
    "    'I-TIME': 56,\n",
    "    'B-WORK_OF_ART': 57,\n",
    "    'I-WORK_OF_ART': 58,\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 279
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vc0BSBLIIrJQ",
    "ExecuteTime": {
     "end_time": "2024-04-10T09:22:24.652702Z",
     "start_time": "2024-04-10T09:22:24.646651Z"
    }
   },
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    \n",
    "    transformed = {\"id\": [], \"text\": [], \"tokens\": [], \"ner_tags\": []}\n",
    "    \n",
    "    for idx, text, entities in zip(examples[\"id\"], examples[\"text\"], examples[\"entities\"]):\n",
    "        tokens, ner_tags = transform(text, transform_entities(entities))\n",
    "        transformed[\"id\"].append(idx)\n",
    "        transformed[\"text\"].append(text)\n",
    "        transformed[\"tokens\"].append(tokens)\n",
    "        transformed[\"ner_tags\"].append(ner_tags)\n",
    "    \n",
    "    tokenized_inputs = tokenizer(transformed[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(transformed[f\"{task}_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
    "            # ignored in the loss function.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            # We set the label for the first token of each word.\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label2id[label[word_idx]])\n",
    "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
    "            # the label_all_tokens flag.\n",
    "            else:\n",
    "                label_ids.append(label2id[label[word_idx]] if label_all_tokens else -100)\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ],
   "outputs": [],
   "execution_count": 280
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0lm8ozrJIrJR"
   },
   "source": [
    "This function works with one or several examples. In the case of several examples, the tokenizer will return a list of lists for each key:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-b70jh26IrJS",
    "outputId": "acd3a42d-985b-44ee-9daa-af5d944ce1d9",
    "ExecuteTime": {
     "end_time": "2024-04-10T09:22:25.784008Z",
     "start_time": "2024-04-10T09:22:25.750924Z"
    }
   },
   "source": "tokenize_and_align_labels(datasets[\"train\"][:5])",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 56081, 121, 37009, 107, 3594, 378, 1004, 1022, 29653, 36666, 113, 15568, 10060, 35797, 4308, 113, 1461, 4356, 809, 9381, 197, 8535, 197, 4216, 9381, 197, 8535, 197, 4216, 1355, 162, 3902, 1461, 4356, 385, 121, 167, 2684, 197, 5880, 133, 19361, 390, 19361, 390, 197, 126, 19893, 7528, 73689, 54896, 73689, 54896, 8201, 113, 4308, 121, 15568, 10060, 21578, 67899, 67899, 113, 1461, 4356, 809, 121, 56081, 121, 37009, 107, 3594, 378, 1004, 1022, 29653, 121, 1762, 703, 6697, 2262, 133, 4167, 115, 384, 387, 73689, 54896, 115, 384, 387, 115, 384, 387, 73689, 54896, 73689, 54896, 126, 152, 113, 2972, 5303, 14455, 133, 22294, 2008, 6824, 771, 89786, 6288, 152, 44732, 152, 113, 2257, 6569, 809, 120, 24042, 23009, 121, 113, 4308, 121, 94152, 9485, 133, 28225, 49857, 73689, 54896, 73689, 54896, 107, 15568, 10060, 21578, 67899, 67899, 121, 14204, 107, 36666, 162, 4439, 89209, 41096, 110, 7564, 3985, 52226, 107, 110, 62046, 26369, 26998, 121, 2900, 33131, 19842, 167, 121, 7889, 60827, 121, 1363, 13509, 11766, 377, 8283, 726, 381, 705, 741, 1586, 133, 695, 19842, 121, 2439, 30297, 700, 44489, 747, 34296, 121, 1363, 118216, 1560, 73822, 121, 2439, 3594, 378, 1004, 1022, 29653, 110, 7564, 3985, 52226, 73920, 4995, 121, 4439, 57028, 19842, 159, 34463, 8283, 14913, 666, 121, 2395, 57955, 152, 121, 133, 3165, 113, 4810, 115, 384, 387, 126, 2262, 133, 4167, 5432, 121, 693, 660, 2105, 39930, 152, 113, 4308, 6719, 1456, 5545, 14623, 67899, 14623, 67899, 67899, 121, 62688, 60629, 115268, 121, 107, 1355, 9804, 121, 5990, 39185, 734, 67899, 849, 5303, 111956, 377, 110, 13932, 66146, 23059, 734, 22672, 10760, 4960, 121, 9115, 1698, 113, 3514, 1012, 28345, 152, 126, 4741, 22049, 121, 113, 4308, 904, 16311, 107, 19888, 3414, 17928, 126, 152, 1363, 32815, 121, 74359, 415, 18270, 26531, 19842, 167, 121, 7889, 60827, 121, 15494, 44295, 18270, 26531, 19842, 159, 34463, 121, 1363, 32650, 26531, 19842, 2721, 34463, 121, 113, 8038, 16921, 18270, 121, 34824, 19842, 1586, 34463, 113, 13148, 103236, 18270, 121, 8283, 81898, 160, 119492, 15863, 158, 34824, 160, 16656, 4995, 158, 10365, 18270, 121, 9485, 18270, 38940, 15339, 700, 40208, 4825, 121, 8154, 18270, 38940, 15339, 700, 18260, 14913, 666, 152, 121, 133, 3165, 113, 2262, 133, 17228, 126, 2262, 133, 4167, 115, 384, 387, 115, 384, 387, 5553, 121, 693, 8621, 654, 15070, 7415, 10722, 12534, 12534, 1461, 4356, 657, 1461, 4356, 657, 126, 794, 86425, 381, 33846, 121, 4276, 1922, 7991, 40332, 376, 4937, 121, 3025, 1938, 377, 5880, 126, 4937, 121, 40332, 376, 118, 2382, 67899, 67899, 48956, 15565, 73689, 54896, 73689, 54896, 121, 14275, 113, 14804, 110, 47902, 3476, 73689, 54896, 73689, 54896, 121, 2422, 703, 6697, 4123, 2262, 133, 3629, 14623, 67899, 2262, 133, 3629, 14623, 67899, 14623, 67899, 67899, 126, 152, 780, 11286, 14275, 660, 2209, 73689, 54896, 110, 47902, 107, 10402, 73689, 917, 86774, 378, 73689, 917, 86774, 378, 152, 121, 133, 1239, 11653, 6218, 126, 24699, 107, 4937, 152, 8267, 113, 34840, 654, 37836, 3476, 110, 4655, 7975, 19217, 1874, 63147, 849, 40772, 152, 121, 33611, 29934, 29934, 101151, 14876, 101151, 14876, 126, 152, 3158, 107, 11286, 6719, 771, 1906, 104663, 73689, 917, 73689, 917, 86774, 378, 152, 121, 133, 5432, 2262, 133, 4167, 126, 22149, 67899, 67899, 3542, 38108, 152, 50229, 70301, 152, 107, 31334, 14142, 693, 152, 67899, 107, 73689, 79261, 3029, 707, 12258, 7641, 654, 40003, 19217, 1874, 1501, 988, 378, 73689, 54896, 152, 126, 2262, 133, 4167, 1907, 702, 378, 3838, 378, 9302, 1907, 702, 378, 1907, 702, 378, 3838, 378, 9302, 3108, 110870, 113, 17809, 11158, 152, 81452, 381, 152, 7291, 73689, 54896, 73689, 54896, 13790, 21530, 1260, 667, 378, 14092, 110, 8411, 7332, 4385, 126, 152, 5439, 18924, 121, 43415, 110, 2206, 28166, 121, 8758, 22149, 67899, 67899, 152, 121, 133, 3617, 1938, 377, 5880, 113, 2262, 133, 4713, 9302, 126, 102], [101, 32429, 666, 668, 690, 10902, 10239, 87352, 380, 21093, 2598, 2598, 80666, 54896, 80666, 54896, 32429, 666, 668, 690, 10902, 10239, 113, 3754, 110870, 768, 3636, 24503, 13820, 2467, 378, 4900, 126, 5171, 795, 53614, 25381, 15129, 70507, 4910, 121, 862, 378, 12502, 80666, 1533, 28839, 80666, 1533, 28839, 1748, 2271, 934, 60675, 378, 21178, 21178, 2202, 390, 36250, 27009, 97208, 121, 794, 86425, 381, 1835, 2358, 3866, 11412, 7508, 3495, 2662, 51771, 654, 32721, 378, 8849, 7508, 3495, 2662, 51771, 654, 32721, 378, 8849, 3495, 2662, 51771, 654, 32721, 378, 8849, 2662, 2662, 51771, 51771, 654, 32721, 378, 8849, 126, 60762, 17172, 70507, 4910, 121, 1981, 26563, 660, 2849, 113, 84626, 84626, 118, 4676, 118, 4676, 121, 1281, 672, 5488, 126, 785, 2422, 152, 192, 152, 2969, 2262, 133, 3629, 94070, 2662, 2262, 133, 3629, 94070, 2662, 94070, 94070, 2662, 2662, 110183, 8083, 32429, 668, 5426, 1005, 121, 5171, 32429, 666, 668, 690, 10902, 10239, 8447, 14958, 721, 17612, 4050, 2467, 378, 4900, 126, 6397, 133, 1049, 939, 25381, 5885, 70507, 883, 121, 2944, 1310, 946, 378, 113, 6109, 36286, 654, 9457, 16169, 7832, 121, 106, 2478, 1578, 73272, 23059, 734, 690, 378, 833, 748, 4900, 118, 4676, 118, 4676, 121, 8370, 1373, 3866, 113, 7660, 4949, 878, 126, 2875, 33963, 98493, 4776, 12020, 15965, 121, 7856, 946, 378, 5517, 21178, 27305, 4050, 4900, 2202, 390, 36250, 27009, 97208, 126, 1748, 2271, 113, 10118, 5115, 1480, 94070, 94070, 20620, 9620, 18687, 152, 36524, 6556, 6556, 152, 121, 7526, 3480, 17172, 36250, 27009, 97208, 113, 3170, 160, 4888, 8146, 36250, 27009, 10239, 905, 45503, 660, 2849, 113, 116721, 158, 126, 4430, 834, 19278, 378, 1073, 3170, 844, 14274, 660, 4681, 17172, 690, 10902, 97208, 152, 19595, 113847, 394, 1251, 19595, 113847, 394, 1251, 152, 121, 113, 2567, 795, 36451, 3462, 20900, 378, 4282, 107, 16592, 152, 27186, 102634, 102634, 152, 681, 52294, 863, 114, 7369, 386, 8741, 126, 785, 15968, 152, 192, 152, 180, 2840, 121, 5464, 9278, 14871, 4925, 3170, 29062, 7174, 1078, 377, 1005, 672, 32438, 1180, 10419, 32429, 666, 868, 690, 10902, 97208, 3913, 92855, 377, 126, 660, 1373, 768, 6304, 27801, 113, 80666, 1022, 1196, 672, 2575, 126, 2969, 28937, 2969, 28937, 152, 7114, 378, 44422, 152, 7114, 378, 44422, 44422, 152, 29062, 7174, 43467, 6035, 1689, 152, 192, 152, 121, 693, 118, 3170, 1177, 4654, 73272, 4988, 654, 4448, 21178, 4050, 80666, 702, 378, 4900, 80666, 702, 378, 80666, 702, 378, 4900, 126, 152, 736, 27603, 1715, 9247, 126, 795, 2526, 10654, 1818, 89467, 1841, 31394, 152, 121, 133, 1239, 795, 126, 6534, 73272, 3754, 110870, 21178, 5500, 152, 192, 152, 113, 80666, 702, 378, 80666, 702, 378, 4900, 5742, 7413, 118, 20620, 9362, 99540, 748, 5106, 917, 33799, 107, 24259, 113, 25670, 1591, 670, 126, 152, 934, 14837, 2202, 390, 36250, 27009, 97208, 14408, 6232, 102644, 121, 1003, 7023, 5148, 32243, 654, 5968, 110, 44368, 3476, 152, 121, 133, 3308, 11653, 152, 192, 152, 126, 654, 806, 1923, 121, 9495, 10866, 3168, 121, 693, 15987, 3816, 113, 80666, 702, 378, 8849, 1020, 4746, 4483, 703, 5900, 110, 690, 1181, 686, 29616, 118479, 121, 2224, 113, 4578, 7893, 121, 693, 2969, 2656, 27262, 152, 9964, 106886, 747, 12297, 121, 862, 378, 113, 4270, 3302, 7183, 700, 104521, 22632, 4050, 4900, 152, 126, 7979, 27300, 5089, 121, 693, 2541, 11476, 1011, 1716, 15478, 121, 785, 8146, 70507, 883, 121, 1293, 17506, 11246, 152, 15591, 2450, 152, 121, 934, 1093, 785, 14381, 7336, 3269, 17172, 690, 10902, 97208, 110, 31444, 10353, 126, 113, 49087, 702, 378, 49087, 702, 378, 18526, 152, 192, 152, 3617, 121, 693, 5171, 834, 8146, 70507, 883, 2702, 6336, 17817, 660, 3866, 32506, 15703, 32506, 15703, 4900, 118, 4676, 4900, 118, 4676, 118, 4676, 126, 3048, 104, 25887, 3445, 4050, 2467, 378, 4900, 32429, 666, 668, 690, 10902, 10239, 121, 654, 1923, 17172, 32429, 668, 5426, 2568, 121, 1281, 672, 8447, 126, 654, 66672, 2206, 152, 192, 152, 121, 113, 2847, 6118, 59052, 660, 1373, 3866, 20621, 22346, 22346, 104, 377, 375, 152, 80666, 14667, 152, 80666, 14667, 152, 116238, 378, 21817, 3463, 121, 7943, 755, 6520, 390, 113, 14804, 152, 44781, 17227, 57964, 6536, 152, 107, 5296, 17557, 33820, 5329, 110870, 17832, 73272, 126, 785, 3542, 6811, 81666, 4925, 1857, 110870, 10330, 3086, 75278, 110358, 823, 121, 1688, 15226, 13779, 152, 68036, 76769, 651, 152, 121, 107, 2969, 2656, 1079, 12734, 17172, 21817, 10029, 785, 1942, 16885, 50468, 55249, 660, 6594, 2662, 4960, 126, 152, 849, 13448, 752, 1688, 15226, 1079, 9667, 1184, 114845, 378, 121, 1009, 29616, 19559, 121, 12902, 1788, 707, 734, 806, 14495, 378, 26106, 107, 8129, 11414, 7535, 3495, 152, 121, 133, 1689, 8146, 110358, 823, 126, 49087, 727, 378, 22576, 2652, 12355, 28249, 2532, 10239, 121, 7880, 121, 3542, 121, 693, 3975, 3071, 672, 104, 60762, 376, 121, 106, 104, 152, 16582, 5398, 917, 44263, 152, 126, 654, 806, 1923, 121, 2598, 121, 15477, 1981, 110586, 779, 1458, 1748, 121, 17355, 4881, 2470, 5512, 11780, 7892, 375, 376, 1613, 113, 77601, 15319, 378, 39695, 133, 818, 834, 121, 785, 11569, 2944, 2048, 133, 5900, 115, 384, 387, 654, 80666, 54896, 115, 384, 387, 654, 80666, 54896, 80666, 54896, 690, 1799, 1181, 389, 96309, 17742, 121, 1981, 934, 21178, 734, 10399, 9146, 113, 14804, 26867, 5401, 133, 33402, 126, 102], [101, 6556, 105657, 19986, 53070, 1806, 113, 38158, 376, 21688, 10482, 13644, 1970, 133, 50417, 5260, 160, 139, 78967, 393, 158, 121, 2514, 2077, 51320, 53070, 736, 378, 3034, 126, 654, 2206, 152, 192, 152, 121, 1205, 2081, 2037, 21961, 133, 113, 6473, 13448, 661, 14432, 660, 19615, 8213, 133, 8074, 3034, 113, 38158, 376, 113, 9024, 660, 1818, 51607, 1942, 53070, 126, 2224, 681, 22319, 11239, 6556, 818, 107, 672, 103740, 110, 73703, 73272, 121, 693, 1079, 41543, 1003, 4988, 113, 3034, 126, 60530, 53070, 53070, 139, 78967, 393, 139, 78967, 393, 2077, 2037, 13108, 13967, 660, 3665, 39472, 736, 378, 3034, 113, 152, 89356, 10912, 385, 10912, 385, 152, 126, 5206, 755, 378, 5550, 113, 1019, 5952, 905, 15336, 660, 21479, 1111, 7193, 113, 110919, 121, 8619, 1981, 15949, 55871, 4001, 7906, 107, 6255, 14306, 3034, 126, 1882, 834, 904, 5429, 2335, 104, 8213, 133, 7822, 139, 78967, 393, 139, 78967, 393, 126, 6556, 6145, 24841, 5026, 64100, 133, 9663, 121, 750, 113, 2972, 12410, 76933, 10471, 5023, 10670, 665, 38158, 389, 126, 9271, 121, 785, 3308, 152, 192, 152, 1354, 734, 5414, 696, 378, 4417, 121, 6556, 28038, 25589, 100036, 2656, 711, 3814, 16437, 162, 44991, 6536, 44991, 6536, 139, 78967, 393, 139, 78967, 393, 2081, 2037, 12830, 51771, 51771, 126, 2686, 60530, 27133, 44991, 6536, 139, 78967, 393, 44991, 6536, 139, 78967, 393, 113, 2972, 18847, 10293, 904, 1861, 94504, 133, 110919, 9220, 1707, 2775, 680, 44113, 1847, 126, 2224, 736, 5032, 22014, 126, 2598, 2598, 51771, 51771, 116, 4851, 1030, 10133, 4171, 15958, 14385, 39601, 110, 73703, 73272, 114, 1470, 2574, 126, 4741, 62102, 13644, 121, 44991, 2081, 1202, 672, 34041, 4258, 1049, 121, 4821, 1470, 133, 1049, 939, 6166, 2218, 113, 33103, 73272, 10998, 107, 35034, 24272, 54896, 1313, 126, 785, 3308, 152, 192, 152, 5500, 113, 12007, 12007, 51771, 51771, 121, 1025, 113, 7125, 904, 14355, 51607, 660, 2241, 6047, 2048, 133, 4477, 13390, 42594, 390, 132, 829, 7128, 377, 121, 862, 378, 794, 86425, 381, 1733, 63520, 2403, 2662, 51771, 654, 37578, 80043, 389, 24609, 2662, 51771, 51771, 654, 37578, 80043, 389, 24609, 107, 6347, 113, 1991, 11525, 152, 2588, 44019, 152, 2588, 44019, 152, 126, 2224, 8146, 132, 829, 7128, 6444, 6613, 126, 654, 1923, 26740, 110, 1823, 19654, 121, 152, 6634, 3034, 849, 1263, 672, 2330, 52782, 152, 126, 5500, 152, 192, 152, 113, 12007, 6529, 17110, 2812, 654, 133, 7865, 162, 152, 780, 12855, 121, 693, 35442, 967, 794, 2314, 21563, 132, 829, 7128, 389, 6309, 121, 700, 1981, 672, 28001, 126, 750, 9486, 672, 25248, 152, 126, 21981, 110, 10260, 42594, 686, 132, 829, 7128, 49761, 152, 192, 152, 5171, 672, 2845, 126, 934, 1164, 121, 654, 1923, 20026, 152, 192, 152, 121, 16936, 1025, 2493, 34995, 162, 6463, 9324, 62110, 80069, 378, 3875, 152, 2588, 44019, 152, 9324, 62110, 80069, 378, 3875, 152, 2588, 44019, 152, 2588, 44019, 152, 2414, 6520, 11527, 26495, 832, 107, 2048, 133, 2969, 83963, 152, 2588, 61557, 152, 83963, 152, 2588, 61557, 152, 4520, 378, 60294, 121, 6848, 928, 378, 10400, 133, 19137, 36014, 24626, 33048, 15263, 26767, 20322, 13512, 23015, 486, 11580, 100752, 2530, 6003, 12947, 30269, 126, 152, 119, 2289, 121, 693, 904, 6117, 794, 1555, 660, 3653, 66536, 6891, 104, 1109, 121, 1015, 22340, 112192, 113, 38158, 389, 60294, 377, 967, 26495, 2007, 152, 121, 133, 8496, 152, 192, 152, 12891, 36199, 6236, 121, 20894, 378, 110, 52238, 55216, 126, 750, 113, 4578, 4984, 11050, 126, 16348, 26495, 832, 107, 60294, 672, 53121, 5143, 126, 113, 2411, 1355, 2840, 5401, 133, 3848, 51771, 5401, 133, 3848, 51771, 42594, 394, 794, 2314, 11369, 8264, 121, 693, 6556, 1281, 818, 107, 672, 103740, 110, 73703, 73272, 660, 3866, 4050, 139, 78967, 393, 139, 78967, 393, 126, 14615, 11990, 121, 654, 2206, 152, 192, 152, 121, 1073, 67211, 113, 2171, 2396, 384, 756, 378, 5098, 126, 785, 3308, 152, 192, 152, 5500, 113, 12007, 121, 152, 6065, 7508, 2235, 734, 71204, 805, 675, 4921, 15851, 18255, 113, 38158, 389, 121, 2224, 42594, 394, 794, 2314, 1239, 121, 693, 672, 9810, 121, 4349, 6797, 1373, 1266, 2526, 114, 47168, 121, 818, 693, 107, 1688, 53171, 89790, 152, 126, 113, 4578, 44422, 1075, 26391, 121, 2633, 40119, 3398, 13390, 3398, 13390, 51771, 51771, 1379, 1062, 378, 131, 5885, 650, 121, 7042, 121, 5335, 121, 25728, 113, 38158, 389, 1151, 34995, 660, 3866, 53070, 53070, 139, 78967, 393, 139, 78967, 393, 126, 9008, 654, 4648, 121, 13448, 661, 16181, 13892, 7349, 5200, 3034, 8651, 2136, 104, 44991, 376, 660, 8394, 7193, 126, 736, 8496, 152, 192, 152, 1354, 734, 5414, 4417, 113, 38158, 376, 126, 152, 118, 1226, 1114, 3003, 11272, 45645, 4004, 5296, 16252, 8213, 133, 8074, 121, 42164, 107, 2455, 152, 121, 133, 1239, 795, 126, 3982, 20900, 378, 13021, 26657, 6167, 53070, 1114, 126, 785, 19924, 152, 192, 152, 113, 8970, 14667, 121, 849, 806, 31395, 2404, 121, 1015, 121, 654, 1138, 91841, 378, 3675, 121, 2762, 5414, 139, 78967, 393, 41517, 3130, 7906, 104, 8698, 3034, 121, 107, 110, 5123, 63195, 5155, 7349, 5414, 721, 1019, 2846, 1913, 13669, 378, 126, 660, 3246, 2840, 78739, 1146, 6825, 654, 139, 78967, 393, 13087, 4439, 734, 1741, 1970, 133, 5200, 162, 67722, 382, 121, 15022, 121, 63691, 121, 19939, 79261, 121, 1463, 61811, 387, 107, 696, 831, 653, 121, 106, 1080, 6556, 126, 750, 11110, 64071, 673, 14808, 104, 56687, 10487, 1707, 51771, 121, 19939, 79261, 107, 1463, 61811, 387, 126, 43632, 834, 113, 13201, 7829, 8387, 121, 18922, 13699, 662, 121, 11449, 121, 52094, 1421, 107, 94835, 5656, 844, 59793, 91841, 390, 110, 78739, 83027, 378, 119325, 126, 1201, 672, 2482, 8619, 5394, 691, 378, 6711, 113, 38158, 376, 121, 5335, 121, 39184, 660, 60530, 53070, 126, 818, 121, 11449, 5171, 4549, 7198, 3653, 1942, 13085, 133, 1205, 1579, 5401, 133, 2598, 5401, 133, 2598, 11449, 702, 378, 23231, 378, 33103, 73272, 2185, 11449, 702, 378, 23231, 378, 33103, 73272, 2185, 11449, 702, 378, 23231, 378, 33103, 73272, 2185, 8171, 6016, 19736, 662, 18952, 12758, 24366, 387, 126, 711, 1019, 4123, 745, 37524, 377, 113, 10912, 385, 745, 37524, 377, 113, 10912, 385, 36951, 13714, 97823, 133, 23529, 1798, 680, 783, 5171, 1689, 121, 693, 5979, 53070, 53070, 3034, 984, 2194, 113, 7339, 1947, 126, 152, 1081, 8619, 4417, 672, 99853, 654, 7114, 378, 108177, 121, 696, 44991, 660, 12622, 377, 378, 1838, 1363, 878, 1020, 5488, 113, 57341, 870, 4803, 152, 121, 133, 1689, 795, 126, 113, 1019, 1947, 121, 44991, 6536, 44991, 6536, 139, 78967, 393, 139, 78967, 393, 1020, 12117, 700, 67722, 649, 126, 1081, 2241, 10025, 4184, 59588, 107, 2455, 8619, 5394, 691, 378, 4417, 121, 118, 44422, 8122, 1363, 3665, 126, 960, 2985, 1020, 2188, 9136, 700, 3759, 53070, 53070, 139, 78967, 393, 139, 78967, 393, 107, 12688, 4299, 22541, 4351, 849, 1231, 22221, 121, 2188, 51607, 113, 1388, 939, 2105, 3197, 5744, 133, 696, 13085, 126, 750, 13122, 32587, 667, 378, 113, 60945, 12117, 1079, 9667, 103887, 16312, 152, 89356, 10912, 385, 10912, 385, 152, 113, 47387, 849, 13448, 752, 7086, 126, 102], [101, 44422, 1022, 44958, 11050, 88395, 152, 89356, 10912, 385, 10912, 385, 152, 4483, 4483, 44422, 44422, 672, 50805, 2775, 680, 22221, 12818, 12689, 12818, 12689, 13644, 1970, 133, 50417, 5260, 13644, 1970, 133, 50417, 5260, 160, 139, 78967, 393, 158, 121, 862, 378, 113, 17415, 2828, 7232, 152, 33103, 73272, 10912, 385, 10912, 385, 152, 126, 721, 1019, 3660, 5935, 152, 6701, 7210, 152, 126, 654, 1003, 2206, 121, 780, 52215, 95224, 700, 44422, 11050, 700, 46134, 73272, 1205, 6709, 121, 2686, 6556, 32350, 660, 29092, 139, 78967, 393, 113, 38158, 376, 1151, 1942, 13085, 126, 152, 6701, 7210, 152, 5432, 121, 693, 28921, 28893, 3034, 2081, 905, 2037, 21961, 162, 721, 1019, 121, 654, 17771, 10065, 7610, 121, 1916, 12233, 113, 6473, 4216, 878, 113, 110919, 121, 1040, 6556, 14432, 660, 19615, 8213, 133, 8074, 139, 78967, 393, 113, 38158, 376, 126, 44422, 1362, 44422, 1362, 4483, 4483, 1882, 19866, 375, 14545, 8213, 133, 8724, 113, 64100, 133, 9663, 376, 121, 2224, 113, 2972, 10471, 22828, 1922, 38158, 377, 126, 9495, 113, 44422, 25013, 51607, 113, 29531, 660, 3866, 53070, 53070, 152, 33103, 73272, 10912, 385, 152, 33103, 73272, 10912, 385, 10912, 385, 152, 6665, 4477, 13390, 42594, 390, 132, 829, 7128, 377, 126, 794, 86425, 381, 795, 4209, 63520, 2403, 2662, 654, 37578, 80043, 389, 24609, 2662, 654, 37578, 80043, 389, 24609, 107, 3155, 734, 11525, 152, 2588, 44019, 152, 11525, 152, 2588, 44019, 152, 126, 654, 2206, 152, 6701, 25498, 152, 121, 132, 829, 7128, 6444, 6613, 700, 46134, 73272, 1211, 6709, 126, 2478, 12665, 18840, 1025, 2493, 34995, 162, 7508, 9324, 62110, 80069, 378, 3875, 152, 2588, 44019, 152, 7508, 9324, 62110, 80069, 378, 3875, 152, 2588, 44019, 152, 2414, 6520, 48526, 26495, 2007, 107, 6665, 4050, 152, 2588, 91225, 152, 2588, 91225, 152, 4520, 390, 60294, 377, 126, 4984, 991, 1080, 11050, 27796, 139, 78967, 393, 126, 4741, 62102, 139, 78967, 393, 121, 4891, 394, 667, 378, 5906, 3034, 2081, 35034, 24272, 54896, 1313, 11785, 121, 4821, 1470, 133, 1049, 939, 6166, 2218, 113, 10998, 107, 1202, 672, 34041, 4258, 1049, 126, 654, 2206, 152, 6701, 25498, 152, 121, 660, 17856, 113, 38158, 376, 6556, 33383, 19347, 5979, 12818, 12689, 660, 21248, 9103, 126, 2224, 2455, 1909, 965, 49434, 1841, 10074, 126, 818, 121, 113, 11449, 376, 5089, 121, 693, 44991, 6536, 1079, 2037, 5401, 133, 2598, 11449, 702, 378, 23231, 378, 33103, 73272, 2185, 5401, 133, 2598, 11449, 702, 378, 23231, 378, 33103, 73272, 2185, 11449, 702, 378, 23231, 378, 33103, 73272, 2185, 8171, 6016, 19736, 662, 18952, 12758, 24366, 387, 126, 113, 3359, 139, 78967, 393, 8619, 3034, 85780, 1662, 83027, 378, 721, 52837, 13367, 107, 17137, 5260, 126, 7023, 736, 378, 3034, 660, 6750, 654, 5968, 110, 10912, 385, 160, 2542, 83027, 378, 1970, 133, 50417, 6130, 158, 113768, 162, 139, 78967, 393, 3732, 672, 1079, 27066, 660, 5445, 660, 21646, 5562, 126, 1201, 672, 2482, 121, 113, 3498, 2771, 1688, 7700, 6595, 98818, 126, 113, 6473, 4216, 878, 3200, 139, 78967, 393, 660, 5131, 1111, 4302, 9680, 113, 64100, 133, 9663, 376, 126, 6556, 1733, 2143, 691, 378, 1979, 85940, 912, 5260, 113, 2814, 121, 2686, 960, 1079, 15289, 660, 2125, 378, 7399, 113, 3034, 126, 3283, 44422, 121, 113, 139, 78967, 393, 9750, 1080, 67722, 382, 121, 7829, 8387, 121, 26309, 691, 378, 121, 18922, 13699, 662, 121, 15022, 121, 42696, 4804, 121, 11449, 121, 63691, 121, 19939, 79261, 121, 26533, 1955, 79261, 121, 52094, 1421, 121, 104, 377, 407, 121, 16959, 888, 121, 1463, 61811, 387, 107, 696, 831, 653, 107, 94835, 5656, 844, 59793, 91841, 390, 126, 102], [101, 78307, 6502, 3445, 15789, 6795, 32399, 13048, 11255, 378, 5273, 78307, 5488, 6655, 133, 1049, 939, 58774, 2732, 136, 1542, 19112, 160, 91101, 2769, 156, 7334, 70869, 1321, 158, 121, 1762, 3251, 217, 6116, 119811, 15706, 443, 263, 16598, 126, 660, 2849, 113, 78307, 795, 3640, 865, 113, 6517, 126, 2944, 136, 1542, 19112, 905, 32399, 13048, 102637, 80069, 378, 2185, 66512, 99338, 3575, 126, 136, 1542, 19112, 4675, 121, 693, 8176, 1349, 6639, 1289, 78307, 107, 66512, 99338, 3575, 126, 113, 3325, 121, 736, 2493, 113020, 2430, 2185, 110, 3584, 378, 6662, 4041, 378, 96480, 378, 126, 1080, 795, 1689, 121, 693, 78307, 15837, 4156, 133, 17089, 845, 13139, 33445, 113, 4206, 979, 126, 113, 2185, 66512, 99338, 3575, 58774, 2732, 136, 1542, 19112, 35738, 1470, 1049, 126, 1003, 32399, 13048, 795, 1579, 113, 5093, 979, 126, 660, 736, 378, 6709, 136, 1542, 19112, 35738, 708, 2866, 4206, 878, 121, 1040, 27847, 11266, 195, 13232, 2804, 12206, 66512, 99338, 3575, 126, 654, 2206, 3251, 217, 6116, 119811, 15706, 443, 263, 16598, 121, 660, 6047, 15789, 6795, 15789, 6795, 78307, 78307, 75336, 1741, 10074, 126, 2563, 378, 734, 1303, 6568, 72802, 110, 42657, 78307, 52071, 6536, 30313, 5007, 45520, 160, 83900, 111964, 28658, 1119, 14636, 158, 107, 3993, 36365, 2185, 126, 2944, 32399, 13048, 32399, 13048, 78307, 78307, 905, 46614, 376, 833, 132, 160, 203, 50707, 446, 207, 459, 158, 126, 795, 10114, 10400, 1463, 4907, 2271, 126, 3961, 1263, 29598, 9282, 7042, 45610, 9803, 133, 31630, 110, 14330, 2218, 113, 17664, 378, 2185, 126, 78307, 1733, 2143, 691, 378, 756, 378, 40395, 378, 11255, 378, 35427, 126, 681, 2762, 1049, 10470, 1164, 4522, 806, 34796, 40730, 1241, 3815, 1266, 126, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 33, 0, 0, 5, 5, 5, 11, 11, 11, 11, 11, 55, 55, 55, 55, 55, 56, 56, 56, 5, 5, 5, 0, 11, 12, 0, 39, 39, 39, 39, 7, 7, 0, 0, 39, 40, 40, 40, 7, 7, 0, 0, 0, 0, 0, 0, 33, 34, 7, 0, 5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11, 12, 39, 39, 39, 40, 40, 40, 40, 40, 39, 39, 39, 39, 39, 39, 40, 40, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 17, 0, 0, 0, 0, 0, 5, 5, 5, 0, 0, 0, 0, 0, 1, 1, 1, 33, 34, 34, 7, 7, 0, 0, 0, 33, 34, 7, 0, 17, 18, 18, 0, 35, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 35, 0, 0, 35, 35, 35, 36, 0, 35, 0, 0, 0, 0, 47, 47, 47, 47, 35, 35, 35, 36, 0, 35, 0, 0, 0, 0, 0, 0, 35, 0, 0, 0, 0, 35, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 35, 0, 0, 35, 36, 0, 47, 47, 0, 35, 0, 0, 0, 0, 0, 0, 0, 39, 39, 39, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 49, 50, 50, 39, 40, 7, 0, 0, 0, 0, 0, 0, 35, 49, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 49, 50, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 35, 0, 0, 35, 35, 0, 0, 0, 35, 35, 35, 36, 0, 35, 35, 0, 0, 0, 35, 36, 0, 35, 0, 0, 0, 35, 36, 0, 0, 0, 35, 0, 0, 0, 0, 35, 36, 0, 0, 35, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 35, 0, 0, 35, 0, 0, 0, 0, 0, 0, 0, 35, 0, 0, 0, 0, 0, 47, 47, 0, 0, 0, 0, 0, 0, 0, 0, 0, 39, 39, 39, 40, 40, 40, 39, 39, 39, 0, 0, 0, 0, 0, 0, 0, 0, 39, 39, 40, 40, 40, 5, 5, 5, 0, 55, 55, 55, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 39, 39, 40, 0, 0, 0, 0, 0, 0, 33, 34, 7, 39, 40, 40, 40, 7, 7, 0, 0, 0, 0, 0, 0, 39, 40, 40, 7, 7, 0, 0, 11, 12, 49, 50, 50, 50, 50, 50, 39, 39, 39, 40, 40, 39, 40, 7, 0, 0, 0, 0, 0, 0, 0, 7, 7, 0, 0, 0, 0, 39, 39, 40, 40, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 49, 0, 0, 0, 0, 0, 0, 0, 0, 39, 0, 0, 0, 0, 0, 0, 0, 39, 0, 0, 0, 7, 39, 40, 40, 39, 40, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 39, 39, 40, 40, 0, 0, 0, 0, 39, 39, 39, 0, 39, 40, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 0, 0, 39, 39, 39, 40, 40, 40, 40, 40, 40, 7, 7, 7, 39, 39, 39, 40, 40, 40, 0, 0, 0, 0, 0, 0, 19, 19, 0, 5, 6, 6, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 7, 49, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 39, 40, 7, 0, 0, 0, 0, 39, 39, 40, 0, 0, 0, 0, 0, 0, -100], [-100, 45, 45, 45, 46, 46, 46, 0, 0, 0, 49, 49, 50, 50, 53, 53, 45, 45, 45, 46, 46, 46, 0, 0, 0, 0, 0, 0, 49, 50, 50, 50, 0, 11, 0, 17, 45, 45, 46, 46, 0, 0, 0, 0, 39, 39, 40, 53, 53, 0, 11, 12, 0, 17, 17, 18, 17, 45, 45, 46, 46, 46, 0, 0, 0, 0, 0, 0, 0, 49, 50, 50, 50, 50, 50, 50, 50, 50, 49, 50, 50, 50, 50, 50, 50, 50, 39, 40, 40, 40, 40, 40, 40, 49, 49, 50, 7, 0, 0, 0, 0, 0, 0, 0, 45, 45, 0, 0, 0, 0, 0, 0, 39, 39, 40, 40, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 39, 0, 49, 50, 50, 50, 50, 50, 39, 39, 39, 40, 40, 53, 49, 50, 49, 45, 45, 46, 46, 46, 46, 0, 11, 45, 45, 45, 46, 46, 46, 17, 18, 0, 17, 49, 0, 0, 0, 0, 1, 1, 1, 1, 45, 45, 46, 46, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 49, 49, 50, 50, 50, 50, 50, 50, 50, 50, 50, 5, 5, 0, 17, 18, 18, 11, 12, 12, 12, 0, 0, 0, 0, 17, 17, 18, 0, 0, 0, 0, 0, 17, 0, 49, 50, 45, 45, 46, 46, 46, 0, 11, 12, 0, 0, 0, 0, 53, 49, 50, 0, 0, 0, 39, 40, 7, 0, 0, 0, 0, 0, 45, 45, 45, 0, 0, 0, 0, 0, 45, 45, 45, 0, 0, 0, 0, 0, 39, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 45, 45, 45, 0, 39, 40, 40, 40, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 39, 39, 39, 40, 0, 0, 0, 39, 40, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 39, 0, 11, 12, 0, 0, 39, 40, 40, 40, 45, 45, 46, 46, 46, 0, 0, 0, 0, 45, 45, 45, 46, 46, 46, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 53, 53, 0, 0, 0, 0, 49, 50, 49, 50, 50, 50, 50, 50, 50, 39, 39, 40, 7, 0, 45, 45, 46, 46, 0, 0, 39, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 17, 49, 50, 50, 50, 50, 53, 53, 53, 39, 39, 39, 40, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 39, 0, 0, 53, 53, 53, 39, 39, 39, 40, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 45, 45, 46, 46, 46, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 39, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 53, 53, 53, 0, 0, 0, 39, 0, 0, 0, 45, 45, 45, 46, 46, 0, 0, 0, 0, 0, 0, 0, 49, 50, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 49, 50, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 45, 45, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 45, 45, 45, 0, 39, 40, 0, 0, 5, 5, 5, 39, 39, 39, 40, 0, 39, 0, 0, 0, 0, 11, 0, 0, 45, 45, 0, 0, 17, 0, 0, 49, 50, 49, 50, 50, 50, 50, 39, 40, 40, 5, 5, 0, 0, 0, 0, 0, 49, 0, 0, 0, 45, 45, 45, 46, 46, 46, 0, 0, 0, 0, 45, 45, 45, 45, 0, 0, 0, 0, 0, 0, 0, 0, 0, 39, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 49, 49, 50, 50, 50, 50, 50, 50, 50, 39, 39, 0, 45, 45, 46, 46, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 49, 50, 50, 0, 0, 23, 45, 45, 46, 46, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 49, 50, 0, 0, 0, 45, 45, 0, 0, 0, 0, 0, 0, 0, 49, 50, 0, 0, 0, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 45, 45, 0, 0, 0, 0, 0, 0, 33, 33, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 45, 45, 0, 5, 5, 5, 49, 45, 45, 46, 46, 46, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 49, 0, 0, 0, 0, 0, 11, 12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 49, 50, 50, 50, 50, 50, 50, 39, 39, 39, 40, 40, 40, 53, 53, 45, 45, 45, 45, 46, 46, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 49, 49, 49, 0, -100], [-100, 7, 0, 0, 49, 11, 0, 5, 5, 0, 17, 39, 40, 40, 40, 40, 0, 39, 39, 39, 0, 0, 0, 0, 0, 49, 0, 0, 0, 0, 0, 0, 0, 39, 0, 0, 0, 0, 0, 33, 0, 11, 12, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 5, 5, 0, 0, 0, 0, 0, 0, 49, 0, 0, 11, 12, 12, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 49, 49, 50, 50, 50, 39, 39, 39, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 39, 40, 40, 39, 39, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11, 11, 17, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 19, 19, 19, 20, 20, 20, 39, 39, 39, 0, 7, 0, 0, 0, 5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 5, 0, 0, 0, 0, 0, 0, 39, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 49, 49, 49, 49, 50, 50, 50, 39, 39, 39, 0, 0, 33, 34, 7, 0, 0, 0, 33, 49, 49, 50, 50, 50, 49, 49, 39, 39, 39, 0, 0, 11, 17, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 49, 49, 50, 7, 45, 45, 45, 46, 46, 0, 39, 0, 0, 0, 0, 11, 12, 12, 0, 0, 0, 39, 0, 49, 0, 0, 1, 2, 2, 2, 0, 0, 11, 11, 11, 11, 0, 0, 0, 0, 0, 0, 0, 0, 25, 25, 25, 0, 0, 0, 0, 39, 0, 0, 0, 39, 39, 40, 7, 0, 0, 11, 12, 0, 0, 0, 0, 0, 0, 0, 0, 49, 50, 45, 45, 46, 46, 46, 46, 0, 0, 0, 0, 0, 0, 0, 49, 49, 50, 50, 50, 50, 50, 50, 50, 49, 50, 7, 0, 0, 0, 0, 0, 0, 0, 0, 39, 40, 40, 40, 40, 40, 39, 39, 0, 0, 0, 0, 45, 45, 45, 0, 0, 0, 0, 0, 0, 0, 0, 49, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 39, 0, 0, 39, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 45, 0, 45, 45, 0, 45, 45, 45, 45, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 45, 45, 46, 46, 46, 46, 0, 39, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 39, 0, 0, 0, 0, 35, 0, 0, 49, 50, 50, 50, 50, 50, 50, 50, 50, 50, 39, 40, 40, 40, 40, 40, 40, 40, 40, 39, 39, 0, 45, 45, 45, 46, 46, 0, 0, 0, 49, 50, 50, 50, 50, 50, 39, 40, 40, 40, 40, 45, 45, 46, 0, 0, 0, 0, 0, 0, 0, 0, 19, 19, 19, 19, 20, 39, 39, 39, 39, 40, 40, 40, 40, 40, 0, 0, 0, 0, 0, 0, 0, 0, 45, 45, 0, 0, 45, 45, 0, 0, 0, 0, 0, 0, 0, 5, 5, 45, 45, 0, 45, 45, 0, 0, 0, 0, 0, 39, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 45, 45, 0, 45, 0, 0, 0, 0, 0, 0, 11, 12, 49, 49, 49, 50, 49, 49, 49, 7, 45, 45, 46, 46, 0, 49, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 49, 50, 50, 50, 39, 39, 39, 0, 0, 0, 0, 0, 0, 0, 39, 0, 0, 0, 0, 11, 12, 12, 12, 12, 12, 12, 0, 0, 0, 0, 39, 0, 0, 0, 39, 0, 0, 49, 50, 0, 0, 0, 39, 39, 0, 0, 0, 0, 5, 5, 0, 0, 45, 45, 46, 46, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 0, 0, 0, 0, 49, 50, 49, 50, 50, 7, 45, 45, 45, 46, 46, 46, 0, 0, 0, 0, 0, 0, 0, 5, 5, 0, 0, 0, 0, 49, 49, 50, 50, 50, 39, 39, 39, 0, 0, 0, 0, 0, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 49, 49, 0, 0, 0, 0, 0, 0, 0, 39, 0, 0, 0, 0, 0, 0, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 49, 0, 0, 0, 0, 0, 39, 0, 0, 39, 39, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 35, 0, 39, 39, 39, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11, 12, 12, 0, 11, 12, 12, 0, 0, 0, 0, 39, 39, 39, 0, 35, 0, 35, 0, 0, 0, 0, 7, 7, 0, 7, 0, 7, 0, 7, 7, 0, 7, 7, 7, 8, 8, 8, 8, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 7, 7, 0, 7, 7, 7, 0, 0, 0, 0, 0, 7, 7, 0, 7, 7, 7, 0, 7, 0, 7, 7, 0, 7, 7, 7, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11, 11, 11, 17, 0, 5, 5, 0, 0, 0, 0, 0, 0, 49, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 49, 49, 49, 49, 49, 49, 50, 50, 50, 50, 50, 50, 50, 50, 39, 39, 39, 40, 40, 40, 40, 40, 7, 7, 7, 0, 0, 0, 0, 0, 45, 45, 45, 45, 46, 46, 46, 46, 0, 0, 0, 49, 50, 50, 50, 50, 50, 50, 5, 5, 5, 0, 39, 39, 45, 45, 45, 45, 45, 46, 46, 46, 11, 0, 0, 0, 17, 18, 49, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 49, 11, 12, 12, 12, 12, 12, 12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 49, 49, 49, 49, 50, 50, 50, 39, 39, 39, 0, 0, 0, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 35, 0, 0, 0, 0, 0, 0, 0, 0, 0, 49, 49, 50, 50, 50, 39, 39, 39, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 39, 40, 40, 39, 39, 0, 0, 0, 0, 5, 5, 0, 0, -100], [-100, 7, 7, 49, 0, 0, 0, 39, 40, 40, 39, 39, 0, 39, 39, 40, 7, 0, 0, 0, 0, 0, 49, 50, 49, 50, 50, 50, 50, 50, 50, 39, 40, 40, 40, 40, 0, 39, 39, 39, 0, 0, 0, 0, 0, 0, 0, 0, 0, 39, 39, 40, 40, 39, 39, 0, 0, 0, 0, 0, 0, 0, 47, 47, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 17, 39, 39, 39, 0, 5, 5, 0, 0, 0, 0, 0, 39, 39, 0, 0, 0, 0, 49, 50, 0, 0, 0, 0, 33, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11, 12, 12, 12, 0, 5, 0, 0, 7, 0, 0, 0, 0, 0, 0, 39, 39, 39, 0, 5, 5, 0, 7, 7, 39, 39, 40, 39, 0, 0, 0, 0, 0, 0, 0, 0, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 5, 5, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 49, 49, 50, 50, 50, 50, 50, 50, 39, 39, 40, 40, 39, 39, 0, 0, 49, 50, 45, 45, 46, 46, 46, 46, 0, 0, 0, 0, 0, 0, 49, 49, 50, 50, 50, 50, 50, 50, 49, 0, 0, 0, 0, 0, 0, 0, 0, 49, 50, 50, 50, 50, 49, 0, 39, 39, 0, 0, 0, 0, 0, 39, 39, 0, 0, 45, 45, 45, 0, 0, 0, 0, 0, 0, 0, 0, 0, 49, 0, 0, 35, 0, 0, 49, 50, 50, 50, 50, 50, 50, 50, 50, 50, 49, 50, 0, 0, 0, 0, 0, 39, 39, 0, 45, 45, 45, 46, 46, 0, 0, 49, 50, 50, 50, 50, 39, 39, 0, 45, 45, 46, 46, 0, 0, 0, 0, 0, 0, 39, 39, 39, 0, 0, 0, 39, 39, 39, 0, 49, 49, 49, 49, 50, 0, 0, 0, 25, 25, 25, 0, 0, 0, 11, 11, 11, 11, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 39, 39, 0, 0, 0, 0, 0, 5, 5, 7, 0, 0, 0, 49, 50, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 0, 0, 0, 49, 49, 0, 0, 49, 49, 49, 50, 50, 50, 50, 50, 50, 50, 50, 49, 49, 49, 39, 39, 39, 40, 40, 40, 40, 40, 7, 7, 7, 0, 0, 0, 0, 0, 45, 45, 45, 45, 46, 46, 46, 46, 0, 0, 0, 39, 39, 39, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 39, 39, 0, 39, 39, 39, 40, 40, 40, 40, 0, 0, 0, 39, 39, 39, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11, 12, 12, 0, 0, 0, 0, 0, 11, 12, 12, 12, 17, 39, 39, 39, 0, 0, 0, 0, 0, 0, 5, 5, 5, 5, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 39, 39, 39, 0, 0, 7, 7, 0, 7, 7, 0, 7, 7, 7, 0, 7, 7, 7, 0, 7, 0, 7, 7, 0, 7, 0, 7, 0, 7, 7, 0, 7, 7, 7, 0, 7, 7, 0, 7, 7, 7, 0, 7, 7, 0, 7, 7, 7, 8, 8, 8, 8, 0, 7, 7, 7, 8, 8, 8, 0, -100], [-100, 39, 0, 0, 49, 50, 49, 50, 0, 0, 0, 39, 17, 1, 1, 1, 1, 45, 45, 46, 46, 46, 0, 45, 45, 46, 46, 46, 46, 0, 0, 0, 39, 40, 40, 40, 40, 40, 40, 40, 0, 0, 0, 0, 39, 0, 0, 0, 11, 12, 0, 0, 45, 45, 45, 0, 49, 50, 0, 0, 0, 0, 39, 39, 39, 0, 45, 45, 45, 0, 0, 0, 0, 0, 0, 0, 39, 0, 39, 39, 39, 0, 0, 0, 0, 0, 35, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 39, 0, 43, 43, 43, 43, 0, 0, 11, 12, 12, 0, 0, 0, 39, 39, 39, 45, 45, 46, 46, 46, 0, 11, 12, 0, 0, 49, 50, 0, 0, 11, 12, 12, 0, 0, 0, 0, 0, 45, 45, 45, 0, 11, 12, 12, 12, 0, 0, 39, 39, 40, 40, 40, 17, 39, 39, 39, 0, 0, 0, 39, 40, 40, 40, 40, 40, 40, 40, 0, 0, 0, 49, 50, 49, 50, 50, 39, 0, 35, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 39, 45, 45, 46, 46, 46, 0, 45, 46, 46, 46, 46, 0, 0, 0, 49, 50, 0, 0, 49, 50, 49, 50, 50, 39, 0, 45, 45, 45, 46, 0, 45, 45, 45, 46, 46, 0, 0, 0, 17, 18, 11, 12, 12, 0, 0, 0, 0, 0, 0, 0, 49, 49, 49, 0, 0, 0, 0, 0, 0, 0, 0, 39, 0, 0, 0, 0, 0, 0, 29, 29, 0, 0, 0, 0, 11, 12, 12, 0, 0, 0, 0, 0, 0, 35, 36, 0, 0, -100]]}"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 281
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zS-6iXTkIrJT"
   },
   "source": [
    "To apply this function on all the sentences (or pairs of sentences) in our dataset, we just use the `map` method of our `dataset` object we created earlier. This will apply the function on all the elements of all the splits in `dataset`, so our training, validation and testing data will be preprocessed in one single command."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DDtsaJeVIrJT",
    "outputId": "aa4734bf-4ef5-4437-9948-2c16363da719",
    "ExecuteTime": {
     "end_time": "2024-04-10T09:22:27.747903Z",
     "start_time": "2024-04-10T09:22:27.589394Z"
    }
   },
   "source": "tokenized_datasets = datasets.map(tokenize_and_align_labels, batched=True)",
   "outputs": [],
   "execution_count": 282
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "voWiw8C7IrJV"
   },
   "source": [
    "Even better, the results are automatically cached by the 🤗 Datasets library to avoid spending time on this step the next time you run your notebook. The 🤗 Datasets library is normally smart enough to detect when the function you pass to map has changed (and thus requires to not use the cache data). For instance, it will properly detect if you change the task in the first cell and rerun the notebook. 🤗 Datasets warns you when it uses cached files, you can pass `load_from_cache_file=False` in the call to `map` to not use the cached files and force the preprocessing to be applied again.\n",
    "\n",
    "Note that we passed `batched=True` to encode the texts by batches together. This is to leverage the full benefit of the fast tokenizer we loaded earlier, which will use multi-threading to treat the texts in a batch concurrently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "545PP3o8IrJV"
   },
   "source": [
    "## Fine-tuning the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FBiW8UpKIrJW"
   },
   "source": [
    "Now that our data is ready, we can download the pretrained model and fine-tune it. Since all our tasks are about token classification, we use the `AutoModelForTokenClassification` class. Like with the tokenizer, the `from_pretrained` method will download and cache the model for us. The only thing we have to specify is the number of labels for our problem (which we can get from the features, as seen before):"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TlqNaB8jIrJW",
    "outputId": "84916cf3-6e6c-47f3-d081-032ec30a4132",
    "ExecuteTime": {
     "end_time": "2024-04-10T09:22:34.403889Z",
     "start_time": "2024-04-10T09:22:29.895825Z"
    }
   },
   "source": [
    "from transformers import BertForTokenClassification, AutoConfig, TrainingArguments, Trainer\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_checkpoint)\n",
    "\n",
    "id2label = {y: x for x, y in label2id.items()}\n",
    "config.label2id = label2id\n",
    "config.id2label = id2label\n",
    "config._num_labels = len(label2id)\n",
    "\n",
    "model = BertForTokenClassification.from_pretrained(model_checkpoint, config=config)"
   ],
   "execution_count": 283,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at ai-forever/ruBert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T09:22:57.211282Z",
     "start_time": "2024-04-10T09:22:57.204438Z"
    }
   },
   "cell_type": "code",
   "source": "model",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(120138, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=59, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 284
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CczA5lJlIrJX"
   },
   "source": [
    "The warning is telling us we are throwing away some weights (the `vocab_transform` and `vocab_layer_norm` layers) and randomly initializing some other (the `pre_classifier` and `classifier` layers). This is absolutely normal in this case, because we are removing the head used to pretrain the model on a masked language modeling objective and replacing it with a new head for which we don't have pretrained weights, so the library warns us we should fine-tune this model before using it for inference, which is exactly what we are going to do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_N8urzhyIrJY"
   },
   "source": [
    "To instantiate a `Trainer`, we will need to define three more things. The most important is the [`TrainingArguments`](https://huggingface.co/transformers/main_classes/trainer.html#transformers.TrainingArguments), which is a class that contains all the attributes to customize the training. It requires one folder name, which will be used to save the checkpoints of the model, and all other arguments are optional:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Bliy8zgjIrJY",
    "ExecuteTime": {
     "end_time": "2024-04-10T09:23:00.599074Z",
     "start_time": "2024-04-10T09:23:00.581457Z"
    }
   },
   "source": [
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-{task}\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=True,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 285
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "km3pGVdTIrJc"
   },
   "source": [
    "Here we set the evaluation to be done at the end of each epoch, tweak the learning rate, use the `batch_size` defined at the top of the notebook and customize the number of epochs for training, as well as the weight decay.\n",
    "\n",
    "The last argument to setup everything so we can push the model to the [Hub](https://huggingface.co/models) regularly during training. Remove it if you didn't follow the installation steps at the top of the notebook. If you want to save your model locally in a name that is different than the name of the repository it will be pushed, or if you want to push your model under an organization and not your name space, use the `hub_model_id` argument to set the repo name (it needs to be the full name, including your namespace: for instance `\"sgugger/bert-finetuned-ner\"` or `\"huggingface/bert-finetuned-ner\"`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W3GyIIRKYoUv"
   },
   "source": [
    "Then we will need a data collator that will batch our processed examples together while applying padding to make them all the same size (each pad will be padded to the length of its longest example). There is a data collator for this task in the Transformers library, that not only pads the inputs, but also the labels:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Yo1EYOh8YoUv",
    "ExecuteTime": {
     "end_time": "2024-04-10T09:23:02.857168Z",
     "start_time": "2024-04-10T09:23:02.851140Z"
    }
   },
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ],
   "outputs": [],
   "execution_count": 286
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kgmxomZ0YoUv"
   },
   "source": [
    "The last thing to define for our `Trainer` is how to compute the metrics from the predictions. Here we will load the [`seqeval`](https://github.com/chakki-works/seqeval) metric (which is commonly used to evaluate results on the CONLL dataset) via the Datasets library."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GZnZeIhlYoUv",
    "ExecuteTime": {
     "end_time": "2024-04-10T09:23:06.445316Z",
     "start_time": "2024-04-10T09:23:05.164711Z"
    }
   },
   "source": [
    "metric = load_metric(\"seqeval\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikolaystepanov/PycharmProjects/NLP/venv/lib/python3.9/site-packages/datasets/load.py:753: FutureWarning: The repository for seqeval contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.17.1/metrics/seqeval/seqeval.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 287
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zqQx07N4YoUv"
   },
   "source": [
    "This metric takes list of labels for the predictions and references:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "G74QYW2sYoUv",
    "outputId": "ceec1723-36c2-42be-fcf8-6e99c73ad48b",
    "ExecuteTime": {
     "end_time": "2024-04-10T09:23:10.564881Z",
     "start_time": "2024-04-10T09:23:10.512455Z"
    }
   },
   "source": [
    "labels = [i for i in example[f\"{task}_tags\"]]\n",
    "metric.compute(predictions=[labels], references=[labels])"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AGE': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'DATE': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 7},\n",
       " 'EVENT': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 3},\n",
       " 'LOCATION': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'NUMBER': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 3},\n",
       " 'ORGANIZATION': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 16},\n",
       " 'PERCENT': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'PERSON': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 10},\n",
       " 'PROFESSION': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 10},\n",
       " 'overall_precision': 1.0,\n",
       " 'overall_recall': 1.0,\n",
       " 'overall_f1': 1.0,\n",
       " 'overall_accuracy': 1.0}"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 288
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7sZOdRlRIrJd"
   },
   "source": [
    "So we will need to do a bit of post-processing on our predictions:\n",
    "- select the predicted index (with the maximum logit) for each token\n",
    "- convert it to its string label\n",
    "- ignore everywhere we set a label of -100\n",
    "\n",
    "The following function does all this post-processing on the result of `Trainer.evaluate` (which is a namedtuple containing predictions and labels) before applying the metric:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UmvbnJ9JIrJd",
    "ExecuteTime": {
     "end_time": "2024-04-10T09:23:11.728400Z",
     "start_time": "2024-04-10T09:23:11.723176Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ],
   "outputs": [],
   "execution_count": 289
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rXuFTAzDIrJe"
   },
   "source": [
    "Note that we drop the precision/recall/f1 computed for each category and only focus on the overall precision/recall/f1/accuracy.\n",
    "\n",
    "Then we just need to pass all of this along with our datasets to the `Trainer`:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "imY1oC3SIrJf",
    "ExecuteTime": {
     "end_time": "2024-04-10T09:23:16.145425Z",
     "start_time": "2024-04-10T09:23:13.285226Z"
    }
   },
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikolaystepanov/PycharmProjects/NLP/venv/lib/python3.9/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 290
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CdzABDVcIrJg"
   },
   "source": [
    "We can now finetune our model by just calling the `train` method:"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T09:24:13.364444Z",
     "start_time": "2024-04-10T09:24:13.348034Z"
    }
   },
   "cell_type": "code",
   "source": "model",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(120138, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=59, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 291
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sxTtB9CIYoUw",
    "outputId": "f3f3d138-c5d7-4275-8533-5eeef7bb4286",
    "ExecuteTime": {
     "end_time": "2024-04-10T09:24:15.076584Z",
     "start_time": "2024-04-10T09:24:13.953813Z"
    }
   },
   "source": [
    "trainer.train()"
   ],
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (1480) must match the size of tensor b (512) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[292], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/NLP/venv/lib/python3.9/site-packages/transformers/trainer.py:1615\u001B[0m, in \u001B[0;36mTrainer.train\u001B[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[1;32m   1612\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1613\u001B[0m     \u001B[38;5;66;03m# Disable progress bars when uploading models during checkpoints to avoid polluting stdout\u001B[39;00m\n\u001B[1;32m   1614\u001B[0m     hf_hub_utils\u001B[38;5;241m.\u001B[39mdisable_progress_bars()\n\u001B[0;32m-> 1615\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_training_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1616\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1617\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1618\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1619\u001B[0m \u001B[43m        \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1620\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1621\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m   1622\u001B[0m     hf_hub_utils\u001B[38;5;241m.\u001B[39menable_progress_bars()\n",
      "File \u001B[0;32m~/PycharmProjects/NLP/venv/lib/python3.9/site-packages/transformers/trainer.py:1961\u001B[0m, in \u001B[0;36mTrainer._inner_training_loop\u001B[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n\u001B[1;32m   1958\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_handler\u001B[38;5;241m.\u001B[39mon_step_begin(args, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol)\n\u001B[1;32m   1960\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maccelerator\u001B[38;5;241m.\u001B[39maccumulate(model):\n\u001B[0;32m-> 1961\u001B[0m     tr_loss_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1963\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m   1964\u001B[0m     args\u001B[38;5;241m.\u001B[39mlogging_nan_inf_filter\n\u001B[1;32m   1965\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_torch_tpu_available()\n\u001B[1;32m   1966\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (torch\u001B[38;5;241m.\u001B[39misnan(tr_loss_step) \u001B[38;5;129;01mor\u001B[39;00m torch\u001B[38;5;241m.\u001B[39misinf(tr_loss_step))\n\u001B[1;32m   1967\u001B[0m ):\n\u001B[1;32m   1968\u001B[0m     \u001B[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001B[39;00m\n\u001B[1;32m   1969\u001B[0m     tr_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m tr_loss \u001B[38;5;241m/\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mglobal_step \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_globalstep_last_logged)\n",
      "File \u001B[0;32m~/PycharmProjects/NLP/venv/lib/python3.9/site-packages/transformers/trainer.py:2902\u001B[0m, in \u001B[0;36mTrainer.training_step\u001B[0;34m(self, model, inputs)\u001B[0m\n\u001B[1;32m   2899\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m loss_mb\u001B[38;5;241m.\u001B[39mreduce_mean()\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m   2901\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_loss_context_manager():\n\u001B[0;32m-> 2902\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2904\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mn_gpu \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   2905\u001B[0m     loss \u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mmean()  \u001B[38;5;66;03m# mean() to average on multi-gpu parallel training\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/NLP/venv/lib/python3.9/site-packages/transformers/trainer.py:2925\u001B[0m, in \u001B[0;36mTrainer.compute_loss\u001B[0;34m(self, model, inputs, return_outputs)\u001B[0m\n\u001B[1;32m   2923\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   2924\u001B[0m     labels \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 2925\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2926\u001B[0m \u001B[38;5;66;03m# Save past state if it exists\u001B[39;00m\n\u001B[1;32m   2927\u001B[0m \u001B[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001B[39;00m\n\u001B[1;32m   2928\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mpast_index \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[0;32m~/PycharmProjects/NLP/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/NLP/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/NLP/venv/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:1758\u001B[0m, in \u001B[0;36mBertForTokenClassification.forward\u001B[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m   1752\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1753\u001B[0m \u001B[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001B[39;00m\n\u001B[1;32m   1754\u001B[0m \u001B[38;5;124;03m    Labels for computing the token classification loss. Indices should be in `[0, ..., config.num_labels - 1]`.\u001B[39;00m\n\u001B[1;32m   1755\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1756\u001B[0m return_dict \u001B[38;5;241m=\u001B[39m return_dict \u001B[38;5;28;01mif\u001B[39;00m return_dict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39muse_return_dict\n\u001B[0;32m-> 1758\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbert\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1759\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1760\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1761\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtoken_type_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken_type_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1762\u001B[0m \u001B[43m    \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1763\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1764\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1765\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1766\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1767\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1768\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1770\u001B[0m sequence_output \u001B[38;5;241m=\u001B[39m outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m   1772\u001B[0m sequence_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout(sequence_output)\n",
      "File \u001B[0;32m~/PycharmProjects/NLP/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/NLP/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/NLP/venv/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:1006\u001B[0m, in \u001B[0;36mBertModel.forward\u001B[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m    999\u001B[0m \u001B[38;5;66;03m# Prepare head mask if needed\u001B[39;00m\n\u001B[1;32m   1000\u001B[0m \u001B[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001B[39;00m\n\u001B[1;32m   1001\u001B[0m \u001B[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001B[39;00m\n\u001B[1;32m   1002\u001B[0m \u001B[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001B[39;00m\n\u001B[1;32m   1003\u001B[0m \u001B[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001B[39;00m\n\u001B[1;32m   1004\u001B[0m head_mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_head_mask(head_mask, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mnum_hidden_layers)\n\u001B[0;32m-> 1006\u001B[0m embedding_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membeddings\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1007\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1008\u001B[0m \u001B[43m    \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1009\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtoken_type_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken_type_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1010\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1011\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_values_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1012\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1013\u001B[0m encoder_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencoder(\n\u001B[1;32m   1014\u001B[0m     embedding_output,\n\u001B[1;32m   1015\u001B[0m     attention_mask\u001B[38;5;241m=\u001B[39mextended_attention_mask,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1023\u001B[0m     return_dict\u001B[38;5;241m=\u001B[39mreturn_dict,\n\u001B[1;32m   1024\u001B[0m )\n\u001B[1;32m   1025\u001B[0m sequence_output \u001B[38;5;241m=\u001B[39m encoder_outputs[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m~/PycharmProjects/NLP/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/NLP/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/NLP/venv/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:238\u001B[0m, in \u001B[0;36mBertEmbeddings.forward\u001B[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001B[0m\n\u001B[1;32m    236\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mposition_embedding_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mabsolute\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    237\u001B[0m     position_embeddings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mposition_embeddings(position_ids)\n\u001B[0;32m--> 238\u001B[0m     embeddings \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m position_embeddings\n\u001B[1;32m    239\u001B[0m embeddings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mLayerNorm(embeddings)\n\u001B[1;32m    240\u001B[0m embeddings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout(embeddings)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: The size of tensor a (1480) must match the size of tensor b (512) at non-singleton dimension 1"
     ]
    }
   ],
   "execution_count": 292
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CKASz-2vIrJi"
   },
   "source": [
    "The `evaluate` method allows you to evaluate again on the evaluation dataset or on another dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UOUcBkX8IrJi",
    "outputId": "de5b9dd6-9dc0-4702-cb43-55e9829fde25"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='408' max='204' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [204/204 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.05934586375951767,\n",
       " 'eval_precision': 0.9292672127518264,\n",
       " 'eval_recall': 0.9391430808815304,\n",
       " 'eval_f1': 0.9341790463472988,\n",
       " 'eval_accuracy': 0.9842565968195466,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xV_q3s1tYoUw"
   },
   "source": [
    "To get the precision/recall/f1 computed for each category now that we have finished training, we can apply the same function as before on the result of the `predict` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lLltoXusYoUw",
    "outputId": "208bd802-bdf7-4729-e362-9958eb34704d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LOC': {'precision': 0.949718574108818,\n",
       "  'recall': 0.966768525592055,\n",
       "  'f1': 0.9581677077418134,\n",
       "  'number': 2618},\n",
       " 'MISC': {'precision': 0.8132387706855791,\n",
       "  'recall': 0.8383428107229894,\n",
       "  'f1': 0.8255999999999999,\n",
       "  'number': 1231},\n",
       " 'ORG': {'precision': 0.9055232558139535,\n",
       "  'recall': 0.9090466926070039,\n",
       "  'f1': 0.9072815533980583,\n",
       "  'number': 2056},\n",
       " 'PER': {'precision': 0.9759552042160737,\n",
       "  'recall': 0.9765985497692815,\n",
       "  'f1': 0.9762767710049424,\n",
       "  'number': 3034},\n",
       " 'overall_precision': 0.9292672127518264,\n",
       " 'overall_recall': 0.9391430808815304,\n",
       " 'overall_f1': 0.9341790463472988,\n",
       " 'overall_accuracy': 0.9842565968195466}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions, labels, _ = trainer.predict(tokenized_datasets[\"validation\"])\n",
    "predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "# Remove ignored index (special tokens)\n",
    "true_predictions = [\n",
    "    [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "true_labels = [\n",
    "    [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "\n",
    "results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XLfJSn-KYoUw"
   },
   "source": [
    "You can now upload the result of the training to the Hub, just execute this instruction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QWwDBfzNYoUw"
   },
   "outputs": [],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "otWUEziQYoUw"
   },
   "source": [
    "You can now share this model with all your friends, family, favorite pets: they can all load it with the identifier `\"your-username/the-name-you-picked\"` so for instance:\n",
    "\n",
    "```python\n",
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"sgugger/my-awesome-model\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XiRmYXjEYoUw"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Token Classification",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
